{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lstm2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과정 요약:<br> \n",
    "feature: season, day of week, week number, sales <br> \n",
    "feature engineering: normalize+ denormalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과요약: seed 7: rmse 96.04 (마지막 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상세과정:\n",
    "주중(1)/주말(2) + 겨울(1)봄(2)여름(3)가을(4) // \n",
    "이미 lstm이라는 것이 sequence 개념이 있으므로 시간축(1~397)를 feature로 설정하는 것은 의미가 없을 듯 하여 LSTM 시도2에서는 제외함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가의견) 개인적으로 이상점을 제거한 후 normalize를 하면 rmse가 커질 수 밖에 없다고 생각함. 다음시도(lstm3)은 이상점을 제거하지 않고 normalize를 하고, lstm4에서는 이상점을 제거하고 normalize를 하지 않는 것을 시도하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가의견2) 처음에는 denormalize과정 없이 rmse를 구했는데, 이것보다는 denormalize를 한 후 rmse를 구하여 모델간 비교를 하는 것이 더 적절한 것 같다. normalize는 어디까지나 변환이니 항상 변환을 할때는 역변환을 하여 원본 데이터 형태m로 생각하는 것이 덜 헷갈리고, 결과값에 대한 더욱 직관적인 이해가 가능할 것 같다. 그리고, 여러 형태의 data transformation이 있는데 normalize 가장 마지막 단계의 data transformation인 것 같다. 다른 로그나 루트 변환을 한 후 normalization을 하고, 그리고 예측값이 모델을 통해 생성되면 바로 denormalize하고...예측(뉴럴) 모델의 input직전과 output직후."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set seednumber(7 or 77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DATA 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 397 entries, 0 to 396\n",
      "Data columns (total 2 columns):\n",
      "date     397 non-null object\n",
      "sales    397 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  sales\n",
       "0  2016-01-01     34\n",
       "1  2016-01-02     41\n",
       "2  2016-01-03     54\n",
       "3  2016-01-04     41\n",
       "4  2016-01-05     35"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['date','sales']\n",
    "\n",
    "txs=pd.read_table('./lstmData/lstmPrac2.csv', sep=',',header=None,names=columns )\n",
    "txs.info()\n",
    "txs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales=list(txs['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34,\n",
       " 41,\n",
       " 54,\n",
       " 41,\n",
       " 35,\n",
       " 44,\n",
       " 50,\n",
       " 42,\n",
       " 42,\n",
       " 66,\n",
       " 50,\n",
       " 55,\n",
       " 56,\n",
       " 53,\n",
       " 44,\n",
       " 54,\n",
       " 54,\n",
       " 50,\n",
       " 40,\n",
       " 49,\n",
       " 28,\n",
       " 72,\n",
       " 71,\n",
       " 53,\n",
       " 43,\n",
       " 38,\n",
       " 55,\n",
       " 49,\n",
       " 43,\n",
       " 49,\n",
       " 49,\n",
       " 44,\n",
       " 39,\n",
       " 52,\n",
       " 45,\n",
       " 33,\n",
       " 43,\n",
       " 40,\n",
       " 46,\n",
       " 49,\n",
       " 50,\n",
       " 37,\n",
       " 37,\n",
       " 45,\n",
       " 48,\n",
       " 48,\n",
       " 38,\n",
       " 60,\n",
       " 31,\n",
       " 35,\n",
       " 53,\n",
       " 70,\n",
       " 62,\n",
       " 48,\n",
       " 51,\n",
       " 49,\n",
       " 38,\n",
       " 32,\n",
       " 39,\n",
       " 35,\n",
       " 30,\n",
       " 36,\n",
       " 31,\n",
       " 31,\n",
       " 44,\n",
       " 41,\n",
       " 41,\n",
       " 45,\n",
       " 46,\n",
       " 45,\n",
       " 41,\n",
       " 47,\n",
       " 48,\n",
       " 40,\n",
       " 42,\n",
       " 38,\n",
       " 38,\n",
       " 45,\n",
       " 48,\n",
       " 62,\n",
       " 46,\n",
       " 38,\n",
       " 62,\n",
       " 81,\n",
       " 40,\n",
       " 45,\n",
       " 42,\n",
       " 53,\n",
       " 53,\n",
       " 56,\n",
       " 53,\n",
       " 47,\n",
       " 61,\n",
       " 64,\n",
       " 62,\n",
       " 37,\n",
       " 65,\n",
       " 54,\n",
       " 44,\n",
       " 46,\n",
       " 50,\n",
       " 43,\n",
       " 53,\n",
       " 63,\n",
       " 52,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 72,\n",
       " 59,\n",
       " 75,\n",
       " 47,\n",
       " 44,\n",
       " 77,\n",
       " 90,\n",
       " 93,\n",
       " 47,\n",
       " 61,\n",
       " 77,\n",
       " 282,\n",
       " 50,\n",
       " 58,\n",
       " 33,\n",
       " 41,\n",
       " 36,\n",
       " 64,\n",
       " 49,\n",
       " 53,\n",
       " 60,\n",
       " 43,\n",
       " 41,\n",
       " 55,\n",
       " 45,\n",
       " 18,\n",
       " 60,\n",
       " 69,\n",
       " 54,\n",
       " 39,\n",
       " 50,\n",
       " 44,\n",
       " 54,\n",
       " 57,\n",
       " 82,\n",
       " 57,\n",
       " 44,\n",
       " 56,\n",
       " 51,\n",
       " 55,\n",
       " 28,\n",
       " 56,\n",
       " 54,\n",
       " 36,\n",
       " 12,\n",
       " 25,\n",
       " 41,\n",
       " 11,\n",
       " 6,\n",
       " 9,\n",
       " 230,\n",
       " 29,\n",
       " 24,\n",
       " 23,\n",
       " 14,\n",
       " 21,\n",
       " 20,\n",
       " 25,\n",
       " 23,\n",
       " 27,\n",
       " 31,\n",
       " 16,\n",
       " 14,\n",
       " 30,\n",
       " 32,\n",
       " 75,\n",
       " 35,\n",
       " 26,\n",
       " 12,\n",
       " 21,\n",
       " 23,\n",
       " 28,\n",
       " 25,\n",
       " 31,\n",
       " 21,\n",
       " 17,\n",
       " 10,\n",
       " 29,\n",
       " 34,\n",
       " 28,\n",
       " 20,\n",
       " 36,\n",
       " 23,\n",
       " 15,\n",
       " 42,\n",
       " 28,\n",
       " 24,\n",
       " 29,\n",
       " 20,\n",
       " 14,\n",
       " 18,\n",
       " 27,\n",
       " 22,\n",
       " 31,\n",
       " 24,\n",
       " 39,\n",
       " 31,\n",
       " 17,\n",
       " 42,\n",
       " 29,\n",
       " 33,\n",
       " 22,\n",
       " 39,\n",
       " 25,\n",
       " 23,\n",
       " 25,\n",
       " 21,\n",
       " 18,\n",
       " 24,\n",
       " 24,\n",
       " 20,\n",
       " 9,\n",
       " 31,\n",
       " 33,\n",
       " 33,\n",
       " 31,\n",
       " 27,\n",
       " 570,\n",
       " 15,\n",
       " 25,\n",
       " 32,\n",
       " 29,\n",
       " 32,\n",
       " 21,\n",
       " 92,\n",
       " 19,\n",
       " 37,\n",
       " 29,\n",
       " 33,\n",
       " 16,\n",
       " 22,\n",
       " 25,\n",
       " 21,\n",
       " 46,\n",
       " 34,\n",
       " 31,\n",
       " 22,\n",
       " 30,\n",
       " 28,\n",
       " 14,\n",
       " 25,\n",
       " 33,\n",
       " 28,\n",
       " 24,\n",
       " 42,\n",
       " 26,\n",
       " 19,\n",
       " 41,\n",
       " 34,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 11,\n",
       " 16,\n",
       " 27,\n",
       " 27,\n",
       " 21,\n",
       " 37,\n",
       " 41,\n",
       " 23,\n",
       " 30,\n",
       " 25,\n",
       " 22,\n",
       " 26,\n",
       " 29,\n",
       " 31,\n",
       " 29,\n",
       " 12,\n",
       " 15,\n",
       " 48,\n",
       " 18,\n",
       " 25,\n",
       " 27,\n",
       " 25,\n",
       " 21,\n",
       " 28,\n",
       " 24,\n",
       " 21,\n",
       " 29,\n",
       " 121,\n",
       " 0,\n",
       " 7,\n",
       " 32,\n",
       " 19,\n",
       " 34,\n",
       " 28,\n",
       " 23,\n",
       " 15,\n",
       " 10,\n",
       " 15,\n",
       " 9,\n",
       " 78,\n",
       " 59,\n",
       " 29,\n",
       " 23,\n",
       " 12,\n",
       " 36,\n",
       " 13,\n",
       " 17,\n",
       " 17,\n",
       " 16,\n",
       " 14,\n",
       " 8,\n",
       " 16,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 20,\n",
       " 24,\n",
       " 8,\n",
       " 15,\n",
       " 17,\n",
       " 9,\n",
       " 17,\n",
       " 13,\n",
       " 19,\n",
       " 8,\n",
       " 14,\n",
       " 18,\n",
       " 24,\n",
       " 16,\n",
       " 11,\n",
       " 13,\n",
       " 10,\n",
       " 16,\n",
       " 11,\n",
       " 22,\n",
       " 15,\n",
       " 18,\n",
       " 11,\n",
       " 14,\n",
       " 34,\n",
       " 10,\n",
       " 13,\n",
       " 21,\n",
       " 35,\n",
       " 15,\n",
       " 6,\n",
       " 23,\n",
       " 22,\n",
       " 19,\n",
       " 20,\n",
       " 13,\n",
       " 21,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 16,\n",
       " 12,\n",
       " 15,\n",
       " 8,\n",
       " 0,\n",
       " 24,\n",
       " 19,\n",
       " 22,\n",
       " 13,\n",
       " 12,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 20,\n",
       " 12,\n",
       " 11,\n",
       " 22,\n",
       " 20,\n",
       " 16,\n",
       " 17,\n",
       " 97,\n",
       " 0,\n",
       " 23,\n",
       " 100,\n",
       " 18,\n",
       " 13,\n",
       " 21,\n",
       " 24,\n",
       " 16,\n",
       " 18,\n",
       " 22,\n",
       " 18,\n",
       " 11,\n",
       " 24,\n",
       " 22,\n",
       " 20,\n",
       " 22,\n",
       " 26,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 31]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 기본 feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'ds-y'의 ds로부터 api로 얻을 수 있는 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "year, day of week, month, week number를 기본 feature로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year = lambda x: datetime.strptime(x, \"%Y-%m-%d\" ).year  \n",
    "day_of_week = lambda x: datetime.strptime(x, \"%Y-%m-%d\" ).weekday()\n",
    "month = lambda x: datetime.strptime(x, \"%Y-%m-%d\" ).month\n",
    "# please read docs on how week numbers are calculate\n",
    "week_number = lambda x: datetime.strptime(x, \"%Y-%m-%d\" ).strftime('%V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txs['year'] = txs['date'].map(year)\n",
    "txs['month']=txs['date'].map(month)\n",
    "txs['week_number']=txs['date'].map(week_number)\n",
    "txs['day_of_week']=txs['date'].map(day_of_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 추가 feature + 가공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'ds-y'의 ds로부터 api로 얻을 수 없는 값: 본 feature를 가공한 feature + ds와 무관한 feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "계절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seasons = [0,0,1,1,1,2,2,2,3,3,3,0] #dec - feb is winter, then spring, summer, fall etc\n",
    "season = lambda x: seasons[(datetime.strptime(x, \"%Y-%m-%d\" ).month-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주중/주말(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day_of_week01s=[0,0,0,0,0,1,1]\n",
    "day_of_week01= lambda x: day_of_week01s[(datetime.strptime(x, \"%Y-%m-%d\" ).weekday())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week_number</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>season</th>\n",
       "      <th>day_of_week01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>34</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>41</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>54</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>41</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>35</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>44</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>50</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>42</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-01-09</td>\n",
       "      <td>42</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-01-10</td>\n",
       "      <td>66</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>50</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016-01-12</td>\n",
       "      <td>55</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>56</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>53</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>44</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>54</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>54</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>50</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>40</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>49</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>28</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>72</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>71</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>53</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>43</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016-01-26</td>\n",
       "      <td>38</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>55</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>49</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016-01-29</td>\n",
       "      <td>43</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016-01-30</td>\n",
       "      <td>49</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>16</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>20</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>22</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>20</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>16</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>17</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>97</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>23</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>2017-01-13</td>\n",
       "      <td>100</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>18</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>13</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>21</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2017-01-17</td>\n",
       "      <td>24</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2017-01-18</td>\n",
       "      <td>16</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>18</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>22</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>18</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>24</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>22</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>20</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>22</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>26</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>31</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  sales  year  month week_number  day_of_week  season  \\\n",
       "0    2016-01-01     34  2016      1          53            4       0   \n",
       "1    2016-01-02     41  2016      1          53            5       0   \n",
       "2    2016-01-03     54  2016      1          53            6       0   \n",
       "3    2016-01-04     41  2016      1          01            0       0   \n",
       "4    2016-01-05     35  2016      1          01            1       0   \n",
       "5    2016-01-06     44  2016      1          01            2       0   \n",
       "6    2016-01-07     50  2016      1          01            3       0   \n",
       "7    2016-01-08     42  2016      1          01            4       0   \n",
       "8    2016-01-09     42  2016      1          01            5       0   \n",
       "9    2016-01-10     66  2016      1          01            6       0   \n",
       "10   2016-01-11     50  2016      1          02            0       0   \n",
       "11   2016-01-12     55  2016      1          02            1       0   \n",
       "12   2016-01-13     56  2016      1          02            2       0   \n",
       "13   2016-01-14     53  2016      1          02            3       0   \n",
       "14   2016-01-15     44  2016      1          02            4       0   \n",
       "15   2016-01-16     54  2016      1          02            5       0   \n",
       "16   2016-01-17     54  2016      1          02            6       0   \n",
       "17   2016-01-18     50  2016      1          03            0       0   \n",
       "18   2016-01-19     40  2016      1          03            1       0   \n",
       "19   2016-01-20     49  2016      1          03            2       0   \n",
       "20   2016-01-21     28  2016      1          03            3       0   \n",
       "21   2016-01-22     72  2016      1          03            4       0   \n",
       "22   2016-01-23     71  2016      1          03            5       0   \n",
       "23   2016-01-24     53  2016      1          03            6       0   \n",
       "24   2016-01-25     43  2016      1          04            0       0   \n",
       "25   2016-01-26     38  2016      1          04            1       0   \n",
       "26   2016-01-27     55  2016      1          04            2       0   \n",
       "27   2016-01-28     49  2016      1          04            3       0   \n",
       "28   2016-01-29     43  2016      1          04            4       0   \n",
       "29   2016-01-30     49  2016      1          04            5       0   \n",
       "..          ...    ...   ...    ...         ...          ...     ...   \n",
       "367  2017-01-02     16  2017      1          01            0       0   \n",
       "368  2017-01-03     20  2017      1          01            1       0   \n",
       "369  2017-01-04     12  2017      1          01            2       0   \n",
       "370  2017-01-05     11  2017      1          01            3       0   \n",
       "371  2017-01-06     22  2017      1          01            4       0   \n",
       "372  2017-01-07     20  2017      1          01            5       0   \n",
       "373  2017-01-08     16  2017      1          01            6       0   \n",
       "374  2017-01-09     17  2017      1          02            0       0   \n",
       "375  2017-01-10     97  2017      1          02            1       0   \n",
       "376  2017-01-11      0  2017      1          02            2       0   \n",
       "377  2017-01-12     23  2017      1          02            3       0   \n",
       "378  2017-01-13    100  2017      1          02            4       0   \n",
       "379  2017-01-14     18  2017      1          02            5       0   \n",
       "380  2017-01-15     13  2017      1          02            6       0   \n",
       "381  2017-01-16     21  2017      1          03            0       0   \n",
       "382  2017-01-17     24  2017      1          03            1       0   \n",
       "383  2017-01-18     16  2017      1          03            2       0   \n",
       "384  2017-01-19     18  2017      1          03            3       0   \n",
       "385  2017-01-20     22  2017      1          03            4       0   \n",
       "386  2017-01-21     18  2017      1          03            5       0   \n",
       "387  2017-01-22     11  2017      1          03            6       0   \n",
       "388  2017-01-23     24  2017      1          04            0       0   \n",
       "389  2017-01-24     22  2017      1          04            1       0   \n",
       "390  2017-01-25     20  2017      1          04            2       0   \n",
       "391  2017-01-26     22  2017      1          04            3       0   \n",
       "392  2017-01-27     26  2017      1          04            4       0   \n",
       "393  2017-01-28      0  2017      1          04            5       0   \n",
       "394  2017-01-29      0  2017      1          04            6       0   \n",
       "395  2017-01-30      5  2017      1          05            0       0   \n",
       "396  2017-01-31     31  2017      1          05            1       0   \n",
       "\n",
       "     day_of_week01  \n",
       "0                0  \n",
       "1                1  \n",
       "2                1  \n",
       "3                0  \n",
       "4                0  \n",
       "5                0  \n",
       "6                0  \n",
       "7                0  \n",
       "8                1  \n",
       "9                1  \n",
       "10               0  \n",
       "11               0  \n",
       "12               0  \n",
       "13               0  \n",
       "14               0  \n",
       "15               1  \n",
       "16               1  \n",
       "17               0  \n",
       "18               0  \n",
       "19               0  \n",
       "20               0  \n",
       "21               0  \n",
       "22               1  \n",
       "23               1  \n",
       "24               0  \n",
       "25               0  \n",
       "26               0  \n",
       "27               0  \n",
       "28               0  \n",
       "29               1  \n",
       "..             ...  \n",
       "367              0  \n",
       "368              0  \n",
       "369              0  \n",
       "370              0  \n",
       "371              0  \n",
       "372              1  \n",
       "373              1  \n",
       "374              0  \n",
       "375              0  \n",
       "376              0  \n",
       "377              0  \n",
       "378              0  \n",
       "379              1  \n",
       "380              1  \n",
       "381              0  \n",
       "382              0  \n",
       "383              0  \n",
       "384              0  \n",
       "385              0  \n",
       "386              1  \n",
       "387              1  \n",
       "388              0  \n",
       "389              0  \n",
       "390              0  \n",
       "391              0  \n",
       "392              0  \n",
       "393              1  \n",
       "394              1  \n",
       "395              0  \n",
       "396              0  \n",
       "\n",
       "[397 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txs['season']=txs['date'].map(season)\n",
    "txs['day_of_week01']=txs['date'].map(day_of_week01)\n",
    "txs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas를 통해 구한 각 feature는 list()로 우리의 기준type인 list로 변경이 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 추가 가공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 y의 추가 가공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막rmse를 계산할 때 원본 데이터를 복원하기 위해 저장해놓음(아무런 가공되지 않은 원본 sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "originalSales=list(txs['sales'])\n",
    "sales=list(txs['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "282 in originalSales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가공을 하는 순서도 중요한데, 이상점 제거-> log or sqrt -> normalization이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이상점 제거, bucketization 을 하여 새로운 열을 생성하는 방향으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이상점 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이상점 제거를 위해 평균과 표준편차를 구한다. 이상점의 기준은 일단 평균+-2*sd로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noOutlierSales(sales):\n",
    "    mean=np.mean(sales)\n",
    "    std=np.std(sales)\n",
    "    for i in range(len(sales)):\n",
    "        if (sales[i]<mean-2*std or sales[i]>mean+2*std):\n",
    "             sales[i]=int(mean)\n",
    "    return sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logSales(sales):\n",
    "    for i in range(len(sales)):\n",
    "        if sales[i] is 0:\n",
    "            sales[i]=1\n",
    "    return np.log(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sqrt(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sqrtSales(sales):\n",
    "    return np.sqrt(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales=noOutlierSales(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "282 in sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "282 in originalSales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 x의 추가 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 합친 후 (필요 시 normalize하여) 최종 data 생성: XY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "계절(0~3) + 요일(0~6) + 주수(1~53) -> 판매량"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tempxy=[list(txs['season']),list(txs['day_of_week']),list(txs['week_number']),sales]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "계절(0~3) + 요일(0,1) + 주수(1~53) -> 판매량"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tempxy=[list(txs['season']),list(txs['day_of_week01']),list(txs['week_number']),sales]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xy=np.array(tempxy).transpose().astype(np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minMaxNormalizer(data):\n",
    "    numerator=data-np.min(data)\n",
    "    denominator=np.max(data)-np.min(data)\n",
    "    return numerator/(denominator+1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization이 필요한 열을 normalize시킴(현재는 sales에 해당하는 마지막 열만 normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xy=minMaxNormalizer(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.53,  0.34],\n",
       "       [ 0.  ,  0.01,  0.53,  0.41],\n",
       "       [ 0.  ,  0.01,  0.53,  0.54],\n",
       "       ..., \n",
       "       [ 0.  ,  0.01,  0.04,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.05,  0.05],\n",
       "       [ 0.  ,  0.  ,  0.05,  0.31]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xy[:,-1]=minMaxNormalizer(xy[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 열 ex) XY[:,-3]=minMaxNormalizer(XY[:,-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Denormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측모델을 통해 얻은 sales결과를 denormalize시켜 기존 단위로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minMaxDeNormalizer(data, originalData):\n",
    "    shift=np.min(originalData)\n",
    "    multiplier=np.max(originalData)-np.min(originalData)\n",
    "    return (data+shift)*multiplier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 함수를 마지막 rmse구하기 전에 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MODEL 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 사용 model 정의: RNN LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 해당 model의 train parameters 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_dim은 y값 도출을 위한 feature 가지수+1(독립변수 가지수 +1(y포함))\n",
    "data_dim=4\n",
    "\n",
    "#data_dim크기의 data 한 묶음이 seq_length만큼 input으로 들어가\n",
    "seq_length=5\n",
    "\n",
    "#output_dim(=forecastDays)만큼의 다음날 y_data를 예측\n",
    "forecastDays=1\n",
    "output_dim=forecastDays\n",
    "\n",
    "#hidden_dim은 정말 임의로 설정\n",
    "hidden_dim=10\n",
    "\n",
    "#learning rate은 배우는 속도(너무 크지도, 작지도 않게 설정)\n",
    "learning_rate=0.01\n",
    "\n",
    "#iterations는 반복 횟수\n",
    "iterations=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 사용 model, train parameter에 맞추어 dataset(XY) 변환: dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.    0.53  0.34]\n",
      " [ 0.    0.01  0.53  0.41]\n",
      " [ 0.    0.01  0.53  0.54]\n",
      " [ 0.    0.    0.01  0.41]\n",
      " [ 0.    0.    0.01  0.35]] -> [ 0.44]\n",
      "[[ 0.    0.01  0.53  0.41]\n",
      " [ 0.    0.01  0.53  0.54]\n",
      " [ 0.    0.    0.01  0.41]\n",
      " [ 0.    0.    0.01  0.35]\n",
      " [ 0.    0.    0.01  0.44]] -> [ 0.5]\n",
      "[[ 0.    0.01  0.53  0.54]\n",
      " [ 0.    0.    0.01  0.41]\n",
      " [ 0.    0.    0.01  0.35]\n",
      " [ 0.    0.    0.01  0.44]\n",
      " [ 0.    0.    0.01  0.5 ]] -> [ 0.42]\n",
      "[[ 0.    0.    0.01  0.41]\n",
      " [ 0.    0.    0.01  0.35]\n",
      " [ 0.    0.    0.01  0.44]\n",
      " [ 0.    0.    0.01  0.5 ]\n",
      " [ 0.    0.    0.01  0.42]] -> [ 0.42]\n",
      "[[ 0.    0.    0.01  0.35]\n",
      " [ 0.    0.    0.01  0.44]\n",
      " [ 0.    0.    0.01  0.5 ]\n",
      " [ 0.    0.    0.01  0.42]\n",
      " [ 0.    0.01  0.01  0.42]] -> [ 0.66]\n",
      "[[ 0.    0.    0.01  0.44]\n",
      " [ 0.    0.    0.01  0.5 ]\n",
      " [ 0.    0.    0.01  0.42]\n",
      " [ 0.    0.01  0.01  0.42]\n",
      " [ 0.    0.01  0.01  0.66]] -> [ 0.5]\n",
      "[[ 0.    0.    0.01  0.5 ]\n",
      " [ 0.    0.    0.01  0.42]\n",
      " [ 0.    0.01  0.01  0.42]\n",
      " [ 0.    0.01  0.01  0.66]\n",
      " [ 0.    0.    0.02  0.5 ]] -> [ 0.55]\n",
      "[[ 0.    0.    0.01  0.42]\n",
      " [ 0.    0.01  0.01  0.42]\n",
      " [ 0.    0.01  0.01  0.66]\n",
      " [ 0.    0.    0.02  0.5 ]\n",
      " [ 0.    0.    0.02  0.55]] -> [ 0.56]\n",
      "[[ 0.    0.01  0.01  0.42]\n",
      " [ 0.    0.01  0.01  0.66]\n",
      " [ 0.    0.    0.02  0.5 ]\n",
      " [ 0.    0.    0.02  0.55]\n",
      " [ 0.    0.    0.02  0.56]] -> [ 0.53]\n",
      "[[ 0.    0.01  0.01  0.66]\n",
      " [ 0.    0.    0.02  0.5 ]\n",
      " [ 0.    0.    0.02  0.55]\n",
      " [ 0.    0.    0.02  0.56]\n",
      " [ 0.    0.    0.02  0.53]] -> [ 0.44]\n",
      "[[ 0.    0.    0.02  0.5 ]\n",
      " [ 0.    0.    0.02  0.55]\n",
      " [ 0.    0.    0.02  0.56]\n",
      " [ 0.    0.    0.02  0.53]\n",
      " [ 0.    0.    0.02  0.44]] -> [ 0.54]\n",
      "[[ 0.    0.    0.02  0.55]\n",
      " [ 0.    0.    0.02  0.56]\n",
      " [ 0.    0.    0.02  0.53]\n",
      " [ 0.    0.    0.02  0.44]\n",
      " [ 0.    0.01  0.02  0.54]] -> [ 0.54]\n",
      "[[ 0.    0.    0.02  0.56]\n",
      " [ 0.    0.    0.02  0.53]\n",
      " [ 0.    0.    0.02  0.44]\n",
      " [ 0.    0.01  0.02  0.54]\n",
      " [ 0.    0.01  0.02  0.54]] -> [ 0.5]\n",
      "[[ 0.    0.    0.02  0.53]\n",
      " [ 0.    0.    0.02  0.44]\n",
      " [ 0.    0.01  0.02  0.54]\n",
      " [ 0.    0.01  0.02  0.54]\n",
      " [ 0.    0.    0.03  0.5 ]] -> [ 0.4]\n",
      "[[ 0.    0.    0.02  0.44]\n",
      " [ 0.    0.01  0.02  0.54]\n",
      " [ 0.    0.01  0.02  0.54]\n",
      " [ 0.    0.    0.03  0.5 ]\n",
      " [ 0.    0.    0.03  0.4 ]] -> [ 0.49]\n",
      "[[ 0.    0.01  0.02  0.54]\n",
      " [ 0.    0.01  0.02  0.54]\n",
      " [ 0.    0.    0.03  0.5 ]\n",
      " [ 0.    0.    0.03  0.4 ]\n",
      " [ 0.    0.    0.03  0.49]] -> [ 0.28]\n",
      "[[ 0.    0.01  0.02  0.54]\n",
      " [ 0.    0.    0.03  0.5 ]\n",
      " [ 0.    0.    0.03  0.4 ]\n",
      " [ 0.    0.    0.03  0.49]\n",
      " [ 0.    0.    0.03  0.28]] -> [ 0.72]\n",
      "[[ 0.    0.    0.03  0.5 ]\n",
      " [ 0.    0.    0.03  0.4 ]\n",
      " [ 0.    0.    0.03  0.49]\n",
      " [ 0.    0.    0.03  0.28]\n",
      " [ 0.    0.    0.03  0.72]] -> [ 0.71]\n",
      "[[ 0.    0.    0.03  0.4 ]\n",
      " [ 0.    0.    0.03  0.49]\n",
      " [ 0.    0.    0.03  0.28]\n",
      " [ 0.    0.    0.03  0.72]\n",
      " [ 0.    0.01  0.03  0.71]] -> [ 0.53]\n",
      "[[ 0.    0.    0.03  0.49]\n",
      " [ 0.    0.    0.03  0.28]\n",
      " [ 0.    0.    0.03  0.72]\n",
      " [ 0.    0.01  0.03  0.71]\n",
      " [ 0.    0.01  0.03  0.53]] -> [ 0.43]\n",
      "[[ 0.    0.    0.03  0.28]\n",
      " [ 0.    0.    0.03  0.72]\n",
      " [ 0.    0.01  0.03  0.71]\n",
      " [ 0.    0.01  0.03  0.53]\n",
      " [ 0.    0.    0.04  0.43]] -> [ 0.38]\n",
      "[[ 0.    0.    0.03  0.72]\n",
      " [ 0.    0.01  0.03  0.71]\n",
      " [ 0.    0.01  0.03  0.53]\n",
      " [ 0.    0.    0.04  0.43]\n",
      " [ 0.    0.    0.04  0.38]] -> [ 0.55]\n",
      "[[ 0.    0.01  0.03  0.71]\n",
      " [ 0.    0.01  0.03  0.53]\n",
      " [ 0.    0.    0.04  0.43]\n",
      " [ 0.    0.    0.04  0.38]\n",
      " [ 0.    0.    0.04  0.55]] -> [ 0.49]\n",
      "[[ 0.    0.01  0.03  0.53]\n",
      " [ 0.    0.    0.04  0.43]\n",
      " [ 0.    0.    0.04  0.38]\n",
      " [ 0.    0.    0.04  0.55]\n",
      " [ 0.    0.    0.04  0.49]] -> [ 0.43]\n",
      "[[ 0.    0.    0.04  0.43]\n",
      " [ 0.    0.    0.04  0.38]\n",
      " [ 0.    0.    0.04  0.55]\n",
      " [ 0.    0.    0.04  0.49]\n",
      " [ 0.    0.    0.04  0.43]] -> [ 0.49]\n",
      "[[ 0.    0.    0.04  0.38]\n",
      " [ 0.    0.    0.04  0.55]\n",
      " [ 0.    0.    0.04  0.49]\n",
      " [ 0.    0.    0.04  0.43]\n",
      " [ 0.    0.01  0.04  0.49]] -> [ 0.49]\n",
      "[[ 0.    0.    0.04  0.55]\n",
      " [ 0.    0.    0.04  0.49]\n",
      " [ 0.    0.    0.04  0.43]\n",
      " [ 0.    0.01  0.04  0.49]\n",
      " [ 0.    0.01  0.04  0.49]] -> [ 0.44]\n",
      "[[ 0.    0.    0.04  0.49]\n",
      " [ 0.    0.    0.04  0.43]\n",
      " [ 0.    0.01  0.04  0.49]\n",
      " [ 0.    0.01  0.04  0.49]\n",
      " [ 0.    0.    0.05  0.44]] -> [ 0.39]\n",
      "[[ 0.    0.    0.04  0.43]\n",
      " [ 0.    0.01  0.04  0.49]\n",
      " [ 0.    0.01  0.04  0.49]\n",
      " [ 0.    0.    0.05  0.44]\n",
      " [ 0.    0.    0.05  0.39]] -> [ 0.52]\n",
      "[[ 0.    0.01  0.04  0.49]\n",
      " [ 0.    0.01  0.04  0.49]\n",
      " [ 0.    0.    0.05  0.44]\n",
      " [ 0.    0.    0.05  0.39]\n",
      " [ 0.    0.    0.05  0.52]] -> [ 0.45]\n",
      "[[ 0.    0.01  0.04  0.49]\n",
      " [ 0.    0.    0.05  0.44]\n",
      " [ 0.    0.    0.05  0.39]\n",
      " [ 0.    0.    0.05  0.52]\n",
      " [ 0.    0.    0.05  0.45]] -> [ 0.33]\n",
      "[[ 0.    0.    0.05  0.44]\n",
      " [ 0.    0.    0.05  0.39]\n",
      " [ 0.    0.    0.05  0.52]\n",
      " [ 0.    0.    0.05  0.45]\n",
      " [ 0.    0.    0.05  0.33]] -> [ 0.43]\n",
      "[[ 0.    0.    0.05  0.39]\n",
      " [ 0.    0.    0.05  0.52]\n",
      " [ 0.    0.    0.05  0.45]\n",
      " [ 0.    0.    0.05  0.33]\n",
      " [ 0.    0.01  0.05  0.43]] -> [ 0.4]\n",
      "[[ 0.    0.    0.05  0.52]\n",
      " [ 0.    0.    0.05  0.45]\n",
      " [ 0.    0.    0.05  0.33]\n",
      " [ 0.    0.01  0.05  0.43]\n",
      " [ 0.    0.01  0.05  0.4 ]] -> [ 0.46]\n",
      "[[ 0.    0.    0.05  0.45]\n",
      " [ 0.    0.    0.05  0.33]\n",
      " [ 0.    0.01  0.05  0.43]\n",
      " [ 0.    0.01  0.05  0.4 ]\n",
      " [ 0.    0.    0.06  0.46]] -> [ 0.49]\n",
      "[[ 0.    0.    0.05  0.33]\n",
      " [ 0.    0.01  0.05  0.43]\n",
      " [ 0.    0.01  0.05  0.4 ]\n",
      " [ 0.    0.    0.06  0.46]\n",
      " [ 0.    0.    0.06  0.49]] -> [ 0.5]\n",
      "[[ 0.    0.01  0.05  0.43]\n",
      " [ 0.    0.01  0.05  0.4 ]\n",
      " [ 0.    0.    0.06  0.46]\n",
      " [ 0.    0.    0.06  0.49]\n",
      " [ 0.    0.    0.06  0.5 ]] -> [ 0.37]\n",
      "[[ 0.    0.01  0.05  0.4 ]\n",
      " [ 0.    0.    0.06  0.46]\n",
      " [ 0.    0.    0.06  0.49]\n",
      " [ 0.    0.    0.06  0.5 ]\n",
      " [ 0.    0.    0.06  0.37]] -> [ 0.37]\n",
      "[[ 0.    0.    0.06  0.46]\n",
      " [ 0.    0.    0.06  0.49]\n",
      " [ 0.    0.    0.06  0.5 ]\n",
      " [ 0.    0.    0.06  0.37]\n",
      " [ 0.    0.    0.06  0.37]] -> [ 0.45]\n",
      "[[ 0.    0.    0.06  0.49]\n",
      " [ 0.    0.    0.06  0.5 ]\n",
      " [ 0.    0.    0.06  0.37]\n",
      " [ 0.    0.    0.06  0.37]\n",
      " [ 0.    0.01  0.06  0.45]] -> [ 0.48]\n",
      "[[ 0.    0.    0.06  0.5 ]\n",
      " [ 0.    0.    0.06  0.37]\n",
      " [ 0.    0.    0.06  0.37]\n",
      " [ 0.    0.01  0.06  0.45]\n",
      " [ 0.    0.01  0.06  0.48]] -> [ 0.48]\n",
      "[[ 0.    0.    0.06  0.37]\n",
      " [ 0.    0.    0.06  0.37]\n",
      " [ 0.    0.01  0.06  0.45]\n",
      " [ 0.    0.01  0.06  0.48]\n",
      " [ 0.    0.    0.07  0.48]] -> [ 0.38]\n",
      "[[ 0.    0.    0.06  0.37]\n",
      " [ 0.    0.01  0.06  0.45]\n",
      " [ 0.    0.01  0.06  0.48]\n",
      " [ 0.    0.    0.07  0.48]\n",
      " [ 0.    0.    0.07  0.38]] -> [ 0.6]\n",
      "[[ 0.    0.01  0.06  0.45]\n",
      " [ 0.    0.01  0.06  0.48]\n",
      " [ 0.    0.    0.07  0.48]\n",
      " [ 0.    0.    0.07  0.38]\n",
      " [ 0.    0.    0.07  0.6 ]] -> [ 0.31]\n",
      "[[ 0.    0.01  0.06  0.48]\n",
      " [ 0.    0.    0.07  0.48]\n",
      " [ 0.    0.    0.07  0.38]\n",
      " [ 0.    0.    0.07  0.6 ]\n",
      " [ 0.    0.    0.07  0.31]] -> [ 0.35]\n",
      "[[ 0.    0.    0.07  0.48]\n",
      " [ 0.    0.    0.07  0.38]\n",
      " [ 0.    0.    0.07  0.6 ]\n",
      " [ 0.    0.    0.07  0.31]\n",
      " [ 0.    0.    0.07  0.35]] -> [ 0.53]\n",
      "[[ 0.    0.    0.07  0.38]\n",
      " [ 0.    0.    0.07  0.6 ]\n",
      " [ 0.    0.    0.07  0.31]\n",
      " [ 0.    0.    0.07  0.35]\n",
      " [ 0.    0.01  0.07  0.53]] -> [ 0.7]\n",
      "[[ 0.    0.    0.07  0.6 ]\n",
      " [ 0.    0.    0.07  0.31]\n",
      " [ 0.    0.    0.07  0.35]\n",
      " [ 0.    0.01  0.07  0.53]\n",
      " [ 0.    0.01  0.07  0.7 ]] -> [ 0.62]\n",
      "[[ 0.    0.    0.07  0.31]\n",
      " [ 0.    0.    0.07  0.35]\n",
      " [ 0.    0.01  0.07  0.53]\n",
      " [ 0.    0.01  0.07  0.7 ]\n",
      " [ 0.    0.    0.08  0.62]] -> [ 0.48]\n",
      "[[ 0.    0.    0.07  0.35]\n",
      " [ 0.    0.01  0.07  0.53]\n",
      " [ 0.    0.01  0.07  0.7 ]\n",
      " [ 0.    0.    0.08  0.62]\n",
      " [ 0.    0.    0.08  0.48]] -> [ 0.51]\n",
      "[[ 0.    0.01  0.07  0.53]\n",
      " [ 0.    0.01  0.07  0.7 ]\n",
      " [ 0.    0.    0.08  0.62]\n",
      " [ 0.    0.    0.08  0.48]\n",
      " [ 0.    0.    0.08  0.51]] -> [ 0.49]\n",
      "[[ 0.    0.01  0.07  0.7 ]\n",
      " [ 0.    0.    0.08  0.62]\n",
      " [ 0.    0.    0.08  0.48]\n",
      " [ 0.    0.    0.08  0.51]\n",
      " [ 0.    0.    0.08  0.49]] -> [ 0.38]\n",
      "[[ 0.    0.    0.08  0.62]\n",
      " [ 0.    0.    0.08  0.48]\n",
      " [ 0.    0.    0.08  0.51]\n",
      " [ 0.    0.    0.08  0.49]\n",
      " [ 0.    0.    0.08  0.38]] -> [ 0.32]\n",
      "[[ 0.    0.    0.08  0.48]\n",
      " [ 0.    0.    0.08  0.51]\n",
      " [ 0.    0.    0.08  0.49]\n",
      " [ 0.    0.    0.08  0.38]\n",
      " [ 0.    0.01  0.08  0.32]] -> [ 0.39]\n",
      "[[ 0.    0.    0.08  0.51]\n",
      " [ 0.    0.    0.08  0.49]\n",
      " [ 0.    0.    0.08  0.38]\n",
      " [ 0.    0.01  0.08  0.32]\n",
      " [ 0.    0.01  0.08  0.39]] -> [ 0.35]\n",
      "[[ 0.    0.    0.08  0.49]\n",
      " [ 0.    0.    0.08  0.38]\n",
      " [ 0.    0.01  0.08  0.32]\n",
      " [ 0.    0.01  0.08  0.39]\n",
      " [ 0.    0.    0.09  0.35]] -> [ 0.3]\n",
      "[[ 0.    0.    0.08  0.38]\n",
      " [ 0.    0.01  0.08  0.32]\n",
      " [ 0.    0.01  0.08  0.39]\n",
      " [ 0.    0.    0.09  0.35]\n",
      " [ 0.01  0.    0.09  0.3 ]] -> [ 0.36]\n",
      "[[ 0.    0.01  0.08  0.32]\n",
      " [ 0.    0.01  0.08  0.39]\n",
      " [ 0.    0.    0.09  0.35]\n",
      " [ 0.01  0.    0.09  0.3 ]\n",
      " [ 0.01  0.    0.09  0.36]] -> [ 0.31]\n",
      "[[ 0.    0.01  0.08  0.39]\n",
      " [ 0.    0.    0.09  0.35]\n",
      " [ 0.01  0.    0.09  0.3 ]\n",
      " [ 0.01  0.    0.09  0.36]\n",
      " [ 0.01  0.    0.09  0.31]] -> [ 0.31]\n",
      "[[ 0.    0.    0.09  0.35]\n",
      " [ 0.01  0.    0.09  0.3 ]\n",
      " [ 0.01  0.    0.09  0.36]\n",
      " [ 0.01  0.    0.09  0.31]\n",
      " [ 0.01  0.    0.09  0.31]] -> [ 0.44]\n",
      "[[ 0.01  0.    0.09  0.3 ]\n",
      " [ 0.01  0.    0.09  0.36]\n",
      " [ 0.01  0.    0.09  0.31]\n",
      " [ 0.01  0.    0.09  0.31]\n",
      " [ 0.01  0.01  0.09  0.44]] -> [ 0.41]\n",
      "[[ 0.01  0.    0.09  0.36]\n",
      " [ 0.01  0.    0.09  0.31]\n",
      " [ 0.01  0.    0.09  0.31]\n",
      " [ 0.01  0.01  0.09  0.44]\n",
      " [ 0.01  0.01  0.09  0.41]] -> [ 0.41]\n",
      "[[ 0.01  0.    0.09  0.31]\n",
      " [ 0.01  0.    0.09  0.31]\n",
      " [ 0.01  0.01  0.09  0.44]\n",
      " [ 0.01  0.01  0.09  0.41]\n",
      " [ 0.01  0.    0.1   0.41]] -> [ 0.45]\n",
      "[[ 0.01  0.    0.09  0.31]\n",
      " [ 0.01  0.01  0.09  0.44]\n",
      " [ 0.01  0.01  0.09  0.41]\n",
      " [ 0.01  0.    0.1   0.41]\n",
      " [ 0.01  0.    0.1   0.45]] -> [ 0.46]\n",
      "[[ 0.01  0.01  0.09  0.44]\n",
      " [ 0.01  0.01  0.09  0.41]\n",
      " [ 0.01  0.    0.1   0.41]\n",
      " [ 0.01  0.    0.1   0.45]\n",
      " [ 0.01  0.    0.1   0.46]] -> [ 0.45]\n",
      "[[ 0.01  0.01  0.09  0.41]\n",
      " [ 0.01  0.    0.1   0.41]\n",
      " [ 0.01  0.    0.1   0.45]\n",
      " [ 0.01  0.    0.1   0.46]\n",
      " [ 0.01  0.    0.1   0.45]] -> [ 0.41]\n",
      "[[ 0.01  0.    0.1   0.41]\n",
      " [ 0.01  0.    0.1   0.45]\n",
      " [ 0.01  0.    0.1   0.46]\n",
      " [ 0.01  0.    0.1   0.45]\n",
      " [ 0.01  0.    0.1   0.41]] -> [ 0.47]\n",
      "[[ 0.01  0.    0.1   0.45]\n",
      " [ 0.01  0.    0.1   0.46]\n",
      " [ 0.01  0.    0.1   0.45]\n",
      " [ 0.01  0.    0.1   0.41]\n",
      " [ 0.01  0.01  0.1   0.47]] -> [ 0.48]\n",
      "[[ 0.01  0.    0.1   0.46]\n",
      " [ 0.01  0.    0.1   0.45]\n",
      " [ 0.01  0.    0.1   0.41]\n",
      " [ 0.01  0.01  0.1   0.47]\n",
      " [ 0.01  0.01  0.1   0.48]] -> [ 0.4]\n",
      "[[ 0.01  0.    0.1   0.45]\n",
      " [ 0.01  0.    0.1   0.41]\n",
      " [ 0.01  0.01  0.1   0.47]\n",
      " [ 0.01  0.01  0.1   0.48]\n",
      " [ 0.01  0.    0.11  0.4 ]] -> [ 0.42]\n",
      "[[ 0.01  0.    0.1   0.41]\n",
      " [ 0.01  0.01  0.1   0.47]\n",
      " [ 0.01  0.01  0.1   0.48]\n",
      " [ 0.01  0.    0.11  0.4 ]\n",
      " [ 0.01  0.    0.11  0.42]] -> [ 0.38]\n",
      "[[ 0.01  0.01  0.1   0.47]\n",
      " [ 0.01  0.01  0.1   0.48]\n",
      " [ 0.01  0.    0.11  0.4 ]\n",
      " [ 0.01  0.    0.11  0.42]\n",
      " [ 0.01  0.    0.11  0.38]] -> [ 0.38]\n",
      "[[ 0.01  0.01  0.1   0.48]\n",
      " [ 0.01  0.    0.11  0.4 ]\n",
      " [ 0.01  0.    0.11  0.42]\n",
      " [ 0.01  0.    0.11  0.38]\n",
      " [ 0.01  0.    0.11  0.38]] -> [ 0.45]\n",
      "[[ 0.01  0.    0.11  0.4 ]\n",
      " [ 0.01  0.    0.11  0.42]\n",
      " [ 0.01  0.    0.11  0.38]\n",
      " [ 0.01  0.    0.11  0.38]\n",
      " [ 0.01  0.    0.11  0.45]] -> [ 0.48]\n",
      "[[ 0.01  0.    0.11  0.42]\n",
      " [ 0.01  0.    0.11  0.38]\n",
      " [ 0.01  0.    0.11  0.38]\n",
      " [ 0.01  0.    0.11  0.45]\n",
      " [ 0.01  0.01  0.11  0.48]] -> [ 0.62]\n",
      "[[ 0.01  0.    0.11  0.38]\n",
      " [ 0.01  0.    0.11  0.38]\n",
      " [ 0.01  0.    0.11  0.45]\n",
      " [ 0.01  0.01  0.11  0.48]\n",
      " [ 0.01  0.01  0.11  0.62]] -> [ 0.46]\n",
      "[[ 0.01  0.    0.11  0.38]\n",
      " [ 0.01  0.    0.11  0.45]\n",
      " [ 0.01  0.01  0.11  0.48]\n",
      " [ 0.01  0.01  0.11  0.62]\n",
      " [ 0.01  0.    0.12  0.46]] -> [ 0.38]\n",
      "[[ 0.01  0.    0.11  0.45]\n",
      " [ 0.01  0.01  0.11  0.48]\n",
      " [ 0.01  0.01  0.11  0.62]\n",
      " [ 0.01  0.    0.12  0.46]\n",
      " [ 0.01  0.    0.12  0.38]] -> [ 0.62]\n",
      "[[ 0.01  0.01  0.11  0.48]\n",
      " [ 0.01  0.01  0.11  0.62]\n",
      " [ 0.01  0.    0.12  0.46]\n",
      " [ 0.01  0.    0.12  0.38]\n",
      " [ 0.01  0.    0.12  0.62]] -> [ 0.81]\n",
      "[[ 0.01  0.01  0.11  0.62]\n",
      " [ 0.01  0.    0.12  0.46]\n",
      " [ 0.01  0.    0.12  0.38]\n",
      " [ 0.01  0.    0.12  0.62]\n",
      " [ 0.01  0.    0.12  0.81]] -> [ 0.4]\n",
      "[[ 0.01  0.    0.12  0.46]\n",
      " [ 0.01  0.    0.12  0.38]\n",
      " [ 0.01  0.    0.12  0.62]\n",
      " [ 0.01  0.    0.12  0.81]\n",
      " [ 0.01  0.    0.12  0.4 ]] -> [ 0.45]\n",
      "[[ 0.01  0.    0.12  0.38]\n",
      " [ 0.01  0.    0.12  0.62]\n",
      " [ 0.01  0.    0.12  0.81]\n",
      " [ 0.01  0.    0.12  0.4 ]\n",
      " [ 0.01  0.01  0.12  0.45]] -> [ 0.42]\n",
      "[[ 0.01  0.    0.12  0.62]\n",
      " [ 0.01  0.    0.12  0.81]\n",
      " [ 0.01  0.    0.12  0.4 ]\n",
      " [ 0.01  0.01  0.12  0.45]\n",
      " [ 0.01  0.01  0.12  0.42]] -> [ 0.53]\n",
      "[[ 0.01  0.    0.12  0.81]\n",
      " [ 0.01  0.    0.12  0.4 ]\n",
      " [ 0.01  0.01  0.12  0.45]\n",
      " [ 0.01  0.01  0.12  0.42]\n",
      " [ 0.01  0.    0.13  0.53]] -> [ 0.53]\n",
      "[[ 0.01  0.    0.12  0.4 ]\n",
      " [ 0.01  0.01  0.12  0.45]\n",
      " [ 0.01  0.01  0.12  0.42]\n",
      " [ 0.01  0.    0.13  0.53]\n",
      " [ 0.01  0.    0.13  0.53]] -> [ 0.56]\n",
      "[[ 0.01  0.01  0.12  0.45]\n",
      " [ 0.01  0.01  0.12  0.42]\n",
      " [ 0.01  0.    0.13  0.53]\n",
      " [ 0.01  0.    0.13  0.53]\n",
      " [ 0.01  0.    0.13  0.56]] -> [ 0.53]\n",
      "[[ 0.01  0.01  0.12  0.42]\n",
      " [ 0.01  0.    0.13  0.53]\n",
      " [ 0.01  0.    0.13  0.53]\n",
      " [ 0.01  0.    0.13  0.56]\n",
      " [ 0.01  0.    0.13  0.53]] -> [ 0.47]\n",
      "[[ 0.01  0.    0.13  0.53]\n",
      " [ 0.01  0.    0.13  0.53]\n",
      " [ 0.01  0.    0.13  0.56]\n",
      " [ 0.01  0.    0.13  0.53]\n",
      " [ 0.01  0.    0.13  0.47]] -> [ 0.61]\n",
      "[[ 0.01  0.    0.13  0.53]\n",
      " [ 0.01  0.    0.13  0.56]\n",
      " [ 0.01  0.    0.13  0.53]\n",
      " [ 0.01  0.    0.13  0.47]\n",
      " [ 0.01  0.01  0.13  0.61]] -> [ 0.64]\n",
      "[[ 0.01  0.    0.13  0.56]\n",
      " [ 0.01  0.    0.13  0.53]\n",
      " [ 0.01  0.    0.13  0.47]\n",
      " [ 0.01  0.01  0.13  0.61]\n",
      " [ 0.01  0.01  0.13  0.64]] -> [ 0.62]\n",
      "[[ 0.01  0.    0.13  0.53]\n",
      " [ 0.01  0.    0.13  0.47]\n",
      " [ 0.01  0.01  0.13  0.61]\n",
      " [ 0.01  0.01  0.13  0.64]\n",
      " [ 0.01  0.    0.14  0.62]] -> [ 0.37]\n",
      "[[ 0.01  0.    0.13  0.47]\n",
      " [ 0.01  0.01  0.13  0.61]\n",
      " [ 0.01  0.01  0.13  0.64]\n",
      " [ 0.01  0.    0.14  0.62]\n",
      " [ 0.01  0.    0.14  0.37]] -> [ 0.65]\n",
      "[[ 0.01  0.01  0.13  0.61]\n",
      " [ 0.01  0.01  0.13  0.64]\n",
      " [ 0.01  0.    0.14  0.62]\n",
      " [ 0.01  0.    0.14  0.37]\n",
      " [ 0.01  0.    0.14  0.65]] -> [ 0.54]\n",
      "[[ 0.01  0.01  0.13  0.64]\n",
      " [ 0.01  0.    0.14  0.62]\n",
      " [ 0.01  0.    0.14  0.37]\n",
      " [ 0.01  0.    0.14  0.65]\n",
      " [ 0.01  0.    0.14  0.54]] -> [ 0.44]\n",
      "[[ 0.01  0.    0.14  0.62]\n",
      " [ 0.01  0.    0.14  0.37]\n",
      " [ 0.01  0.    0.14  0.65]\n",
      " [ 0.01  0.    0.14  0.54]\n",
      " [ 0.01  0.    0.14  0.44]] -> [ 0.46]\n",
      "[[ 0.01  0.    0.14  0.37]\n",
      " [ 0.01  0.    0.14  0.65]\n",
      " [ 0.01  0.    0.14  0.54]\n",
      " [ 0.01  0.    0.14  0.44]\n",
      " [ 0.01  0.01  0.14  0.46]] -> [ 0.5]\n",
      "[[ 0.01  0.    0.14  0.65]\n",
      " [ 0.01  0.    0.14  0.54]\n",
      " [ 0.01  0.    0.14  0.44]\n",
      " [ 0.01  0.01  0.14  0.46]\n",
      " [ 0.01  0.01  0.14  0.5 ]] -> [ 0.43]\n",
      "[[ 0.01  0.    0.14  0.54]\n",
      " [ 0.01  0.    0.14  0.44]\n",
      " [ 0.01  0.01  0.14  0.46]\n",
      " [ 0.01  0.01  0.14  0.5 ]\n",
      " [ 0.01  0.    0.15  0.43]] -> [ 0.53]\n",
      "[[ 0.01  0.    0.14  0.44]\n",
      " [ 0.01  0.01  0.14  0.46]\n",
      " [ 0.01  0.01  0.14  0.5 ]\n",
      " [ 0.01  0.    0.15  0.43]\n",
      " [ 0.01  0.    0.15  0.53]] -> [ 0.63]\n",
      "[[ 0.01  0.01  0.14  0.46]\n",
      " [ 0.01  0.01  0.14  0.5 ]\n",
      " [ 0.01  0.    0.15  0.43]\n",
      " [ 0.01  0.    0.15  0.53]\n",
      " [ 0.01  0.    0.15  0.63]] -> [ 0.52]\n",
      "[[ 0.01  0.01  0.14  0.5 ]\n",
      " [ 0.01  0.    0.15  0.43]\n",
      " [ 0.01  0.    0.15  0.53]\n",
      " [ 0.01  0.    0.15  0.63]\n",
      " [ 0.01  0.    0.15  0.52]] -> [ 0.02]\n",
      "[[ 0.01  0.    0.15  0.43]\n",
      " [ 0.01  0.    0.15  0.53]\n",
      " [ 0.01  0.    0.15  0.63]\n",
      " [ 0.01  0.    0.15  0.52]\n",
      " [ 0.01  0.    0.15  0.02]] -> [ 0.]\n",
      "[[ 0.01  0.    0.15  0.53]\n",
      " [ 0.01  0.    0.15  0.63]\n",
      " [ 0.01  0.    0.15  0.52]\n",
      " [ 0.01  0.    0.15  0.02]\n",
      " [ 0.01  0.01  0.15  0.  ]] -> [ 0.]\n",
      "[[ 0.01  0.    0.15  0.63]\n",
      " [ 0.01  0.    0.15  0.52]\n",
      " [ 0.01  0.    0.15  0.02]\n",
      " [ 0.01  0.01  0.15  0.  ]\n",
      " [ 0.01  0.01  0.15  0.  ]] -> [ 0.72]\n",
      "[[ 0.01  0.    0.15  0.52]\n",
      " [ 0.01  0.    0.15  0.02]\n",
      " [ 0.01  0.01  0.15  0.  ]\n",
      " [ 0.01  0.01  0.15  0.  ]\n",
      " [ 0.01  0.    0.16  0.72]] -> [ 0.59]\n",
      "[[ 0.01  0.    0.15  0.02]\n",
      " [ 0.01  0.01  0.15  0.  ]\n",
      " [ 0.01  0.01  0.15  0.  ]\n",
      " [ 0.01  0.    0.16  0.72]\n",
      " [ 0.01  0.    0.16  0.59]] -> [ 0.75]\n",
      "[[ 0.01  0.01  0.15  0.  ]\n",
      " [ 0.01  0.01  0.15  0.  ]\n",
      " [ 0.01  0.    0.16  0.72]\n",
      " [ 0.01  0.    0.16  0.59]\n",
      " [ 0.01  0.    0.16  0.75]] -> [ 0.47]\n",
      "[[ 0.01  0.01  0.15  0.  ]\n",
      " [ 0.01  0.    0.16  0.72]\n",
      " [ 0.01  0.    0.16  0.59]\n",
      " [ 0.01  0.    0.16  0.75]\n",
      " [ 0.01  0.    0.16  0.47]] -> [ 0.44]\n",
      "[[ 0.01  0.    0.16  0.72]\n",
      " [ 0.01  0.    0.16  0.59]\n",
      " [ 0.01  0.    0.16  0.75]\n",
      " [ 0.01  0.    0.16  0.47]\n",
      " [ 0.01  0.    0.16  0.44]] -> [ 0.77]\n",
      "[[ 0.01  0.    0.16  0.59]\n",
      " [ 0.01  0.    0.16  0.75]\n",
      " [ 0.01  0.    0.16  0.47]\n",
      " [ 0.01  0.    0.16  0.44]\n",
      " [ 0.01  0.01  0.16  0.77]] -> [ 0.9]\n",
      "[[ 0.01  0.    0.16  0.75]\n",
      " [ 0.01  0.    0.16  0.47]\n",
      " [ 0.01  0.    0.16  0.44]\n",
      " [ 0.01  0.01  0.16  0.77]\n",
      " [ 0.01  0.01  0.16  0.9 ]] -> [ 0.93]\n",
      "[[ 0.01  0.    0.16  0.47]\n",
      " [ 0.01  0.    0.16  0.44]\n",
      " [ 0.01  0.01  0.16  0.77]\n",
      " [ 0.01  0.01  0.16  0.9 ]\n",
      " [ 0.01  0.    0.17  0.93]] -> [ 0.47]\n",
      "[[ 0.01  0.    0.16  0.44]\n",
      " [ 0.01  0.01  0.16  0.77]\n",
      " [ 0.01  0.01  0.16  0.9 ]\n",
      " [ 0.01  0.    0.17  0.93]\n",
      " [ 0.01  0.    0.17  0.47]] -> [ 0.61]\n",
      "[[ 0.01  0.01  0.16  0.77]\n",
      " [ 0.01  0.01  0.16  0.9 ]\n",
      " [ 0.01  0.    0.17  0.93]\n",
      " [ 0.01  0.    0.17  0.47]\n",
      " [ 0.01  0.    0.17  0.61]] -> [ 0.77]\n",
      "[[ 0.01  0.01  0.16  0.9 ]\n",
      " [ 0.01  0.    0.17  0.93]\n",
      " [ 0.01  0.    0.17  0.47]\n",
      " [ 0.01  0.    0.17  0.61]\n",
      " [ 0.01  0.    0.17  0.77]] -> [ 0.35]\n",
      "[[ 0.01  0.    0.17  0.93]\n",
      " [ 0.01  0.    0.17  0.47]\n",
      " [ 0.01  0.    0.17  0.61]\n",
      " [ 0.01  0.    0.17  0.77]\n",
      " [ 0.01  0.    0.17  0.35]] -> [ 0.5]\n",
      "[[ 0.01  0.    0.17  0.47]\n",
      " [ 0.01  0.    0.17  0.61]\n",
      " [ 0.01  0.    0.17  0.77]\n",
      " [ 0.01  0.    0.17  0.35]\n",
      " [ 0.01  0.01  0.17  0.5 ]] -> [ 0.58]\n",
      "[[ 0.01  0.    0.17  0.61]\n",
      " [ 0.01  0.    0.17  0.77]\n",
      " [ 0.01  0.    0.17  0.35]\n",
      " [ 0.01  0.01  0.17  0.5 ]\n",
      " [ 0.01  0.01  0.17  0.58]] -> [ 0.33]\n",
      "[[ 0.01  0.    0.17  0.77]\n",
      " [ 0.01  0.    0.17  0.35]\n",
      " [ 0.01  0.01  0.17  0.5 ]\n",
      " [ 0.01  0.01  0.17  0.58]\n",
      " [ 0.01  0.    0.18  0.33]] -> [ 0.41]\n",
      "[[ 0.01  0.    0.17  0.35]\n",
      " [ 0.01  0.01  0.17  0.5 ]\n",
      " [ 0.01  0.01  0.17  0.58]\n",
      " [ 0.01  0.    0.18  0.33]\n",
      " [ 0.01  0.    0.18  0.41]] -> [ 0.36]\n",
      "[[ 0.01  0.01  0.17  0.5 ]\n",
      " [ 0.01  0.01  0.17  0.58]\n",
      " [ 0.01  0.    0.18  0.33]\n",
      " [ 0.01  0.    0.18  0.41]\n",
      " [ 0.01  0.    0.18  0.36]] -> [ 0.64]\n",
      "[[ 0.01  0.01  0.17  0.58]\n",
      " [ 0.01  0.    0.18  0.33]\n",
      " [ 0.01  0.    0.18  0.41]\n",
      " [ 0.01  0.    0.18  0.36]\n",
      " [ 0.01  0.    0.18  0.64]] -> [ 0.49]\n",
      "[[ 0.01  0.    0.18  0.33]\n",
      " [ 0.01  0.    0.18  0.41]\n",
      " [ 0.01  0.    0.18  0.36]\n",
      " [ 0.01  0.    0.18  0.64]\n",
      " [ 0.01  0.    0.18  0.49]] -> [ 0.53]\n",
      "[[ 0.01  0.    0.18  0.41]\n",
      " [ 0.01  0.    0.18  0.36]\n",
      " [ 0.01  0.    0.18  0.64]\n",
      " [ 0.01  0.    0.18  0.49]\n",
      " [ 0.01  0.01  0.18  0.53]] -> [ 0.6]\n",
      "[[ 0.01  0.    0.18  0.36]\n",
      " [ 0.01  0.    0.18  0.64]\n",
      " [ 0.01  0.    0.18  0.49]\n",
      " [ 0.01  0.01  0.18  0.53]\n",
      " [ 0.01  0.01  0.18  0.6 ]] -> [ 0.43]\n",
      "[[ 0.01  0.    0.18  0.64]\n",
      " [ 0.01  0.    0.18  0.49]\n",
      " [ 0.01  0.01  0.18  0.53]\n",
      " [ 0.01  0.01  0.18  0.6 ]\n",
      " [ 0.01  0.    0.19  0.43]] -> [ 0.41]\n",
      "[[ 0.01  0.    0.18  0.49]\n",
      " [ 0.01  0.01  0.18  0.53]\n",
      " [ 0.01  0.01  0.18  0.6 ]\n",
      " [ 0.01  0.    0.19  0.43]\n",
      " [ 0.01  0.    0.19  0.41]] -> [ 0.55]\n",
      "[[ 0.01  0.01  0.18  0.53]\n",
      " [ 0.01  0.01  0.18  0.6 ]\n",
      " [ 0.01  0.    0.19  0.43]\n",
      " [ 0.01  0.    0.19  0.41]\n",
      " [ 0.01  0.    0.19  0.55]] -> [ 0.45]\n",
      "[[ 0.01  0.01  0.18  0.6 ]\n",
      " [ 0.01  0.    0.19  0.43]\n",
      " [ 0.01  0.    0.19  0.41]\n",
      " [ 0.01  0.    0.19  0.55]\n",
      " [ 0.01  0.    0.19  0.45]] -> [ 0.18]\n",
      "[[ 0.01  0.    0.19  0.43]\n",
      " [ 0.01  0.    0.19  0.41]\n",
      " [ 0.01  0.    0.19  0.55]\n",
      " [ 0.01  0.    0.19  0.45]\n",
      " [ 0.01  0.    0.19  0.18]] -> [ 0.6]\n",
      "[[ 0.01  0.    0.19  0.41]\n",
      " [ 0.01  0.    0.19  0.55]\n",
      " [ 0.01  0.    0.19  0.45]\n",
      " [ 0.01  0.    0.19  0.18]\n",
      " [ 0.01  0.01  0.19  0.6 ]] -> [ 0.69]\n",
      "[[ 0.01  0.    0.19  0.55]\n",
      " [ 0.01  0.    0.19  0.45]\n",
      " [ 0.01  0.    0.19  0.18]\n",
      " [ 0.01  0.01  0.19  0.6 ]\n",
      " [ 0.01  0.01  0.19  0.69]] -> [ 0.54]\n",
      "[[ 0.01  0.    0.19  0.45]\n",
      " [ 0.01  0.    0.19  0.18]\n",
      " [ 0.01  0.01  0.19  0.6 ]\n",
      " [ 0.01  0.01  0.19  0.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.01  0.    0.2   0.54]] -> [ 0.39]\n",
      "[[ 0.01  0.    0.19  0.18]\n",
      " [ 0.01  0.01  0.19  0.6 ]\n",
      " [ 0.01  0.01  0.19  0.69]\n",
      " [ 0.01  0.    0.2   0.54]\n",
      " [ 0.01  0.    0.2   0.39]] -> [ 0.5]\n",
      "[[ 0.01  0.01  0.19  0.6 ]\n",
      " [ 0.01  0.01  0.19  0.69]\n",
      " [ 0.01  0.    0.2   0.54]\n",
      " [ 0.01  0.    0.2   0.39]\n",
      " [ 0.01  0.    0.2   0.5 ]] -> [ 0.44]\n",
      "[[ 0.01  0.01  0.19  0.69]\n",
      " [ 0.01  0.    0.2   0.54]\n",
      " [ 0.01  0.    0.2   0.39]\n",
      " [ 0.01  0.    0.2   0.5 ]\n",
      " [ 0.01  0.    0.2   0.44]] -> [ 0.54]\n",
      "[[ 0.01  0.    0.2   0.54]\n",
      " [ 0.01  0.    0.2   0.39]\n",
      " [ 0.01  0.    0.2   0.5 ]\n",
      " [ 0.01  0.    0.2   0.44]\n",
      " [ 0.01  0.    0.2   0.54]] -> [ 0.57]\n",
      "[[ 0.01  0.    0.2   0.39]\n",
      " [ 0.01  0.    0.2   0.5 ]\n",
      " [ 0.01  0.    0.2   0.44]\n",
      " [ 0.01  0.    0.2   0.54]\n",
      " [ 0.01  0.01  0.2   0.57]] -> [ 0.82]\n",
      "[[ 0.01  0.    0.2   0.5 ]\n",
      " [ 0.01  0.    0.2   0.44]\n",
      " [ 0.01  0.    0.2   0.54]\n",
      " [ 0.01  0.01  0.2   0.57]\n",
      " [ 0.01  0.01  0.2   0.82]] -> [ 0.57]\n",
      "[[ 0.01  0.    0.2   0.44]\n",
      " [ 0.01  0.    0.2   0.54]\n",
      " [ 0.01  0.01  0.2   0.57]\n",
      " [ 0.01  0.01  0.2   0.82]\n",
      " [ 0.01  0.    0.21  0.57]] -> [ 0.44]\n",
      "[[ 0.01  0.    0.2   0.54]\n",
      " [ 0.01  0.01  0.2   0.57]\n",
      " [ 0.01  0.01  0.2   0.82]\n",
      " [ 0.01  0.    0.21  0.57]\n",
      " [ 0.01  0.    0.21  0.44]] -> [ 0.56]\n",
      "[[ 0.01  0.01  0.2   0.57]\n",
      " [ 0.01  0.01  0.2   0.82]\n",
      " [ 0.01  0.    0.21  0.57]\n",
      " [ 0.01  0.    0.21  0.44]\n",
      " [ 0.01  0.    0.21  0.56]] -> [ 0.51]\n",
      "[[ 0.01  0.01  0.2   0.82]\n",
      " [ 0.01  0.    0.21  0.57]\n",
      " [ 0.01  0.    0.21  0.44]\n",
      " [ 0.01  0.    0.21  0.56]\n",
      " [ 0.01  0.    0.21  0.51]] -> [ 0.55]\n",
      "[[ 0.01  0.    0.21  0.57]\n",
      " [ 0.01  0.    0.21  0.44]\n",
      " [ 0.01  0.    0.21  0.56]\n",
      " [ 0.01  0.    0.21  0.51]\n",
      " [ 0.01  0.    0.21  0.55]] -> [ 0.28]\n",
      "[[ 0.01  0.    0.21  0.44]\n",
      " [ 0.01  0.    0.21  0.56]\n",
      " [ 0.01  0.    0.21  0.51]\n",
      " [ 0.01  0.    0.21  0.55]\n",
      " [ 0.01  0.01  0.21  0.28]] -> [ 0.56]\n",
      "[[ 0.01  0.    0.21  0.56]\n",
      " [ 0.01  0.    0.21  0.51]\n",
      " [ 0.01  0.    0.21  0.55]\n",
      " [ 0.01  0.01  0.21  0.28]\n",
      " [ 0.01  0.01  0.21  0.56]] -> [ 0.54]\n",
      "[[ 0.01  0.    0.21  0.51]\n",
      " [ 0.01  0.    0.21  0.55]\n",
      " [ 0.01  0.01  0.21  0.28]\n",
      " [ 0.01  0.01  0.21  0.56]\n",
      " [ 0.01  0.    0.22  0.54]] -> [ 0.36]\n",
      "[[ 0.01  0.    0.21  0.55]\n",
      " [ 0.01  0.01  0.21  0.28]\n",
      " [ 0.01  0.01  0.21  0.56]\n",
      " [ 0.01  0.    0.22  0.54]\n",
      " [ 0.01  0.    0.22  0.36]] -> [ 0.12]\n",
      "[[ 0.01  0.01  0.21  0.28]\n",
      " [ 0.01  0.01  0.21  0.56]\n",
      " [ 0.01  0.    0.22  0.54]\n",
      " [ 0.01  0.    0.22  0.36]\n",
      " [ 0.02  0.    0.22  0.12]] -> [ 0.25]\n",
      "[[ 0.01  0.01  0.21  0.56]\n",
      " [ 0.01  0.    0.22  0.54]\n",
      " [ 0.01  0.    0.22  0.36]\n",
      " [ 0.02  0.    0.22  0.12]\n",
      " [ 0.02  0.    0.22  0.25]] -> [ 0.41]\n",
      "[[ 0.01  0.    0.22  0.54]\n",
      " [ 0.01  0.    0.22  0.36]\n",
      " [ 0.02  0.    0.22  0.12]\n",
      " [ 0.02  0.    0.22  0.25]\n",
      " [ 0.02  0.    0.22  0.41]] -> [ 0.11]\n",
      "[[ 0.01  0.    0.22  0.36]\n",
      " [ 0.02  0.    0.22  0.12]\n",
      " [ 0.02  0.    0.22  0.25]\n",
      " [ 0.02  0.    0.22  0.41]\n",
      " [ 0.02  0.01  0.22  0.11]] -> [ 0.06]\n",
      "[[ 0.02  0.    0.22  0.12]\n",
      " [ 0.02  0.    0.22  0.25]\n",
      " [ 0.02  0.    0.22  0.41]\n",
      " [ 0.02  0.01  0.22  0.11]\n",
      " [ 0.02  0.01  0.22  0.06]] -> [ 0.09]\n",
      "[[ 0.02  0.    0.22  0.25]\n",
      " [ 0.02  0.    0.22  0.41]\n",
      " [ 0.02  0.01  0.22  0.11]\n",
      " [ 0.02  0.01  0.22  0.06]\n",
      " [ 0.02  0.    0.23  0.09]] -> [ 0.35]\n",
      "[[ 0.02  0.    0.22  0.41]\n",
      " [ 0.02  0.01  0.22  0.11]\n",
      " [ 0.02  0.01  0.22  0.06]\n",
      " [ 0.02  0.    0.23  0.09]\n",
      " [ 0.02  0.    0.23  0.35]] -> [ 0.29]\n",
      "[[ 0.02  0.01  0.22  0.11]\n",
      " [ 0.02  0.01  0.22  0.06]\n",
      " [ 0.02  0.    0.23  0.09]\n",
      " [ 0.02  0.    0.23  0.35]\n",
      " [ 0.02  0.    0.23  0.29]] -> [ 0.24]\n",
      "[[ 0.02  0.01  0.22  0.06]\n",
      " [ 0.02  0.    0.23  0.09]\n",
      " [ 0.02  0.    0.23  0.35]\n",
      " [ 0.02  0.    0.23  0.29]\n",
      " [ 0.02  0.    0.23  0.24]] -> [ 0.23]\n",
      "[[ 0.02  0.    0.23  0.09]\n",
      " [ 0.02  0.    0.23  0.35]\n",
      " [ 0.02  0.    0.23  0.29]\n",
      " [ 0.02  0.    0.23  0.24]\n",
      " [ 0.02  0.    0.23  0.23]] -> [ 0.14]\n",
      "[[ 0.02  0.    0.23  0.35]\n",
      " [ 0.02  0.    0.23  0.29]\n",
      " [ 0.02  0.    0.23  0.24]\n",
      " [ 0.02  0.    0.23  0.23]\n",
      " [ 0.02  0.01  0.23  0.14]] -> [ 0.21]\n",
      "[[ 0.02  0.    0.23  0.29]\n",
      " [ 0.02  0.    0.23  0.24]\n",
      " [ 0.02  0.    0.23  0.23]\n",
      " [ 0.02  0.01  0.23  0.14]\n",
      " [ 0.02  0.01  0.23  0.21]] -> [ 0.2]\n",
      "[[ 0.02  0.    0.23  0.24]\n",
      " [ 0.02  0.    0.23  0.23]\n",
      " [ 0.02  0.01  0.23  0.14]\n",
      " [ 0.02  0.01  0.23  0.21]\n",
      " [ 0.02  0.    0.24  0.2 ]] -> [ 0.25]\n",
      "[[ 0.02  0.    0.23  0.23]\n",
      " [ 0.02  0.01  0.23  0.14]\n",
      " [ 0.02  0.01  0.23  0.21]\n",
      " [ 0.02  0.    0.24  0.2 ]\n",
      " [ 0.02  0.    0.24  0.25]] -> [ 0.23]\n",
      "[[ 0.02  0.01  0.23  0.14]\n",
      " [ 0.02  0.01  0.23  0.21]\n",
      " [ 0.02  0.    0.24  0.2 ]\n",
      " [ 0.02  0.    0.24  0.25]\n",
      " [ 0.02  0.    0.24  0.23]] -> [ 0.27]\n",
      "[[ 0.02  0.01  0.23  0.21]\n",
      " [ 0.02  0.    0.24  0.2 ]\n",
      " [ 0.02  0.    0.24  0.25]\n",
      " [ 0.02  0.    0.24  0.23]\n",
      " [ 0.02  0.    0.24  0.27]] -> [ 0.31]\n",
      "[[ 0.02  0.    0.24  0.2 ]\n",
      " [ 0.02  0.    0.24  0.25]\n",
      " [ 0.02  0.    0.24  0.23]\n",
      " [ 0.02  0.    0.24  0.27]\n",
      " [ 0.02  0.    0.24  0.31]] -> [ 0.16]\n",
      "[[ 0.02  0.    0.24  0.25]\n",
      " [ 0.02  0.    0.24  0.23]\n",
      " [ 0.02  0.    0.24  0.27]\n",
      " [ 0.02  0.    0.24  0.31]\n",
      " [ 0.02  0.01  0.24  0.16]] -> [ 0.14]\n",
      "[[ 0.02  0.    0.24  0.23]\n",
      " [ 0.02  0.    0.24  0.27]\n",
      " [ 0.02  0.    0.24  0.31]\n",
      " [ 0.02  0.01  0.24  0.16]\n",
      " [ 0.02  0.01  0.24  0.14]] -> [ 0.3]\n",
      "[[ 0.02  0.    0.24  0.27]\n",
      " [ 0.02  0.    0.24  0.31]\n",
      " [ 0.02  0.01  0.24  0.16]\n",
      " [ 0.02  0.01  0.24  0.14]\n",
      " [ 0.02  0.    0.25  0.3 ]] -> [ 0.32]\n",
      "[[ 0.02  0.    0.24  0.31]\n",
      " [ 0.02  0.01  0.24  0.16]\n",
      " [ 0.02  0.01  0.24  0.14]\n",
      " [ 0.02  0.    0.25  0.3 ]\n",
      " [ 0.02  0.    0.25  0.32]] -> [ 0.75]\n",
      "[[ 0.02  0.01  0.24  0.16]\n",
      " [ 0.02  0.01  0.24  0.14]\n",
      " [ 0.02  0.    0.25  0.3 ]\n",
      " [ 0.02  0.    0.25  0.32]\n",
      " [ 0.02  0.    0.25  0.75]] -> [ 0.35]\n",
      "[[ 0.02  0.01  0.24  0.14]\n",
      " [ 0.02  0.    0.25  0.3 ]\n",
      " [ 0.02  0.    0.25  0.32]\n",
      " [ 0.02  0.    0.25  0.75]\n",
      " [ 0.02  0.    0.25  0.35]] -> [ 0.26]\n",
      "[[ 0.02  0.    0.25  0.3 ]\n",
      " [ 0.02  0.    0.25  0.32]\n",
      " [ 0.02  0.    0.25  0.75]\n",
      " [ 0.02  0.    0.25  0.35]\n",
      " [ 0.02  0.    0.25  0.26]] -> [ 0.12]\n",
      "[[ 0.02  0.    0.25  0.32]\n",
      " [ 0.02  0.    0.25  0.75]\n",
      " [ 0.02  0.    0.25  0.35]\n",
      " [ 0.02  0.    0.25  0.26]\n",
      " [ 0.02  0.01  0.25  0.12]] -> [ 0.21]\n",
      "[[ 0.02  0.    0.25  0.75]\n",
      " [ 0.02  0.    0.25  0.35]\n",
      " [ 0.02  0.    0.25  0.26]\n",
      " [ 0.02  0.01  0.25  0.12]\n",
      " [ 0.02  0.01  0.25  0.21]] -> [ 0.23]\n",
      "[[ 0.02  0.    0.25  0.35]\n",
      " [ 0.02  0.    0.25  0.26]\n",
      " [ 0.02  0.01  0.25  0.12]\n",
      " [ 0.02  0.01  0.25  0.21]\n",
      " [ 0.02  0.    0.26  0.23]] -> [ 0.28]\n",
      "[[ 0.02  0.    0.25  0.26]\n",
      " [ 0.02  0.01  0.25  0.12]\n",
      " [ 0.02  0.01  0.25  0.21]\n",
      " [ 0.02  0.    0.26  0.23]\n",
      " [ 0.02  0.    0.26  0.28]] -> [ 0.25]\n",
      "[[ 0.02  0.01  0.25  0.12]\n",
      " [ 0.02  0.01  0.25  0.21]\n",
      " [ 0.02  0.    0.26  0.23]\n",
      " [ 0.02  0.    0.26  0.28]\n",
      " [ 0.02  0.    0.26  0.25]] -> [ 0.31]\n",
      "[[ 0.02  0.01  0.25  0.21]\n",
      " [ 0.02  0.    0.26  0.23]\n",
      " [ 0.02  0.    0.26  0.28]\n",
      " [ 0.02  0.    0.26  0.25]\n",
      " [ 0.02  0.    0.26  0.31]] -> [ 0.21]\n",
      "[[ 0.02  0.    0.26  0.23]\n",
      " [ 0.02  0.    0.26  0.28]\n",
      " [ 0.02  0.    0.26  0.25]\n",
      " [ 0.02  0.    0.26  0.31]\n",
      " [ 0.02  0.    0.26  0.21]] -> [ 0.17]\n",
      "[[ 0.02  0.    0.26  0.28]\n",
      " [ 0.02  0.    0.26  0.25]\n",
      " [ 0.02  0.    0.26  0.31]\n",
      " [ 0.02  0.    0.26  0.21]\n",
      " [ 0.02  0.01  0.26  0.17]] -> [ 0.1]\n",
      "[[ 0.02  0.    0.26  0.25]\n",
      " [ 0.02  0.    0.26  0.31]\n",
      " [ 0.02  0.    0.26  0.21]\n",
      " [ 0.02  0.01  0.26  0.17]\n",
      " [ 0.02  0.01  0.26  0.1 ]] -> [ 0.29]\n",
      "[[ 0.02  0.    0.26  0.31]\n",
      " [ 0.02  0.    0.26  0.21]\n",
      " [ 0.02  0.01  0.26  0.17]\n",
      " [ 0.02  0.01  0.26  0.1 ]\n",
      " [ 0.02  0.    0.27  0.29]] -> [ 0.34]\n",
      "[[ 0.02  0.    0.26  0.21]\n",
      " [ 0.02  0.01  0.26  0.17]\n",
      " [ 0.02  0.01  0.26  0.1 ]\n",
      " [ 0.02  0.    0.27  0.29]\n",
      " [ 0.02  0.    0.27  0.34]] -> [ 0.28]\n",
      "[[ 0.02  0.01  0.26  0.17]\n",
      " [ 0.02  0.01  0.26  0.1 ]\n",
      " [ 0.02  0.    0.27  0.29]\n",
      " [ 0.02  0.    0.27  0.34]\n",
      " [ 0.02  0.    0.27  0.28]] -> [ 0.2]\n",
      "[[ 0.02  0.01  0.26  0.1 ]\n",
      " [ 0.02  0.    0.27  0.29]\n",
      " [ 0.02  0.    0.27  0.34]\n",
      " [ 0.02  0.    0.27  0.28]\n",
      " [ 0.02  0.    0.27  0.2 ]] -> [ 0.36]\n",
      "[[ 0.02  0.    0.27  0.29]\n",
      " [ 0.02  0.    0.27  0.34]\n",
      " [ 0.02  0.    0.27  0.28]\n",
      " [ 0.02  0.    0.27  0.2 ]\n",
      " [ 0.02  0.    0.27  0.36]] -> [ 0.23]\n",
      "[[ 0.02  0.    0.27  0.34]\n",
      " [ 0.02  0.    0.27  0.28]\n",
      " [ 0.02  0.    0.27  0.2 ]\n",
      " [ 0.02  0.    0.27  0.36]\n",
      " [ 0.02  0.01  0.27  0.23]] -> [ 0.15]\n",
      "[[ 0.02  0.    0.27  0.28]\n",
      " [ 0.02  0.    0.27  0.2 ]\n",
      " [ 0.02  0.    0.27  0.36]\n",
      " [ 0.02  0.01  0.27  0.23]\n",
      " [ 0.02  0.01  0.27  0.15]] -> [ 0.42]\n",
      "[[ 0.02  0.    0.27  0.2 ]\n",
      " [ 0.02  0.    0.27  0.36]\n",
      " [ 0.02  0.01  0.27  0.23]\n",
      " [ 0.02  0.01  0.27  0.15]\n",
      " [ 0.02  0.    0.28  0.42]] -> [ 0.28]\n",
      "[[ 0.02  0.    0.27  0.36]\n",
      " [ 0.02  0.01  0.27  0.23]\n",
      " [ 0.02  0.01  0.27  0.15]\n",
      " [ 0.02  0.    0.28  0.42]\n",
      " [ 0.02  0.    0.28  0.28]] -> [ 0.24]\n",
      "[[ 0.02  0.01  0.27  0.23]\n",
      " [ 0.02  0.01  0.27  0.15]\n",
      " [ 0.02  0.    0.28  0.42]\n",
      " [ 0.02  0.    0.28  0.28]\n",
      " [ 0.02  0.    0.28  0.24]] -> [ 0.29]\n",
      "[[ 0.02  0.01  0.27  0.15]\n",
      " [ 0.02  0.    0.28  0.42]\n",
      " [ 0.02  0.    0.28  0.28]\n",
      " [ 0.02  0.    0.28  0.24]\n",
      " [ 0.02  0.    0.28  0.29]] -> [ 0.2]\n",
      "[[ 0.02  0.    0.28  0.42]\n",
      " [ 0.02  0.    0.28  0.28]\n",
      " [ 0.02  0.    0.28  0.24]\n",
      " [ 0.02  0.    0.28  0.29]\n",
      " [ 0.02  0.    0.28  0.2 ]] -> [ 0.14]\n",
      "[[ 0.02  0.    0.28  0.28]\n",
      " [ 0.02  0.    0.28  0.24]\n",
      " [ 0.02  0.    0.28  0.29]\n",
      " [ 0.02  0.    0.28  0.2 ]\n",
      " [ 0.02  0.01  0.28  0.14]] -> [ 0.18]\n",
      "[[ 0.02  0.    0.28  0.24]\n",
      " [ 0.02  0.    0.28  0.29]\n",
      " [ 0.02  0.    0.28  0.2 ]\n",
      " [ 0.02  0.01  0.28  0.14]\n",
      " [ 0.02  0.01  0.28  0.18]] -> [ 0.27]\n",
      "[[ 0.02  0.    0.28  0.29]\n",
      " [ 0.02  0.    0.28  0.2 ]\n",
      " [ 0.02  0.01  0.28  0.14]\n",
      " [ 0.02  0.01  0.28  0.18]\n",
      " [ 0.02  0.    0.29  0.27]] -> [ 0.22]\n",
      "[[ 0.02  0.    0.28  0.2 ]\n",
      " [ 0.02  0.01  0.28  0.14]\n",
      " [ 0.02  0.01  0.28  0.18]\n",
      " [ 0.02  0.    0.29  0.27]\n",
      " [ 0.02  0.    0.29  0.22]] -> [ 0.31]\n",
      "[[ 0.02  0.01  0.28  0.14]\n",
      " [ 0.02  0.01  0.28  0.18]\n",
      " [ 0.02  0.    0.29  0.27]\n",
      " [ 0.02  0.    0.29  0.22]\n",
      " [ 0.02  0.    0.29  0.31]] -> [ 0.24]\n",
      "[[ 0.02  0.01  0.28  0.18]\n",
      " [ 0.02  0.    0.29  0.27]\n",
      " [ 0.02  0.    0.29  0.22]\n",
      " [ 0.02  0.    0.29  0.31]\n",
      " [ 0.02  0.    0.29  0.24]] -> [ 0.39]\n",
      "[[ 0.02  0.    0.29  0.27]\n",
      " [ 0.02  0.    0.29  0.22]\n",
      " [ 0.02  0.    0.29  0.31]\n",
      " [ 0.02  0.    0.29  0.24]\n",
      " [ 0.02  0.    0.29  0.39]] -> [ 0.31]\n",
      "[[ 0.02  0.    0.29  0.22]\n",
      " [ 0.02  0.    0.29  0.31]\n",
      " [ 0.02  0.    0.29  0.24]\n",
      " [ 0.02  0.    0.29  0.39]\n",
      " [ 0.02  0.01  0.29  0.31]] -> [ 0.17]\n",
      "[[ 0.02  0.    0.29  0.31]\n",
      " [ 0.02  0.    0.29  0.24]\n",
      " [ 0.02  0.    0.29  0.39]\n",
      " [ 0.02  0.01  0.29  0.31]\n",
      " [ 0.02  0.01  0.29  0.17]] -> [ 0.42]\n",
      "[[ 0.02  0.    0.29  0.24]\n",
      " [ 0.02  0.    0.29  0.39]\n",
      " [ 0.02  0.01  0.29  0.31]\n",
      " [ 0.02  0.01  0.29  0.17]\n",
      " [ 0.02  0.    0.3   0.42]] -> [ 0.29]\n",
      "[[ 0.02  0.    0.29  0.39]\n",
      " [ 0.02  0.01  0.29  0.31]\n",
      " [ 0.02  0.01  0.29  0.17]\n",
      " [ 0.02  0.    0.3   0.42]\n",
      " [ 0.02  0.    0.3   0.29]] -> [ 0.33]\n",
      "[[ 0.02  0.01  0.29  0.31]\n",
      " [ 0.02  0.01  0.29  0.17]\n",
      " [ 0.02  0.    0.3   0.42]\n",
      " [ 0.02  0.    0.3   0.29]\n",
      " [ 0.02  0.    0.3   0.33]] -> [ 0.22]\n",
      "[[ 0.02  0.01  0.29  0.17]\n",
      " [ 0.02  0.    0.3   0.42]\n",
      " [ 0.02  0.    0.3   0.29]\n",
      " [ 0.02  0.    0.3   0.33]\n",
      " [ 0.02  0.    0.3   0.22]] -> [ 0.39]\n",
      "[[ 0.02  0.    0.3   0.42]\n",
      " [ 0.02  0.    0.3   0.29]\n",
      " [ 0.02  0.    0.3   0.33]\n",
      " [ 0.02  0.    0.3   0.22]\n",
      " [ 0.02  0.    0.3   0.39]] -> [ 0.25]\n",
      "[[ 0.02  0.    0.3   0.29]\n",
      " [ 0.02  0.    0.3   0.33]\n",
      " [ 0.02  0.    0.3   0.22]\n",
      " [ 0.02  0.    0.3   0.39]\n",
      " [ 0.02  0.01  0.3   0.25]] -> [ 0.23]\n",
      "[[ 0.02  0.    0.3   0.33]\n",
      " [ 0.02  0.    0.3   0.22]\n",
      " [ 0.02  0.    0.3   0.39]\n",
      " [ 0.02  0.01  0.3   0.25]\n",
      " [ 0.02  0.01  0.3   0.23]] -> [ 0.25]\n",
      "[[ 0.02  0.    0.3   0.22]\n",
      " [ 0.02  0.    0.3   0.39]\n",
      " [ 0.02  0.01  0.3   0.25]\n",
      " [ 0.02  0.01  0.3   0.23]\n",
      " [ 0.02  0.    0.31  0.25]] -> [ 0.21]\n",
      "[[ 0.02  0.    0.3   0.39]\n",
      " [ 0.02  0.01  0.3   0.25]\n",
      " [ 0.02  0.01  0.3   0.23]\n",
      " [ 0.02  0.    0.31  0.25]\n",
      " [ 0.02  0.    0.31  0.21]] -> [ 0.18]\n",
      "[[ 0.02  0.01  0.3   0.25]\n",
      " [ 0.02  0.01  0.3   0.23]\n",
      " [ 0.02  0.    0.31  0.25]\n",
      " [ 0.02  0.    0.31  0.21]\n",
      " [ 0.02  0.    0.31  0.18]] -> [ 0.24]\n",
      "[[ 0.02  0.01  0.3   0.23]\n",
      " [ 0.02  0.    0.31  0.25]\n",
      " [ 0.02  0.    0.31  0.21]\n",
      " [ 0.02  0.    0.31  0.18]\n",
      " [ 0.02  0.    0.31  0.24]] -> [ 0.24]\n",
      "[[ 0.02  0.    0.31  0.25]\n",
      " [ 0.02  0.    0.31  0.21]\n",
      " [ 0.02  0.    0.31  0.18]\n",
      " [ 0.02  0.    0.31  0.24]\n",
      " [ 0.02  0.    0.31  0.24]] -> [ 0.2]\n",
      "[[ 0.02  0.    0.31  0.21]\n",
      " [ 0.02  0.    0.31  0.18]\n",
      " [ 0.02  0.    0.31  0.24]\n",
      " [ 0.02  0.    0.31  0.24]\n",
      " [ 0.02  0.01  0.31  0.2 ]] -> [ 0.09]\n",
      "[[ 0.02  0.    0.31  0.18]\n",
      " [ 0.02  0.    0.31  0.24]\n",
      " [ 0.02  0.    0.31  0.24]\n",
      " [ 0.02  0.01  0.31  0.2 ]\n",
      " [ 0.02  0.01  0.31  0.09]] -> [ 0.31]\n",
      "[[ 0.02  0.    0.31  0.24]\n",
      " [ 0.02  0.    0.31  0.24]\n",
      " [ 0.02  0.01  0.31  0.2 ]\n",
      " [ 0.02  0.01  0.31  0.09]\n",
      " [ 0.02  0.    0.32  0.31]] -> [ 0.33]\n",
      "[[ 0.02  0.    0.31  0.24]\n",
      " [ 0.02  0.01  0.31  0.2 ]\n",
      " [ 0.02  0.01  0.31  0.09]\n",
      " [ 0.02  0.    0.32  0.31]\n",
      " [ 0.02  0.    0.32  0.33]] -> [ 0.33]\n",
      "[[ 0.02  0.01  0.31  0.2 ]\n",
      " [ 0.02  0.01  0.31  0.09]\n",
      " [ 0.02  0.    0.32  0.31]\n",
      " [ 0.02  0.    0.32  0.33]\n",
      " [ 0.02  0.    0.32  0.33]] -> [ 0.31]\n",
      "[[ 0.02  0.01  0.31  0.09]\n",
      " [ 0.02  0.    0.32  0.31]\n",
      " [ 0.02  0.    0.32  0.33]\n",
      " [ 0.02  0.    0.32  0.33]\n",
      " [ 0.02  0.    0.32  0.31]] -> [ 0.27]\n",
      "[[ 0.02  0.    0.32  0.31]\n",
      " [ 0.02  0.    0.32  0.33]\n",
      " [ 0.02  0.    0.32  0.33]\n",
      " [ 0.02  0.    0.32  0.31]\n",
      " [ 0.02  0.    0.32  0.27]] -> [ 0.35]\n",
      "[[ 0.02  0.    0.32  0.33]\n",
      " [ 0.02  0.    0.32  0.33]\n",
      " [ 0.02  0.    0.32  0.31]\n",
      " [ 0.02  0.    0.32  0.27]\n",
      " [ 0.02  0.01  0.32  0.35]] -> [ 0.15]\n",
      "[[ 0.02  0.    0.32  0.33]\n",
      " [ 0.02  0.    0.32  0.31]\n",
      " [ 0.02  0.    0.32  0.27]\n",
      " [ 0.02  0.01  0.32  0.35]\n",
      " [ 0.02  0.01  0.32  0.15]] -> [ 0.25]\n",
      "[[ 0.02  0.    0.32  0.31]\n",
      " [ 0.02  0.    0.32  0.27]\n",
      " [ 0.02  0.01  0.32  0.35]\n",
      " [ 0.02  0.01  0.32  0.15]\n",
      " [ 0.02  0.    0.33  0.25]] -> [ 0.32]\n",
      "[[ 0.02  0.    0.32  0.27]\n",
      " [ 0.02  0.01  0.32  0.35]\n",
      " [ 0.02  0.01  0.32  0.15]\n",
      " [ 0.02  0.    0.33  0.25]\n",
      " [ 0.02  0.    0.33  0.32]] -> [ 0.29]\n",
      "[[ 0.02  0.01  0.32  0.35]\n",
      " [ 0.02  0.01  0.32  0.15]\n",
      " [ 0.02  0.    0.33  0.25]\n",
      " [ 0.02  0.    0.33  0.32]\n",
      " [ 0.02  0.    0.33  0.29]] -> [ 0.32]\n",
      "[[ 0.02  0.01  0.32  0.15]\n",
      " [ 0.02  0.    0.33  0.25]\n",
      " [ 0.02  0.    0.33  0.32]\n",
      " [ 0.02  0.    0.33  0.29]\n",
      " [ 0.02  0.    0.33  0.32]] -> [ 0.21]\n",
      "[[ 0.02  0.    0.33  0.25]\n",
      " [ 0.02  0.    0.33  0.32]\n",
      " [ 0.02  0.    0.33  0.29]\n",
      " [ 0.02  0.    0.33  0.32]\n",
      " [ 0.02  0.    0.33  0.21]] -> [ 0.92]\n",
      "[[ 0.02  0.    0.33  0.32]\n",
      " [ 0.02  0.    0.33  0.29]\n",
      " [ 0.02  0.    0.33  0.32]\n",
      " [ 0.02  0.    0.33  0.21]\n",
      " [ 0.02  0.01  0.33  0.92]] -> [ 0.19]\n",
      "[[ 0.02  0.    0.33  0.29]\n",
      " [ 0.02  0.    0.33  0.32]\n",
      " [ 0.02  0.    0.33  0.21]\n",
      " [ 0.02  0.01  0.33  0.92]\n",
      " [ 0.02  0.01  0.33  0.19]] -> [ 0.37]\n",
      "[[ 0.02  0.    0.33  0.32]\n",
      " [ 0.02  0.    0.33  0.21]\n",
      " [ 0.02  0.01  0.33  0.92]\n",
      " [ 0.02  0.01  0.33  0.19]\n",
      " [ 0.02  0.    0.34  0.37]] -> [ 0.29]\n",
      "[[ 0.02  0.    0.33  0.21]\n",
      " [ 0.02  0.01  0.33  0.92]\n",
      " [ 0.02  0.01  0.33  0.19]\n",
      " [ 0.02  0.    0.34  0.37]\n",
      " [ 0.02  0.    0.34  0.29]] -> [ 0.33]\n",
      "[[ 0.02  0.01  0.33  0.92]\n",
      " [ 0.02  0.01  0.33  0.19]\n",
      " [ 0.02  0.    0.34  0.37]\n",
      " [ 0.02  0.    0.34  0.29]\n",
      " [ 0.02  0.    0.34  0.33]] -> [ 0.16]\n",
      "[[ 0.02  0.01  0.33  0.19]\n",
      " [ 0.02  0.    0.34  0.37]\n",
      " [ 0.02  0.    0.34  0.29]\n",
      " [ 0.02  0.    0.34  0.33]\n",
      " [ 0.02  0.    0.34  0.16]] -> [ 0.22]\n",
      "[[ 0.02  0.    0.34  0.37]\n",
      " [ 0.02  0.    0.34  0.29]\n",
      " [ 0.02  0.    0.34  0.33]\n",
      " [ 0.02  0.    0.34  0.16]\n",
      " [ 0.02  0.    0.34  0.22]] -> [ 0.25]\n",
      "[[ 0.02  0.    0.34  0.29]\n",
      " [ 0.02  0.    0.34  0.33]\n",
      " [ 0.02  0.    0.34  0.16]\n",
      " [ 0.02  0.    0.34  0.22]\n",
      " [ 0.02  0.01  0.34  0.25]] -> [ 0.21]\n",
      "[[ 0.02  0.    0.34  0.33]\n",
      " [ 0.02  0.    0.34  0.16]\n",
      " [ 0.02  0.    0.34  0.22]\n",
      " [ 0.02  0.01  0.34  0.25]\n",
      " [ 0.02  0.01  0.34  0.21]] -> [ 0.46]\n",
      "[[ 0.02  0.    0.34  0.16]\n",
      " [ 0.02  0.    0.34  0.22]\n",
      " [ 0.02  0.01  0.34  0.25]\n",
      " [ 0.02  0.01  0.34  0.21]\n",
      " [ 0.02  0.    0.35  0.46]] -> [ 0.34]\n",
      "[[ 0.02  0.    0.34  0.22]\n",
      " [ 0.02  0.01  0.34  0.25]\n",
      " [ 0.02  0.01  0.34  0.21]\n",
      " [ 0.02  0.    0.35  0.46]\n",
      " [ 0.02  0.    0.35  0.34]] -> [ 0.31]\n",
      "[[ 0.02  0.01  0.34  0.25]\n",
      " [ 0.02  0.01  0.34  0.21]\n",
      " [ 0.02  0.    0.35  0.46]\n",
      " [ 0.02  0.    0.35  0.34]\n",
      " [ 0.02  0.    0.35  0.31]] -> [ 0.22]\n",
      "[[ 0.02  0.01  0.34  0.21]\n",
      " [ 0.02  0.    0.35  0.46]\n",
      " [ 0.02  0.    0.35  0.34]\n",
      " [ 0.02  0.    0.35  0.31]\n",
      " [ 0.03  0.    0.35  0.22]] -> [ 0.3]\n",
      "[[ 0.02  0.    0.35  0.46]\n",
      " [ 0.02  0.    0.35  0.34]\n",
      " [ 0.02  0.    0.35  0.31]\n",
      " [ 0.03  0.    0.35  0.22]\n",
      " [ 0.03  0.    0.35  0.3 ]] -> [ 0.28]\n",
      "[[ 0.02  0.    0.35  0.34]\n",
      " [ 0.02  0.    0.35  0.31]\n",
      " [ 0.03  0.    0.35  0.22]\n",
      " [ 0.03  0.    0.35  0.3 ]\n",
      " [ 0.03  0.01  0.35  0.28]] -> [ 0.14]\n",
      "[[ 0.02  0.    0.35  0.31]\n",
      " [ 0.03  0.    0.35  0.22]\n",
      " [ 0.03  0.    0.35  0.3 ]\n",
      " [ 0.03  0.01  0.35  0.28]\n",
      " [ 0.03  0.01  0.35  0.14]] -> [ 0.25]\n",
      "[[ 0.03  0.    0.35  0.22]\n",
      " [ 0.03  0.    0.35  0.3 ]\n",
      " [ 0.03  0.01  0.35  0.28]\n",
      " [ 0.03  0.01  0.35  0.14]\n",
      " [ 0.03  0.    0.36  0.25]] -> [ 0.33]\n",
      "[[ 0.03  0.    0.35  0.3 ]\n",
      " [ 0.03  0.01  0.35  0.28]\n",
      " [ 0.03  0.01  0.35  0.14]\n",
      " [ 0.03  0.    0.36  0.25]\n",
      " [ 0.03  0.    0.36  0.33]] -> [ 0.28]\n",
      "[[ 0.03  0.01  0.35  0.28]\n",
      " [ 0.03  0.01  0.35  0.14]\n",
      " [ 0.03  0.    0.36  0.25]\n",
      " [ 0.03  0.    0.36  0.33]\n",
      " [ 0.03  0.    0.36  0.28]] -> [ 0.24]\n",
      "[[ 0.03  0.01  0.35  0.14]\n",
      " [ 0.03  0.    0.36  0.25]\n",
      " [ 0.03  0.    0.36  0.33]\n",
      " [ 0.03  0.    0.36  0.28]\n",
      " [ 0.03  0.    0.36  0.24]] -> [ 0.42]\n",
      "[[ 0.03  0.    0.36  0.25]\n",
      " [ 0.03  0.    0.36  0.33]\n",
      " [ 0.03  0.    0.36  0.28]\n",
      " [ 0.03  0.    0.36  0.24]\n",
      " [ 0.03  0.    0.36  0.42]] -> [ 0.26]\n",
      "[[ 0.03  0.    0.36  0.33]\n",
      " [ 0.03  0.    0.36  0.28]\n",
      " [ 0.03  0.    0.36  0.24]\n",
      " [ 0.03  0.    0.36  0.42]\n",
      " [ 0.03  0.01  0.36  0.26]] -> [ 0.19]\n",
      "[[ 0.03  0.    0.36  0.28]\n",
      " [ 0.03  0.    0.36  0.24]\n",
      " [ 0.03  0.    0.36  0.42]\n",
      " [ 0.03  0.01  0.36  0.26]\n",
      " [ 0.03  0.01  0.36  0.19]] -> [ 0.41]\n",
      "[[ 0.03  0.    0.36  0.24]\n",
      " [ 0.03  0.    0.36  0.42]\n",
      " [ 0.03  0.01  0.36  0.26]\n",
      " [ 0.03  0.01  0.36  0.19]\n",
      " [ 0.03  0.    0.37  0.41]] -> [ 0.34]\n",
      "[[ 0.03  0.    0.36  0.42]\n",
      " [ 0.03  0.01  0.36  0.26]\n",
      " [ 0.03  0.01  0.36  0.19]\n",
      " [ 0.03  0.    0.37  0.41]\n",
      " [ 0.03  0.    0.37  0.34]] -> [ 0.08]\n",
      "[[ 0.03  0.01  0.36  0.26]\n",
      " [ 0.03  0.01  0.36  0.19]\n",
      " [ 0.03  0.    0.37  0.41]\n",
      " [ 0.03  0.    0.37  0.34]\n",
      " [ 0.03  0.    0.37  0.08]] -> [ 0.]\n",
      "[[ 0.03  0.01  0.36  0.19]\n",
      " [ 0.03  0.    0.37  0.41]\n",
      " [ 0.03  0.    0.37  0.34]\n",
      " [ 0.03  0.    0.37  0.08]\n",
      " [ 0.03  0.    0.37  0.  ]] -> [ 0.]\n",
      "[[ 0.03  0.    0.37  0.41]\n",
      " [ 0.03  0.    0.37  0.34]\n",
      " [ 0.03  0.    0.37  0.08]\n",
      " [ 0.03  0.    0.37  0.  ]\n",
      " [ 0.03  0.    0.37  0.  ]] -> [ 0.11]\n",
      "[[ 0.03  0.    0.37  0.34]\n",
      " [ 0.03  0.    0.37  0.08]\n",
      " [ 0.03  0.    0.37  0.  ]\n",
      " [ 0.03  0.    0.37  0.  ]\n",
      " [ 0.03  0.01  0.37  0.11]] -> [ 0.16]\n",
      "[[ 0.03  0.    0.37  0.08]\n",
      " [ 0.03  0.    0.37  0.  ]\n",
      " [ 0.03  0.    0.37  0.  ]\n",
      " [ 0.03  0.01  0.37  0.11]\n",
      " [ 0.03  0.01  0.37  0.16]] -> [ 0.27]\n",
      "[[ 0.03  0.    0.37  0.  ]\n",
      " [ 0.03  0.    0.37  0.  ]\n",
      " [ 0.03  0.01  0.37  0.11]\n",
      " [ 0.03  0.01  0.37  0.16]\n",
      " [ 0.03  0.    0.38  0.27]] -> [ 0.27]\n",
      "[[ 0.03  0.    0.37  0.  ]\n",
      " [ 0.03  0.01  0.37  0.11]\n",
      " [ 0.03  0.01  0.37  0.16]\n",
      " [ 0.03  0.    0.38  0.27]\n",
      " [ 0.03  0.    0.38  0.27]] -> [ 0.21]\n",
      "[[ 0.03  0.01  0.37  0.11]\n",
      " [ 0.03  0.01  0.37  0.16]\n",
      " [ 0.03  0.    0.38  0.27]\n",
      " [ 0.03  0.    0.38  0.27]\n",
      " [ 0.03  0.    0.38  0.21]] -> [ 0.37]\n",
      "[[ 0.03  0.01  0.37  0.16]\n",
      " [ 0.03  0.    0.38  0.27]\n",
      " [ 0.03  0.    0.38  0.27]\n",
      " [ 0.03  0.    0.38  0.21]\n",
      " [ 0.03  0.    0.38  0.37]] -> [ 0.41]\n",
      "[[ 0.03  0.    0.38  0.27]\n",
      " [ 0.03  0.    0.38  0.27]\n",
      " [ 0.03  0.    0.38  0.21]\n",
      " [ 0.03  0.    0.38  0.37]\n",
      " [ 0.03  0.    0.38  0.41]] -> [ 0.23]\n",
      "[[ 0.03  0.    0.38  0.27]\n",
      " [ 0.03  0.    0.38  0.21]\n",
      " [ 0.03  0.    0.38  0.37]\n",
      " [ 0.03  0.    0.38  0.41]\n",
      " [ 0.03  0.01  0.38  0.23]] -> [ 0.3]\n",
      "[[ 0.03  0.    0.38  0.21]\n",
      " [ 0.03  0.    0.38  0.37]\n",
      " [ 0.03  0.    0.38  0.41]\n",
      " [ 0.03  0.01  0.38  0.23]\n",
      " [ 0.03  0.01  0.38  0.3 ]] -> [ 0.25]\n",
      "[[ 0.03  0.    0.38  0.37]\n",
      " [ 0.03  0.    0.38  0.41]\n",
      " [ 0.03  0.01  0.38  0.23]\n",
      " [ 0.03  0.01  0.38  0.3 ]\n",
      " [ 0.03  0.    0.39  0.25]] -> [ 0.22]\n",
      "[[ 0.03  0.    0.38  0.41]\n",
      " [ 0.03  0.01  0.38  0.23]\n",
      " [ 0.03  0.01  0.38  0.3 ]\n",
      " [ 0.03  0.    0.39  0.25]\n",
      " [ 0.03  0.    0.39  0.22]] -> [ 0.26]\n",
      "[[ 0.03  0.01  0.38  0.23]\n",
      " [ 0.03  0.01  0.38  0.3 ]\n",
      " [ 0.03  0.    0.39  0.25]\n",
      " [ 0.03  0.    0.39  0.22]\n",
      " [ 0.03  0.    0.39  0.26]] -> [ 0.29]\n",
      "[[ 0.03  0.01  0.38  0.3 ]\n",
      " [ 0.03  0.    0.39  0.25]\n",
      " [ 0.03  0.    0.39  0.22]\n",
      " [ 0.03  0.    0.39  0.26]\n",
      " [ 0.03  0.    0.39  0.29]] -> [ 0.31]\n",
      "[[ 0.03  0.    0.39  0.25]\n",
      " [ 0.03  0.    0.39  0.22]\n",
      " [ 0.03  0.    0.39  0.26]\n",
      " [ 0.03  0.    0.39  0.29]\n",
      " [ 0.03  0.    0.39  0.31]] -> [ 0.29]\n",
      "[[ 0.03  0.    0.39  0.22]\n",
      " [ 0.03  0.    0.39  0.26]\n",
      " [ 0.03  0.    0.39  0.29]\n",
      " [ 0.03  0.    0.39  0.31]\n",
      " [ 0.03  0.01  0.39  0.29]] -> [ 0.12]\n",
      "[[ 0.03  0.    0.39  0.26]\n",
      " [ 0.03  0.    0.39  0.29]\n",
      " [ 0.03  0.    0.39  0.31]\n",
      " [ 0.03  0.01  0.39  0.29]\n",
      " [ 0.03  0.01  0.39  0.12]] -> [ 0.15]\n",
      "[[ 0.03  0.    0.39  0.29]\n",
      " [ 0.03  0.    0.39  0.31]\n",
      " [ 0.03  0.01  0.39  0.29]\n",
      " [ 0.03  0.01  0.39  0.12]\n",
      " [ 0.03  0.    0.4   0.15]] -> [ 0.48]\n",
      "[[ 0.03  0.    0.39  0.31]\n",
      " [ 0.03  0.01  0.39  0.29]\n",
      " [ 0.03  0.01  0.39  0.12]\n",
      " [ 0.03  0.    0.4   0.15]\n",
      " [ 0.03  0.    0.4   0.48]] -> [ 0.18]\n",
      "[[ 0.03  0.01  0.39  0.29]\n",
      " [ 0.03  0.01  0.39  0.12]\n",
      " [ 0.03  0.    0.4   0.15]\n",
      " [ 0.03  0.    0.4   0.48]\n",
      " [ 0.03  0.    0.4   0.18]] -> [ 0.25]\n",
      "[[ 0.03  0.01  0.39  0.12]\n",
      " [ 0.03  0.    0.4   0.15]\n",
      " [ 0.03  0.    0.4   0.48]\n",
      " [ 0.03  0.    0.4   0.18]\n",
      " [ 0.03  0.    0.4   0.25]] -> [ 0.27]\n",
      "[[ 0.03  0.    0.4   0.15]\n",
      " [ 0.03  0.    0.4   0.48]\n",
      " [ 0.03  0.    0.4   0.18]\n",
      " [ 0.03  0.    0.4   0.25]\n",
      " [ 0.03  0.    0.4   0.27]] -> [ 0.25]\n",
      "[[ 0.03  0.    0.4   0.48]\n",
      " [ 0.03  0.    0.4   0.18]\n",
      " [ 0.03  0.    0.4   0.25]\n",
      " [ 0.03  0.    0.4   0.27]\n",
      " [ 0.03  0.01  0.4   0.25]] -> [ 0.21]\n",
      "[[ 0.03  0.    0.4   0.18]\n",
      " [ 0.03  0.    0.4   0.25]\n",
      " [ 0.03  0.    0.4   0.27]\n",
      " [ 0.03  0.01  0.4   0.25]\n",
      " [ 0.03  0.01  0.4   0.21]] -> [ 0.28]\n",
      "[[ 0.03  0.    0.4   0.25]\n",
      " [ 0.03  0.    0.4   0.27]\n",
      " [ 0.03  0.01  0.4   0.25]\n",
      " [ 0.03  0.01  0.4   0.21]\n",
      " [ 0.03  0.    0.41  0.28]] -> [ 0.24]\n",
      "[[ 0.03  0.    0.4   0.27]\n",
      " [ 0.03  0.01  0.4   0.25]\n",
      " [ 0.03  0.01  0.4   0.21]\n",
      " [ 0.03  0.    0.41  0.28]\n",
      " [ 0.03  0.    0.41  0.24]] -> [ 0.21]\n",
      "[[ 0.03  0.01  0.4   0.25]\n",
      " [ 0.03  0.01  0.4   0.21]\n",
      " [ 0.03  0.    0.41  0.28]\n",
      " [ 0.03  0.    0.41  0.24]\n",
      " [ 0.03  0.    0.41  0.21]] -> [ 0.29]\n",
      "[[ 0.03  0.01  0.4   0.21]\n",
      " [ 0.03  0.    0.41  0.28]\n",
      " [ 0.03  0.    0.41  0.24]\n",
      " [ 0.03  0.    0.41  0.21]\n",
      " [ 0.03  0.    0.41  0.29]] -> [ 0.35]\n",
      "[[ 0.03  0.    0.41  0.28]\n",
      " [ 0.03  0.    0.41  0.24]\n",
      " [ 0.03  0.    0.41  0.21]\n",
      " [ 0.03  0.    0.41  0.29]\n",
      " [ 0.03  0.    0.41  0.35]] -> [ 0.]\n",
      "[[ 0.03  0.    0.41  0.24]\n",
      " [ 0.03  0.    0.41  0.21]\n",
      " [ 0.03  0.    0.41  0.29]\n",
      " [ 0.03  0.    0.41  0.35]\n",
      " [ 0.03  0.01  0.41  0.  ]] -> [ 0.07]\n",
      "[[ 0.03  0.    0.41  0.21]\n",
      " [ 0.03  0.    0.41  0.29]\n",
      " [ 0.03  0.    0.41  0.35]\n",
      " [ 0.03  0.01  0.41  0.  ]\n",
      " [ 0.03  0.01  0.41  0.07]] -> [ 0.32]\n",
      "[[ 0.03  0.    0.41  0.29]\n",
      " [ 0.03  0.    0.41  0.35]\n",
      " [ 0.03  0.01  0.41  0.  ]\n",
      " [ 0.03  0.01  0.41  0.07]\n",
      " [ 0.03  0.    0.42  0.32]] -> [ 0.19]\n",
      "[[ 0.03  0.    0.41  0.35]\n",
      " [ 0.03  0.01  0.41  0.  ]\n",
      " [ 0.03  0.01  0.41  0.07]\n",
      " [ 0.03  0.    0.42  0.32]\n",
      " [ 0.03  0.    0.42  0.19]] -> [ 0.34]\n",
      "[[ 0.03  0.01  0.41  0.  ]\n",
      " [ 0.03  0.01  0.41  0.07]\n",
      " [ 0.03  0.    0.42  0.32]\n",
      " [ 0.03  0.    0.42  0.19]\n",
      " [ 0.03  0.    0.42  0.34]] -> [ 0.28]\n",
      "[[ 0.03  0.01  0.41  0.07]\n",
      " [ 0.03  0.    0.42  0.32]\n",
      " [ 0.03  0.    0.42  0.19]\n",
      " [ 0.03  0.    0.42  0.34]\n",
      " [ 0.03  0.    0.42  0.28]] -> [ 0.23]\n",
      "[[ 0.03  0.    0.42  0.32]\n",
      " [ 0.03  0.    0.42  0.19]\n",
      " [ 0.03  0.    0.42  0.34]\n",
      " [ 0.03  0.    0.42  0.28]\n",
      " [ 0.03  0.    0.42  0.23]] -> [ 0.15]\n",
      "[[ 0.03  0.    0.42  0.19]\n",
      " [ 0.03  0.    0.42  0.34]\n",
      " [ 0.03  0.    0.42  0.28]\n",
      " [ 0.03  0.    0.42  0.23]\n",
      " [ 0.03  0.01  0.42  0.15]] -> [ 0.1]\n",
      "[[ 0.03  0.    0.42  0.34]\n",
      " [ 0.03  0.    0.42  0.28]\n",
      " [ 0.03  0.    0.42  0.23]\n",
      " [ 0.03  0.01  0.42  0.15]\n",
      " [ 0.03  0.01  0.42  0.1 ]] -> [ 0.15]\n",
      "[[ 0.03  0.    0.42  0.28]\n",
      " [ 0.03  0.    0.42  0.23]\n",
      " [ 0.03  0.01  0.42  0.15]\n",
      " [ 0.03  0.01  0.42  0.1 ]\n",
      " [ 0.03  0.    0.43  0.15]] -> [ 0.09]\n",
      "[[ 0.03  0.    0.42  0.23]\n",
      " [ 0.03  0.01  0.42  0.15]\n",
      " [ 0.03  0.01  0.42  0.1 ]\n",
      " [ 0.03  0.    0.43  0.15]\n",
      " [ 0.03  0.    0.43  0.09]] -> [ 0.78]\n",
      "[[ 0.03  0.01  0.42  0.15]\n",
      " [ 0.03  0.01  0.42  0.1 ]\n",
      " [ 0.03  0.    0.43  0.15]\n",
      " [ 0.03  0.    0.43  0.09]\n",
      " [ 0.03  0.    0.43  0.78]] -> [ 0.59]\n",
      "[[ 0.03  0.01  0.42  0.1 ]\n",
      " [ 0.03  0.    0.43  0.15]\n",
      " [ 0.03  0.    0.43  0.09]\n",
      " [ 0.03  0.    0.43  0.78]\n",
      " [ 0.03  0.    0.43  0.59]] -> [ 0.29]\n",
      "[[ 0.03  0.    0.43  0.15]\n",
      " [ 0.03  0.    0.43  0.09]\n",
      " [ 0.03  0.    0.43  0.78]\n",
      " [ 0.03  0.    0.43  0.59]\n",
      " [ 0.03  0.    0.43  0.29]] -> [ 0.23]\n",
      "[[ 0.03  0.    0.43  0.09]\n",
      " [ 0.03  0.    0.43  0.78]\n",
      " [ 0.03  0.    0.43  0.59]\n",
      " [ 0.03  0.    0.43  0.29]\n",
      " [ 0.03  0.01  0.43  0.23]] -> [ 0.12]\n",
      "[[ 0.03  0.    0.43  0.78]\n",
      " [ 0.03  0.    0.43  0.59]\n",
      " [ 0.03  0.    0.43  0.29]\n",
      " [ 0.03  0.01  0.43  0.23]\n",
      " [ 0.03  0.01  0.43  0.12]] -> [ 0.36]\n",
      "[[ 0.03  0.    0.43  0.59]\n",
      " [ 0.03  0.    0.43  0.29]\n",
      " [ 0.03  0.01  0.43  0.23]\n",
      " [ 0.03  0.01  0.43  0.12]\n",
      " [ 0.03  0.    0.44  0.36]] -> [ 0.13]\n",
      "[[ 0.03  0.    0.43  0.29]\n",
      " [ 0.03  0.01  0.43  0.23]\n",
      " [ 0.03  0.01  0.43  0.12]\n",
      " [ 0.03  0.    0.44  0.36]\n",
      " [ 0.03  0.    0.44  0.13]] -> [ 0.17]\n",
      "[[ 0.03  0.01  0.43  0.23]\n",
      " [ 0.03  0.01  0.43  0.12]\n",
      " [ 0.03  0.    0.44  0.36]\n",
      " [ 0.03  0.    0.44  0.13]\n",
      " [ 0.03  0.    0.44  0.17]] -> [ 0.17]\n",
      "[[ 0.03  0.01  0.43  0.12]\n",
      " [ 0.03  0.    0.44  0.36]\n",
      " [ 0.03  0.    0.44  0.13]\n",
      " [ 0.03  0.    0.44  0.17]\n",
      " [ 0.03  0.    0.44  0.17]] -> [ 0.16]\n",
      "[[ 0.03  0.    0.44  0.36]\n",
      " [ 0.03  0.    0.44  0.13]\n",
      " [ 0.03  0.    0.44  0.17]\n",
      " [ 0.03  0.    0.44  0.17]\n",
      " [ 0.03  0.    0.44  0.16]] -> [ 0.14]\n",
      "[[ 0.03  0.    0.44  0.13]\n",
      " [ 0.03  0.    0.44  0.17]\n",
      " [ 0.03  0.    0.44  0.17]\n",
      " [ 0.03  0.    0.44  0.16]\n",
      " [ 0.03  0.01  0.44  0.14]] -> [ 0.08]\n",
      "[[ 0.03  0.    0.44  0.17]\n",
      " [ 0.03  0.    0.44  0.17]\n",
      " [ 0.03  0.    0.44  0.16]\n",
      " [ 0.03  0.01  0.44  0.14]\n",
      " [ 0.03  0.01  0.44  0.08]] -> [ 0.16]\n",
      "[[ 0.03  0.    0.44  0.17]\n",
      " [ 0.03  0.    0.44  0.16]\n",
      " [ 0.03  0.01  0.44  0.14]\n",
      " [ 0.03  0.01  0.44  0.08]\n",
      " [ 0.03  0.    0.45  0.16]] -> [ 0.14]\n",
      "[[ 0.03  0.    0.44  0.16]\n",
      " [ 0.03  0.01  0.44  0.14]\n",
      " [ 0.03  0.01  0.44  0.08]\n",
      " [ 0.03  0.    0.45  0.16]\n",
      " [ 0.03  0.    0.45  0.14]] -> [ 0.14]\n",
      "[[ 0.03  0.01  0.44  0.14]\n",
      " [ 0.03  0.01  0.44  0.08]\n",
      " [ 0.03  0.    0.45  0.16]\n",
      " [ 0.03  0.    0.45  0.14]\n",
      " [ 0.03  0.    0.45  0.14]] -> [ 0.15]\n",
      "[[ 0.03  0.01  0.44  0.08]\n",
      " [ 0.03  0.    0.45  0.16]\n",
      " [ 0.03  0.    0.45  0.14]\n",
      " [ 0.03  0.    0.45  0.14]\n",
      " [ 0.03  0.    0.45  0.15]] -> [ 0.2]\n",
      "[[ 0.03  0.    0.45  0.16]\n",
      " [ 0.03  0.    0.45  0.14]\n",
      " [ 0.03  0.    0.45  0.14]\n",
      " [ 0.03  0.    0.45  0.15]\n",
      " [ 0.03  0.    0.45  0.2 ]] -> [ 0.24]\n",
      "[[ 0.03  0.    0.45  0.14]\n",
      " [ 0.03  0.    0.45  0.14]\n",
      " [ 0.03  0.    0.45  0.15]\n",
      " [ 0.03  0.    0.45  0.2 ]\n",
      " [ 0.03  0.01  0.45  0.24]] -> [ 0.08]\n",
      "[[ 0.03  0.    0.45  0.14]\n",
      " [ 0.03  0.    0.45  0.15]\n",
      " [ 0.03  0.    0.45  0.2 ]\n",
      " [ 0.03  0.01  0.45  0.24]\n",
      " [ 0.03  0.01  0.45  0.08]] -> [ 0.15]\n",
      "[[ 0.03  0.    0.45  0.15]\n",
      " [ 0.03  0.    0.45  0.2 ]\n",
      " [ 0.03  0.01  0.45  0.24]\n",
      " [ 0.03  0.01  0.45  0.08]\n",
      " [ 0.03  0.    0.46  0.15]] -> [ 0.17]\n",
      "[[ 0.03  0.    0.45  0.2 ]\n",
      " [ 0.03  0.01  0.45  0.24]\n",
      " [ 0.03  0.01  0.45  0.08]\n",
      " [ 0.03  0.    0.46  0.15]\n",
      " [ 0.03  0.    0.46  0.17]] -> [ 0.09]\n",
      "[[ 0.03  0.01  0.45  0.24]\n",
      " [ 0.03  0.01  0.45  0.08]\n",
      " [ 0.03  0.    0.46  0.15]\n",
      " [ 0.03  0.    0.46  0.17]\n",
      " [ 0.03  0.    0.46  0.09]] -> [ 0.17]\n",
      "[[ 0.03  0.01  0.45  0.08]\n",
      " [ 0.03  0.    0.46  0.15]\n",
      " [ 0.03  0.    0.46  0.17]\n",
      " [ 0.03  0.    0.46  0.09]\n",
      " [ 0.03  0.    0.46  0.17]] -> [ 0.13]\n",
      "[[ 0.03  0.    0.46  0.15]\n",
      " [ 0.03  0.    0.46  0.17]\n",
      " [ 0.03  0.    0.46  0.09]\n",
      " [ 0.03  0.    0.46  0.17]\n",
      " [ 0.03  0.    0.46  0.13]] -> [ 0.19]\n",
      "[[ 0.03  0.    0.46  0.17]\n",
      " [ 0.03  0.    0.46  0.09]\n",
      " [ 0.03  0.    0.46  0.17]\n",
      " [ 0.03  0.    0.46  0.13]\n",
      " [ 0.03  0.01  0.46  0.19]] -> [ 0.08]\n",
      "[[ 0.03  0.    0.46  0.09]\n",
      " [ 0.03  0.    0.46  0.17]\n",
      " [ 0.03  0.    0.46  0.13]\n",
      " [ 0.03  0.01  0.46  0.19]\n",
      " [ 0.03  0.01  0.46  0.08]] -> [ 0.14]\n",
      "[[ 0.03  0.    0.46  0.17]\n",
      " [ 0.03  0.    0.46  0.13]\n",
      " [ 0.03  0.01  0.46  0.19]\n",
      " [ 0.03  0.01  0.46  0.08]\n",
      " [ 0.03  0.    0.47  0.14]] -> [ 0.18]\n",
      "[[ 0.03  0.    0.46  0.13]\n",
      " [ 0.03  0.01  0.46  0.19]\n",
      " [ 0.03  0.01  0.46  0.08]\n",
      " [ 0.03  0.    0.47  0.14]\n",
      " [ 0.03  0.    0.47  0.18]] -> [ 0.24]\n",
      "[[ 0.03  0.01  0.46  0.19]\n",
      " [ 0.03  0.01  0.46  0.08]\n",
      " [ 0.03  0.    0.47  0.14]\n",
      " [ 0.03  0.    0.47  0.18]\n",
      " [ 0.03  0.    0.47  0.24]] -> [ 0.16]\n",
      "[[ 0.03  0.01  0.46  0.08]\n",
      " [ 0.03  0.    0.47  0.14]\n",
      " [ 0.03  0.    0.47  0.18]\n",
      " [ 0.03  0.    0.47  0.24]\n",
      " [ 0.03  0.    0.47  0.16]] -> [ 0.11]\n",
      "[[ 0.03  0.    0.47  0.14]\n",
      " [ 0.03  0.    0.47  0.18]\n",
      " [ 0.03  0.    0.47  0.24]\n",
      " [ 0.03  0.    0.47  0.16]\n",
      " [ 0.03  0.    0.47  0.11]] -> [ 0.13]\n",
      "[[ 0.03  0.    0.47  0.18]\n",
      " [ 0.03  0.    0.47  0.24]\n",
      " [ 0.03  0.    0.47  0.16]\n",
      " [ 0.03  0.    0.47  0.11]\n",
      " [ 0.03  0.01  0.47  0.13]] -> [ 0.1]\n",
      "[[ 0.03  0.    0.47  0.24]\n",
      " [ 0.03  0.    0.47  0.16]\n",
      " [ 0.03  0.    0.47  0.11]\n",
      " [ 0.03  0.01  0.47  0.13]\n",
      " [ 0.03  0.01  0.47  0.1 ]] -> [ 0.16]\n",
      "[[ 0.03  0.    0.47  0.16]\n",
      " [ 0.03  0.    0.47  0.11]\n",
      " [ 0.03  0.01  0.47  0.13]\n",
      " [ 0.03  0.01  0.47  0.1 ]\n",
      " [ 0.03  0.    0.48  0.16]] -> [ 0.11]\n",
      "[[ 0.03  0.    0.47  0.11]\n",
      " [ 0.03  0.01  0.47  0.13]\n",
      " [ 0.03  0.01  0.47  0.1 ]\n",
      " [ 0.03  0.    0.48  0.16]\n",
      " [ 0.03  0.    0.48  0.11]] -> [ 0.22]\n",
      "[[ 0.03  0.01  0.47  0.13]\n",
      " [ 0.03  0.01  0.47  0.1 ]\n",
      " [ 0.03  0.    0.48  0.16]\n",
      " [ 0.03  0.    0.48  0.11]\n",
      " [ 0.03  0.    0.48  0.22]] -> [ 0.15]\n",
      "[[ 0.03  0.01  0.47  0.1 ]\n",
      " [ 0.03  0.    0.48  0.16]\n",
      " [ 0.03  0.    0.48  0.11]\n",
      " [ 0.03  0.    0.48  0.22]\n",
      " [ 0.    0.    0.48  0.15]] -> [ 0.18]\n",
      "[[ 0.03  0.    0.48  0.16]\n",
      " [ 0.03  0.    0.48  0.11]\n",
      " [ 0.03  0.    0.48  0.22]\n",
      " [ 0.    0.    0.48  0.15]\n",
      " [ 0.    0.    0.48  0.18]] -> [ 0.11]\n",
      "[[ 0.03  0.    0.48  0.11]\n",
      " [ 0.03  0.    0.48  0.22]\n",
      " [ 0.    0.    0.48  0.15]\n",
      " [ 0.    0.    0.48  0.18]\n",
      " [ 0.    0.01  0.48  0.11]] -> [ 0.14]\n",
      "[[ 0.03  0.    0.48  0.22]\n",
      " [ 0.    0.    0.48  0.15]\n",
      " [ 0.    0.    0.48  0.18]\n",
      " [ 0.    0.01  0.48  0.11]\n",
      " [ 0.    0.01  0.48  0.14]] -> [ 0.34]\n",
      "[[ 0.    0.    0.48  0.15]\n",
      " [ 0.    0.    0.48  0.18]\n",
      " [ 0.    0.01  0.48  0.11]\n",
      " [ 0.    0.01  0.48  0.14]\n",
      " [ 0.    0.    0.49  0.34]] -> [ 0.1]\n",
      "[[ 0.    0.    0.48  0.18]\n",
      " [ 0.    0.01  0.48  0.11]\n",
      " [ 0.    0.01  0.48  0.14]\n",
      " [ 0.    0.    0.49  0.34]\n",
      " [ 0.    0.    0.49  0.1 ]] -> [ 0.13]\n",
      "[[ 0.    0.01  0.48  0.11]\n",
      " [ 0.    0.01  0.48  0.14]\n",
      " [ 0.    0.    0.49  0.34]\n",
      " [ 0.    0.    0.49  0.1 ]\n",
      " [ 0.    0.    0.49  0.13]] -> [ 0.21]\n",
      "[[ 0.    0.01  0.48  0.14]\n",
      " [ 0.    0.    0.49  0.34]\n",
      " [ 0.    0.    0.49  0.1 ]\n",
      " [ 0.    0.    0.49  0.13]\n",
      " [ 0.    0.    0.49  0.21]] -> [ 0.35]\n",
      "[[ 0.    0.    0.49  0.34]\n",
      " [ 0.    0.    0.49  0.1 ]\n",
      " [ 0.    0.    0.49  0.13]\n",
      " [ 0.    0.    0.49  0.21]\n",
      " [ 0.    0.    0.49  0.35]] -> [ 0.15]\n",
      "[[ 0.    0.    0.49  0.1 ]\n",
      " [ 0.    0.    0.49  0.13]\n",
      " [ 0.    0.    0.49  0.21]\n",
      " [ 0.    0.    0.49  0.35]\n",
      " [ 0.    0.01  0.49  0.15]] -> [ 0.06]\n",
      "[[ 0.    0.    0.49  0.13]\n",
      " [ 0.    0.    0.49  0.21]\n",
      " [ 0.    0.    0.49  0.35]\n",
      " [ 0.    0.01  0.49  0.15]\n",
      " [ 0.    0.01  0.49  0.06]] -> [ 0.23]\n",
      "[[ 0.    0.    0.49  0.21]\n",
      " [ 0.    0.    0.49  0.35]\n",
      " [ 0.    0.01  0.49  0.15]\n",
      " [ 0.    0.01  0.49  0.06]\n",
      " [ 0.    0.    0.5   0.23]] -> [ 0.22]\n",
      "[[ 0.    0.    0.49  0.35]\n",
      " [ 0.    0.01  0.49  0.15]\n",
      " [ 0.    0.01  0.49  0.06]\n",
      " [ 0.    0.    0.5   0.23]\n",
      " [ 0.    0.    0.5   0.22]] -> [ 0.19]\n",
      "[[ 0.    0.01  0.49  0.15]\n",
      " [ 0.    0.01  0.49  0.06]\n",
      " [ 0.    0.    0.5   0.23]\n",
      " [ 0.    0.    0.5   0.22]\n",
      " [ 0.    0.    0.5   0.19]] -> [ 0.2]\n",
      "[[ 0.    0.01  0.49  0.06]\n",
      " [ 0.    0.    0.5   0.23]\n",
      " [ 0.    0.    0.5   0.22]\n",
      " [ 0.    0.    0.5   0.19]\n",
      " [ 0.    0.    0.5   0.2 ]] -> [ 0.13]\n",
      "[[ 0.    0.    0.5   0.23]\n",
      " [ 0.    0.    0.5   0.22]\n",
      " [ 0.    0.    0.5   0.19]\n",
      " [ 0.    0.    0.5   0.2 ]\n",
      " [ 0.    0.    0.5   0.13]] -> [ 0.21]\n",
      "[[ 0.    0.    0.5   0.22]\n",
      " [ 0.    0.    0.5   0.19]\n",
      " [ 0.    0.    0.5   0.2 ]\n",
      " [ 0.    0.    0.5   0.13]\n",
      " [ 0.    0.01  0.5   0.21]] -> [ 0.1]\n",
      "[[ 0.    0.    0.5   0.19]\n",
      " [ 0.    0.    0.5   0.2 ]\n",
      " [ 0.    0.    0.5   0.13]\n",
      " [ 0.    0.01  0.5   0.21]\n",
      " [ 0.    0.01  0.5   0.1 ]] -> [ 0.11]\n",
      "[[ 0.    0.    0.5   0.2 ]\n",
      " [ 0.    0.    0.5   0.13]\n",
      " [ 0.    0.01  0.5   0.21]\n",
      " [ 0.    0.01  0.5   0.1 ]\n",
      " [ 0.    0.    0.51  0.11]] -> [ 0.11]\n",
      "[[ 0.    0.    0.5   0.13]\n",
      " [ 0.    0.01  0.5   0.21]\n",
      " [ 0.    0.01  0.5   0.1 ]\n",
      " [ 0.    0.    0.51  0.11]\n",
      " [ 0.    0.    0.51  0.11]] -> [ 0.16]\n",
      "[[ 0.    0.01  0.5   0.21]\n",
      " [ 0.    0.01  0.5   0.1 ]\n",
      " [ 0.    0.    0.51  0.11]\n",
      " [ 0.    0.    0.51  0.11]\n",
      " [ 0.    0.    0.51  0.16]] -> [ 0.12]\n",
      "[[ 0.    0.01  0.5   0.1 ]\n",
      " [ 0.    0.    0.51  0.11]\n",
      " [ 0.    0.    0.51  0.11]\n",
      " [ 0.    0.    0.51  0.16]\n",
      " [ 0.    0.    0.51  0.12]] -> [ 0.15]\n",
      "[[ 0.    0.    0.51  0.11]\n",
      " [ 0.    0.    0.51  0.11]\n",
      " [ 0.    0.    0.51  0.16]\n",
      " [ 0.    0.    0.51  0.12]\n",
      " [ 0.    0.    0.51  0.15]] -> [ 0.08]\n",
      "[[ 0.    0.    0.51  0.11]\n",
      " [ 0.    0.    0.51  0.16]\n",
      " [ 0.    0.    0.51  0.12]\n",
      " [ 0.    0.    0.51  0.15]\n",
      " [ 0.    0.01  0.51  0.08]] -> [ 0.]\n",
      "[[ 0.    0.    0.51  0.16]\n",
      " [ 0.    0.    0.51  0.12]\n",
      " [ 0.    0.    0.51  0.15]\n",
      " [ 0.    0.01  0.51  0.08]\n",
      " [ 0.    0.01  0.51  0.  ]] -> [ 0.24]\n",
      "[[ 0.    0.    0.51  0.12]\n",
      " [ 0.    0.    0.51  0.15]\n",
      " [ 0.    0.01  0.51  0.08]\n",
      " [ 0.    0.01  0.51  0.  ]\n",
      " [ 0.    0.    0.52  0.24]] -> [ 0.19]\n",
      "[[ 0.    0.    0.51  0.15]\n",
      " [ 0.    0.01  0.51  0.08]\n",
      " [ 0.    0.01  0.51  0.  ]\n",
      " [ 0.    0.    0.52  0.24]\n",
      " [ 0.    0.    0.52  0.19]] -> [ 0.22]\n",
      "[[ 0.    0.01  0.51  0.08]\n",
      " [ 0.    0.01  0.51  0.  ]\n",
      " [ 0.    0.    0.52  0.24]\n",
      " [ 0.    0.    0.52  0.19]\n",
      " [ 0.    0.    0.52  0.22]] -> [ 0.13]\n",
      "[[ 0.    0.01  0.51  0.  ]\n",
      " [ 0.    0.    0.52  0.24]\n",
      " [ 0.    0.    0.52  0.19]\n",
      " [ 0.    0.    0.52  0.22]\n",
      " [ 0.    0.    0.52  0.13]] -> [ 0.12]\n",
      "[[ 0.    0.    0.52  0.24]\n",
      " [ 0.    0.    0.52  0.19]\n",
      " [ 0.    0.    0.52  0.22]\n",
      " [ 0.    0.    0.52  0.13]\n",
      " [ 0.    0.    0.52  0.12]] -> [ 0.16]\n",
      "[[ 0.    0.    0.52  0.19]\n",
      " [ 0.    0.    0.52  0.22]\n",
      " [ 0.    0.    0.52  0.13]\n",
      " [ 0.    0.    0.52  0.12]\n",
      " [ 0.    0.01  0.52  0.16]] -> [ 0.02]\n",
      "[[ 0.    0.    0.52  0.22]\n",
      " [ 0.    0.    0.52  0.13]\n",
      " [ 0.    0.    0.52  0.12]\n",
      " [ 0.    0.01  0.52  0.16]\n",
      " [ 0.    0.01  0.52  0.02]] -> [ 0.16]\n",
      "[[ 0.    0.    0.52  0.13]\n",
      " [ 0.    0.    0.52  0.12]\n",
      " [ 0.    0.01  0.52  0.16]\n",
      " [ 0.    0.01  0.52  0.02]\n",
      " [ 0.    0.    0.01  0.16]] -> [ 0.2]\n",
      "[[ 0.    0.    0.52  0.12]\n",
      " [ 0.    0.01  0.52  0.16]\n",
      " [ 0.    0.01  0.52  0.02]\n",
      " [ 0.    0.    0.01  0.16]\n",
      " [ 0.    0.    0.01  0.2 ]] -> [ 0.12]\n",
      "[[ 0.    0.01  0.52  0.16]\n",
      " [ 0.    0.01  0.52  0.02]\n",
      " [ 0.    0.    0.01  0.16]\n",
      " [ 0.    0.    0.01  0.2 ]\n",
      " [ 0.    0.    0.01  0.12]] -> [ 0.11]\n",
      "[[ 0.    0.01  0.52  0.02]\n",
      " [ 0.    0.    0.01  0.16]\n",
      " [ 0.    0.    0.01  0.2 ]\n",
      " [ 0.    0.    0.01  0.12]\n",
      " [ 0.    0.    0.01  0.11]] -> [ 0.22]\n",
      "[[ 0.    0.    0.01  0.16]\n",
      " [ 0.    0.    0.01  0.2 ]\n",
      " [ 0.    0.    0.01  0.12]\n",
      " [ 0.    0.    0.01  0.11]\n",
      " [ 0.    0.    0.01  0.22]] -> [ 0.2]\n",
      "[[ 0.    0.    0.01  0.2 ]\n",
      " [ 0.    0.    0.01  0.12]\n",
      " [ 0.    0.    0.01  0.11]\n",
      " [ 0.    0.    0.01  0.22]\n",
      " [ 0.    0.01  0.01  0.2 ]] -> [ 0.16]\n",
      "[[ 0.    0.    0.01  0.12]\n",
      " [ 0.    0.    0.01  0.11]\n",
      " [ 0.    0.    0.01  0.22]\n",
      " [ 0.    0.01  0.01  0.2 ]\n",
      " [ 0.    0.01  0.01  0.16]] -> [ 0.17]\n",
      "[[ 0.    0.    0.01  0.11]\n",
      " [ 0.    0.    0.01  0.22]\n",
      " [ 0.    0.01  0.01  0.2 ]\n",
      " [ 0.    0.01  0.01  0.16]\n",
      " [ 0.    0.    0.02  0.17]] -> [ 0.97]\n",
      "[[ 0.    0.    0.01  0.22]\n",
      " [ 0.    0.01  0.01  0.2 ]\n",
      " [ 0.    0.01  0.01  0.16]\n",
      " [ 0.    0.    0.02  0.17]\n",
      " [ 0.    0.    0.02  0.97]] -> [ 0.]\n",
      "[[ 0.    0.01  0.01  0.2 ]\n",
      " [ 0.    0.01  0.01  0.16]\n",
      " [ 0.    0.    0.02  0.17]\n",
      " [ 0.    0.    0.02  0.97]\n",
      " [ 0.    0.    0.02  0.  ]] -> [ 0.23]\n",
      "[[ 0.    0.01  0.01  0.16]\n",
      " [ 0.    0.    0.02  0.17]\n",
      " [ 0.    0.    0.02  0.97]\n",
      " [ 0.    0.    0.02  0.  ]\n",
      " [ 0.    0.    0.02  0.23]] -> [ 1.]\n",
      "[[ 0.    0.    0.02  0.17]\n",
      " [ 0.    0.    0.02  0.97]\n",
      " [ 0.    0.    0.02  0.  ]\n",
      " [ 0.    0.    0.02  0.23]\n",
      " [ 0.    0.    0.02  1.  ]] -> [ 0.18]\n",
      "[[ 0.    0.    0.02  0.97]\n",
      " [ 0.    0.    0.02  0.  ]\n",
      " [ 0.    0.    0.02  0.23]\n",
      " [ 0.    0.    0.02  1.  ]\n",
      " [ 0.    0.01  0.02  0.18]] -> [ 0.13]\n",
      "[[ 0.    0.    0.02  0.  ]\n",
      " [ 0.    0.    0.02  0.23]\n",
      " [ 0.    0.    0.02  1.  ]\n",
      " [ 0.    0.01  0.02  0.18]\n",
      " [ 0.    0.01  0.02  0.13]] -> [ 0.21]\n",
      "[[ 0.    0.    0.02  0.23]\n",
      " [ 0.    0.    0.02  1.  ]\n",
      " [ 0.    0.01  0.02  0.18]\n",
      " [ 0.    0.01  0.02  0.13]\n",
      " [ 0.    0.    0.03  0.21]] -> [ 0.24]\n",
      "[[ 0.    0.    0.02  1.  ]\n",
      " [ 0.    0.01  0.02  0.18]\n",
      " [ 0.    0.01  0.02  0.13]\n",
      " [ 0.    0.    0.03  0.21]\n",
      " [ 0.    0.    0.03  0.24]] -> [ 0.16]\n",
      "[[ 0.    0.01  0.02  0.18]\n",
      " [ 0.    0.01  0.02  0.13]\n",
      " [ 0.    0.    0.03  0.21]\n",
      " [ 0.    0.    0.03  0.24]\n",
      " [ 0.    0.    0.03  0.16]] -> [ 0.18]\n",
      "[[ 0.    0.01  0.02  0.13]\n",
      " [ 0.    0.    0.03  0.21]\n",
      " [ 0.    0.    0.03  0.24]\n",
      " [ 0.    0.    0.03  0.16]\n",
      " [ 0.    0.    0.03  0.18]] -> [ 0.22]\n",
      "[[ 0.    0.    0.03  0.21]\n",
      " [ 0.    0.    0.03  0.24]\n",
      " [ 0.    0.    0.03  0.16]\n",
      " [ 0.    0.    0.03  0.18]\n",
      " [ 0.    0.    0.03  0.22]] -> [ 0.18]\n",
      "[[ 0.    0.    0.03  0.24]\n",
      " [ 0.    0.    0.03  0.16]\n",
      " [ 0.    0.    0.03  0.18]\n",
      " [ 0.    0.    0.03  0.22]\n",
      " [ 0.    0.01  0.03  0.18]] -> [ 0.11]\n",
      "[[ 0.    0.    0.03  0.16]\n",
      " [ 0.    0.    0.03  0.18]\n",
      " [ 0.    0.    0.03  0.22]\n",
      " [ 0.    0.01  0.03  0.18]\n",
      " [ 0.    0.01  0.03  0.11]] -> [ 0.24]\n",
      "[[ 0.    0.    0.03  0.18]\n",
      " [ 0.    0.    0.03  0.22]\n",
      " [ 0.    0.01  0.03  0.18]\n",
      " [ 0.    0.01  0.03  0.11]\n",
      " [ 0.    0.    0.04  0.24]] -> [ 0.22]\n",
      "[[ 0.    0.    0.03  0.22]\n",
      " [ 0.    0.01  0.03  0.18]\n",
      " [ 0.    0.01  0.03  0.11]\n",
      " [ 0.    0.    0.04  0.24]\n",
      " [ 0.    0.    0.04  0.22]] -> [ 0.2]\n",
      "[[ 0.    0.01  0.03  0.18]\n",
      " [ 0.    0.01  0.03  0.11]\n",
      " [ 0.    0.    0.04  0.24]\n",
      " [ 0.    0.    0.04  0.22]\n",
      " [ 0.    0.    0.04  0.2 ]] -> [ 0.22]\n",
      "[[ 0.    0.01  0.03  0.11]\n",
      " [ 0.    0.    0.04  0.24]\n",
      " [ 0.    0.    0.04  0.22]\n",
      " [ 0.    0.    0.04  0.2 ]\n",
      " [ 0.    0.    0.04  0.22]] -> [ 0.26]\n",
      "[[ 0.    0.    0.04  0.24]\n",
      " [ 0.    0.    0.04  0.22]\n",
      " [ 0.    0.    0.04  0.2 ]\n",
      " [ 0.    0.    0.04  0.22]\n",
      " [ 0.    0.    0.04  0.26]] -> [ 0.]\n",
      "[[ 0.    0.    0.04  0.22]\n",
      " [ 0.    0.    0.04  0.2 ]\n",
      " [ 0.    0.    0.04  0.22]\n",
      " [ 0.    0.    0.04  0.26]\n",
      " [ 0.    0.01  0.04  0.  ]] -> [ 0.]\n",
      "[[ 0.    0.    0.04  0.2 ]\n",
      " [ 0.    0.    0.04  0.22]\n",
      " [ 0.    0.    0.04  0.26]\n",
      " [ 0.    0.01  0.04  0.  ]\n",
      " [ 0.    0.01  0.04  0.  ]] -> [ 0.05]\n",
      "[[ 0.    0.    0.04  0.22]\n",
      " [ 0.    0.    0.04  0.26]\n",
      " [ 0.    0.01  0.04  0.  ]\n",
      " [ 0.    0.01  0.04  0.  ]\n",
      " [ 0.    0.    0.05  0.05]] -> [ 0.31]\n"
     ]
    }
   ],
   "source": [
    "x=xy\n",
    "y=xy[:,[-1]]\n",
    "\n",
    "#build a series dataset(seq_length에 해당하는 전날 X와 다음 forecastDays에 해당하는 Y)\n",
    "dataX=[]\n",
    "dataY=[]\n",
    "for i in range(0, len(y)-seq_length):\n",
    "    _x=x[i:i+seq_length]\n",
    "    _y=y[i+seq_length]\n",
    "    #     _y=Y[i+seq_length:i+seq_length+forecastDays]\n",
    "    print(_x,\"->\",_y)\n",
    "    dataX.append(_x)\n",
    "    dataY.append(_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = int(len(dataY) * 0.7)\n",
    "test_size = len(dataY) - train_size\n",
    "trainX, testX = np.array(dataX[0:train_size]), np.array(dataX[train_size:])\n",
    "trainY, testY = np.array(dataY[0:train_size]), np.array(dataY[train_size:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 input place holders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X의 경우 input type과 [batch size, sequence length, input data dimension(feature+1))]\n",
    "\n",
    "Y의 경우 input type과 [batch size, 원하는 output 의 개수(forecastDays)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=tf.placeholder(tf.float32, [None, seq_length, data_dim])\n",
    "Y=tf.placeholder(tf.float32, [None, forecastDays])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 build LSTM network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lstm network의 \n",
    "\n",
    "    기본단위 cell, \n",
    "    \n",
    "    사용 driver, \n",
    "    \n",
    "    예측 y 산출방식, \n",
    "    \n",
    "    loss 함수, \n",
    "    \n",
    "    사용 optimizer 정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### lstm의 한 기본단위인 cell을 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cell의 결과값을 fully connected layer로 한 번 더 가공할 것이기 때문에 cell의 output dimension인 num_units=hidden_dim로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_dim, state_is_tuple=True, activation=tf.tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_dim, state_is_tuple=True, activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic rnn이라는 driver를 가동"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.dynamic_rnn의 input은 cell, input, input type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.dynamic_rnn의 output은 outputs와 states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs, _states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 마지막 cell의 output과 fully connected layer를  이용하여 Y_pred 도출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputs[:, -1]: cell의 outputs 중 마지막 하나만 이용(we use the last cell's output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_dim: fully connected의 최종출력개수는 output_dim(=forecastDays) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "activation_fn= None: 분류 문제가 아니라 회귀 문제이므로 activation_fn은 none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = tf.contrib.layers.fully_connected(outputs[:, -1], output_dim, activation_fn= None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.square(Y_pred - Y))  # sum of the squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimizer정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss를 줄이는 방향으로 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model 평가 with RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "denormalizedTestY=originalSales[train_size+seq_length:]\n",
    "# denormalizedTestY_original=sales[train_size+seq_length:]\n",
    "denormalizedTestY_feed=np.array([[i] for i in denormalizedTestY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "121 in denormalizedTestY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = tf.placeholder(tf.float32, [None, 1])\n",
    "predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rootMeanSquaredError(a,b):\n",
    "    sum=0\n",
    "    for i in range(len(a)):\n",
    "        sum=sum+(a[i]-b[i])**2\n",
    "    return np.sqrt( sum/len(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 0] loss: 92.15336608886719\n",
      "[step: 1] loss: 71.37467956542969\n",
      "[step: 2] loss: 54.94713592529297\n",
      "[step: 3] loss: 41.997657775878906\n",
      "[step: 4] loss: 31.792631149291992\n",
      "[step: 5] loss: 23.78457260131836\n",
      "[step: 6] loss: 17.61846160888672\n",
      "[step: 7] loss: 13.104969024658203\n",
      "[step: 8] loss: 10.165894508361816\n",
      "[step: 9] loss: 8.75556755065918\n",
      "[step: 10] loss: 8.74187183380127\n",
      "[step: 11] loss: 9.744924545288086\n",
      "[step: 12] loss: 11.090425491333008\n",
      "[step: 13] loss: 12.095087051391602\n",
      "[step: 14] loss: 12.40707778930664\n",
      "[step: 15] loss: 12.042083740234375\n",
      "[step: 16] loss: 11.222620010375977\n",
      "[step: 17] loss: 10.216704368591309\n",
      "[step: 18] loss: 9.243365287780762\n",
      "[step: 19] loss: 8.43898868560791\n",
      "[step: 20] loss: 7.86123514175415\n",
      "[step: 21] loss: 7.509598731994629\n",
      "[step: 22] loss: 7.3487958908081055\n",
      "[step: 23] loss: 7.328001499176025\n",
      "[step: 24] loss: 7.394001007080078\n",
      "[step: 25] loss: 7.498885631561279\n",
      "[step: 26] loss: 7.603890419006348\n",
      "[step: 27] loss: 7.680779933929443\n",
      "[step: 28] loss: 7.711801528930664\n",
      "[step: 29] loss: 7.68878173828125\n",
      "[step: 30] loss: 7.6117143630981445\n",
      "[step: 31] loss: 7.4870476722717285\n",
      "[step: 32] loss: 7.325834274291992\n",
      "[step: 33] loss: 7.1418986320495605\n",
      "[step: 34] loss: 6.950077056884766\n",
      "[step: 35] loss: 6.764636039733887\n",
      "[step: 36] loss: 6.597857475280762\n",
      "[step: 37] loss: 6.4588470458984375\n",
      "[step: 38] loss: 6.352574348449707\n",
      "[step: 39] loss: 6.279234409332275\n",
      "[step: 40] loss: 6.234111309051514\n",
      "[step: 41] loss: 6.2081074714660645\n",
      "[step: 42] loss: 6.189116477966309\n",
      "[step: 43] loss: 6.164210796356201\n",
      "[step: 44] loss: 6.122279167175293\n",
      "[step: 45] loss: 6.056511402130127\n",
      "[step: 46] loss: 5.965939044952393\n",
      "[step: 47] loss: 5.8555216789245605\n",
      "[step: 48] loss: 5.734717845916748\n",
      "[step: 49] loss: 5.614979267120361\n",
      "[step: 50] loss: 5.506885528564453\n",
      "[step: 51] loss: 5.417625904083252\n",
      "[step: 52] loss: 5.349355697631836\n",
      "[step: 53] loss: 5.298814296722412\n",
      "[step: 54] loss: 5.258429050445557\n",
      "[step: 55] loss: 5.218893051147461\n",
      "[step: 56] loss: 5.172687530517578\n",
      "[step: 57] loss: 5.117452621459961\n",
      "[step: 58] loss: 5.057753562927246\n",
      "[step: 59] loss: 5.0041093826293945\n",
      "[step: 60] loss: 4.968864440917969\n",
      "[step: 61] loss: 4.959783554077148\n",
      "[step: 62] loss: 4.974214553833008\n",
      "[step: 63] loss: 4.998528003692627\n",
      "[step: 64] loss: 5.015913963317871\n",
      "[step: 65] loss: 5.017941474914551\n",
      "[step: 66] loss: 5.009409427642822\n",
      "[step: 67] loss: 5.002041816711426\n",
      "[step: 68] loss: 5.003540515899658\n",
      "[step: 69] loss: 5.01170015335083\n",
      "[step: 70] loss: 5.017547607421875\n",
      "[step: 71] loss: 5.013460159301758\n",
      "[step: 72] loss: 4.998765468597412\n",
      "[step: 73] loss: 4.979152679443359\n",
      "[step: 74] loss: 4.961929798126221\n",
      "[step: 75] loss: 4.951366424560547\n",
      "[step: 76] loss: 4.947024345397949\n",
      "[step: 77] loss: 4.9454026222229\n",
      "[step: 78] loss: 4.943027019500732\n",
      "[step: 79] loss: 4.938637733459473\n",
      "[step: 80] loss: 4.933313846588135\n",
      "[step: 81] loss: 4.929078102111816\n",
      "[step: 82] loss: 4.927305698394775\n",
      "[step: 83] loss: 4.927947044372559\n",
      "[step: 84] loss: 4.929774761199951\n",
      "[step: 85] loss: 4.931220054626465\n",
      "[step: 86] loss: 4.931211471557617\n",
      "[step: 87] loss: 4.9295854568481445\n",
      "[step: 88] loss: 4.926948547363281\n",
      "[step: 89] loss: 4.924192905426025\n",
      "[step: 90] loss: 4.921957969665527\n",
      "[step: 91] loss: 4.920338153839111\n",
      "[step: 92] loss: 4.9189324378967285\n",
      "[step: 93] loss: 4.91719388961792\n",
      "[step: 94] loss: 4.914807319641113\n",
      "[step: 95] loss: 4.911889553070068\n",
      "[step: 96] loss: 4.908894062042236\n",
      "[step: 97] loss: 4.906310081481934\n",
      "[step: 98] loss: 4.904376983642578\n",
      "[step: 99] loss: 4.902980327606201\n",
      "[step: 100] loss: 4.901784420013428\n",
      "[step: 101] loss: 4.900472640991211\n",
      "[step: 102] loss: 4.898941516876221\n",
      "[step: 103] loss: 4.897319316864014\n",
      "[step: 104] loss: 4.8958234786987305\n",
      "[step: 105] loss: 4.8945817947387695\n",
      "[step: 106] loss: 4.893530368804932\n",
      "[step: 107] loss: 4.89247465133667\n",
      "[step: 108] loss: 4.891231536865234\n",
      "[step: 109] loss: 4.889751434326172\n",
      "[step: 110] loss: 4.888128280639648\n",
      "[step: 111] loss: 4.886511325836182\n",
      "[step: 112] loss: 4.884993553161621\n",
      "[step: 113] loss: 4.883564472198486\n",
      "[step: 114] loss: 4.882143020629883\n",
      "[step: 115] loss: 4.8806610107421875\n",
      "[step: 116] loss: 4.879112720489502\n",
      "[step: 117] loss: 4.8775529861450195\n",
      "[step: 118] loss: 4.876053810119629\n",
      "[step: 119] loss: 4.874646186828613\n",
      "[step: 120] loss: 4.873307228088379\n",
      "[step: 121] loss: 4.871984958648682\n",
      "[step: 122] loss: 4.87063455581665\n",
      "[step: 123] loss: 4.8692498207092285\n",
      "[step: 124] loss: 4.867855072021484\n",
      "[step: 125] loss: 4.866478443145752\n",
      "[step: 126] loss: 4.865128517150879\n",
      "[step: 127] loss: 4.863790035247803\n",
      "[step: 128] loss: 4.862436771392822\n",
      "[step: 129] loss: 4.86105489730835\n",
      "[step: 130] loss: 4.859647750854492\n",
      "[step: 131] loss: 4.858236789703369\n",
      "[step: 132] loss: 4.856837272644043\n",
      "[step: 133] loss: 4.855454444885254\n",
      "[step: 134] loss: 4.854080677032471\n",
      "[step: 135] loss: 4.852704048156738\n",
      "[step: 136] loss: 4.851320743560791\n",
      "[step: 137] loss: 4.8499345779418945\n",
      "[step: 138] loss: 4.848556995391846\n",
      "[step: 139] loss: 4.847192287445068\n",
      "[step: 140] loss: 4.845839023590088\n",
      "[step: 141] loss: 4.84448766708374\n",
      "[step: 142] loss: 4.843134880065918\n",
      "[step: 143] loss: 4.841776371002197\n",
      "[step: 144] loss: 4.840418815612793\n",
      "[step: 145] loss: 4.839064121246338\n",
      "[step: 146] loss: 4.837715148925781\n",
      "[step: 147] loss: 4.836369514465332\n",
      "[step: 148] loss: 4.835022449493408\n",
      "[step: 149] loss: 4.83367395401001\n",
      "[step: 150] loss: 4.8323259353637695\n",
      "[step: 151] loss: 4.8309807777404785\n",
      "[step: 152] loss: 4.829639911651611\n",
      "[step: 153] loss: 4.828305244445801\n",
      "[step: 154] loss: 4.826972484588623\n",
      "[step: 155] loss: 4.825642108917236\n",
      "[step: 156] loss: 4.824312210083008\n",
      "[step: 157] loss: 4.822986602783203\n",
      "[step: 158] loss: 4.821664810180664\n",
      "[step: 159] loss: 4.820346832275391\n",
      "[step: 160] loss: 4.819032192230225\n",
      "[step: 161] loss: 4.81771993637085\n",
      "[step: 162] loss: 4.816409587860107\n",
      "[step: 163] loss: 4.815101623535156\n",
      "[step: 164] loss: 4.813797473907471\n",
      "[step: 165] loss: 4.812496662139893\n",
      "[step: 166] loss: 4.8111982345581055\n",
      "[step: 167] loss: 4.809903621673584\n",
      "[step: 168] loss: 4.808610916137695\n",
      "[step: 169] loss: 4.807321548461914\n",
      "[step: 170] loss: 4.80603551864624\n",
      "[step: 171] loss: 4.80475378036499\n",
      "[step: 172] loss: 4.803475379943848\n",
      "[step: 173] loss: 4.8022003173828125\n",
      "[step: 174] loss: 4.800929069519043\n",
      "[step: 175] loss: 4.799661159515381\n",
      "[step: 176] loss: 4.798397064208984\n",
      "[step: 177] loss: 4.797137260437012\n",
      "[step: 178] loss: 4.7958807945251465\n",
      "[step: 179] loss: 4.794628620147705\n",
      "[step: 180] loss: 4.793380260467529\n",
      "[step: 181] loss: 4.792135238647461\n",
      "[step: 182] loss: 4.790894508361816\n",
      "[step: 183] loss: 4.789657115936279\n",
      "[step: 184] loss: 4.788424491882324\n",
      "[step: 185] loss: 4.787195682525635\n",
      "[step: 186] loss: 4.785971641540527\n",
      "[step: 187] loss: 4.784750461578369\n",
      "[step: 188] loss: 4.783533573150635\n",
      "[step: 189] loss: 4.782321929931641\n",
      "[step: 190] loss: 4.781113624572754\n",
      "[step: 191] loss: 4.779909610748291\n",
      "[step: 192] loss: 4.77871036529541\n",
      "[step: 193] loss: 4.777514934539795\n",
      "[step: 194] loss: 4.776324272155762\n",
      "[step: 195] loss: 4.775137901306152\n",
      "[step: 196] loss: 4.77395486831665\n",
      "[step: 197] loss: 4.772777080535889\n",
      "[step: 198] loss: 4.771603584289551\n",
      "[step: 199] loss: 4.770434379577637\n",
      "[step: 200] loss: 4.76926851272583\n",
      "[step: 201] loss: 4.768107891082764\n",
      "[step: 202] loss: 4.766952037811279\n",
      "[step: 203] loss: 4.765799522399902\n",
      "[step: 204] loss: 4.764651298522949\n",
      "[step: 205] loss: 4.763508319854736\n",
      "[step: 206] loss: 4.762369155883789\n",
      "[step: 207] loss: 4.761233806610107\n",
      "[step: 208] loss: 4.760103225708008\n",
      "[step: 209] loss: 4.758976936340332\n",
      "[step: 210] loss: 4.75785493850708\n",
      "[step: 211] loss: 4.756736755371094\n",
      "[step: 212] loss: 4.755623817443848\n",
      "[step: 213] loss: 4.754513740539551\n",
      "[step: 214] loss: 4.753408432006836\n",
      "[step: 215] loss: 4.752307415008545\n",
      "[step: 216] loss: 4.7512102127075195\n",
      "[step: 217] loss: 4.750117301940918\n",
      "[step: 218] loss: 4.749027729034424\n",
      "[step: 219] loss: 4.7479424476623535\n",
      "[step: 220] loss: 4.746861457824707\n",
      "[step: 221] loss: 4.745783805847168\n",
      "[step: 222] loss: 4.744710445404053\n",
      "[step: 223] loss: 4.743640422821045\n",
      "[step: 224] loss: 4.742574214935303\n",
      "[step: 225] loss: 4.741511344909668\n",
      "[step: 226] loss: 4.740452289581299\n",
      "[step: 227] loss: 4.739396095275879\n",
      "[step: 228] loss: 4.738343715667725\n",
      "[step: 229] loss: 4.737294673919678\n",
      "[step: 230] loss: 4.736248970031738\n",
      "[step: 231] loss: 4.73520565032959\n",
      "[step: 232] loss: 4.734166145324707\n",
      "[step: 233] loss: 4.733129501342773\n",
      "[step: 234] loss: 4.732095718383789\n",
      "[step: 235] loss: 4.7310638427734375\n",
      "[step: 236] loss: 4.730035305023193\n",
      "[step: 237] loss: 4.729008674621582\n",
      "[step: 238] loss: 4.727985858917236\n",
      "[step: 239] loss: 4.726963996887207\n",
      "[step: 240] loss: 4.725944519042969\n",
      "[step: 241] loss: 4.7249274253845215\n",
      "[step: 242] loss: 4.723912239074707\n",
      "[step: 243] loss: 4.722898960113525\n",
      "[step: 244] loss: 4.72188663482666\n",
      "[step: 245] loss: 4.720876216888428\n",
      "[step: 246] loss: 4.71986722946167\n",
      "[step: 247] loss: 4.7188591957092285\n",
      "[step: 248] loss: 4.71785306930542\n",
      "[step: 249] loss: 4.716846942901611\n",
      "[step: 250] loss: 4.715842247009277\n",
      "[step: 251] loss: 4.714837551116943\n",
      "[step: 252] loss: 4.713833332061768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 253] loss: 4.712830066680908\n",
      "[step: 254] loss: 4.711825847625732\n",
      "[step: 255] loss: 4.710822105407715\n",
      "[step: 256] loss: 4.7098188400268555\n",
      "[step: 257] loss: 4.708813667297363\n",
      "[step: 258] loss: 4.707808494567871\n",
      "[step: 259] loss: 4.706803321838379\n",
      "[step: 260] loss: 4.705796241760254\n",
      "[step: 261] loss: 4.7047882080078125\n",
      "[step: 262] loss: 4.703779220581055\n",
      "[step: 263] loss: 4.702768325805664\n",
      "[step: 264] loss: 4.701755046844482\n",
      "[step: 265] loss: 4.700740814208984\n",
      "[step: 266] loss: 4.699724197387695\n",
      "[step: 267] loss: 4.698705196380615\n",
      "[step: 268] loss: 4.697683334350586\n",
      "[step: 269] loss: 4.696659088134766\n",
      "[step: 270] loss: 4.695631980895996\n",
      "[step: 271] loss: 4.694601535797119\n",
      "[step: 272] loss: 4.693568229675293\n",
      "[step: 273] loss: 4.692530632019043\n",
      "[step: 274] loss: 4.691490650177002\n",
      "[step: 275] loss: 4.690446376800537\n",
      "[step: 276] loss: 4.689398288726807\n",
      "[step: 277] loss: 4.688345909118652\n",
      "[step: 278] loss: 4.687289237976074\n",
      "[step: 279] loss: 4.6862287521362305\n",
      "[step: 280] loss: 4.685163497924805\n",
      "[step: 281] loss: 4.684093952178955\n",
      "[step: 282] loss: 4.683019638061523\n",
      "[step: 283] loss: 4.68194055557251\n",
      "[step: 284] loss: 4.680856704711914\n",
      "[step: 285] loss: 4.6797685623168945\n",
      "[step: 286] loss: 4.678675174713135\n",
      "[step: 287] loss: 4.677577018737793\n",
      "[step: 288] loss: 4.676474571228027\n",
      "[step: 289] loss: 4.6753668785095215\n",
      "[step: 290] loss: 4.67425537109375\n",
      "[step: 291] loss: 4.673139572143555\n",
      "[step: 292] loss: 4.672018527984619\n",
      "[step: 293] loss: 4.670894622802734\n",
      "[step: 294] loss: 4.669766426086426\n",
      "[step: 295] loss: 4.668634414672852\n",
      "[step: 296] loss: 4.667498588562012\n",
      "[step: 297] loss: 4.666360855102539\n",
      "[step: 298] loss: 4.665220260620117\n",
      "[step: 299] loss: 4.664077281951904\n",
      "[step: 300] loss: 4.662933349609375\n",
      "[step: 301] loss: 4.661787986755371\n",
      "[step: 302] loss: 4.660641670227051\n",
      "[step: 303] loss: 4.659496307373047\n",
      "[step: 304] loss: 4.658351421356201\n",
      "[step: 305] loss: 4.657207012176514\n",
      "[step: 306] loss: 4.656065940856934\n",
      "[step: 307] loss: 4.654926776885986\n",
      "[step: 308] loss: 4.653791427612305\n",
      "[step: 309] loss: 4.652660369873047\n",
      "[step: 310] loss: 4.6515350341796875\n",
      "[step: 311] loss: 4.650415897369385\n",
      "[step: 312] loss: 4.649303913116455\n",
      "[step: 313] loss: 4.648200035095215\n",
      "[step: 314] loss: 4.647104740142822\n",
      "[step: 315] loss: 4.64601993560791\n",
      "[step: 316] loss: 4.644946098327637\n",
      "[step: 317] loss: 4.64388370513916\n",
      "[step: 318] loss: 4.6428351402282715\n",
      "[step: 319] loss: 4.6417999267578125\n",
      "[step: 320] loss: 4.640779495239258\n",
      "[step: 321] loss: 4.639774799346924\n",
      "[step: 322] loss: 4.638787269592285\n",
      "[step: 323] loss: 4.637816905975342\n",
      "[step: 324] loss: 4.63686466217041\n",
      "[step: 325] loss: 4.635931015014648\n",
      "[step: 326] loss: 4.6350178718566895\n",
      "[step: 327] loss: 4.634124279022217\n",
      "[step: 328] loss: 4.633252143859863\n",
      "[step: 329] loss: 4.632401466369629\n",
      "[step: 330] loss: 4.6315717697143555\n",
      "[step: 331] loss: 4.630764484405518\n",
      "[step: 332] loss: 4.629979133605957\n",
      "[step: 333] loss: 4.62921667098999\n",
      "[step: 334] loss: 4.628476142883301\n",
      "[step: 335] loss: 4.627758026123047\n",
      "[step: 336] loss: 4.6270623207092285\n",
      "[step: 337] loss: 4.6263885498046875\n",
      "[step: 338] loss: 4.625736236572266\n",
      "[step: 339] loss: 4.625105381011963\n",
      "[step: 340] loss: 4.624495506286621\n",
      "[step: 341] loss: 4.623905181884766\n",
      "[step: 342] loss: 4.623335361480713\n",
      "[step: 343] loss: 4.622783660888672\n",
      "[step: 344] loss: 4.622250556945801\n",
      "[step: 345] loss: 4.621734619140625\n",
      "[step: 346] loss: 4.621235370635986\n",
      "[step: 347] loss: 4.620751857757568\n",
      "[step: 348] loss: 4.620282173156738\n",
      "[step: 349] loss: 4.6198272705078125\n",
      "[step: 350] loss: 4.619384765625\n",
      "[step: 351] loss: 4.618954181671143\n",
      "[step: 352] loss: 4.618535041809082\n",
      "[step: 353] loss: 4.6181254386901855\n",
      "[step: 354] loss: 4.617725372314453\n",
      "[step: 355] loss: 4.61733341217041\n",
      "[step: 356] loss: 4.616949081420898\n",
      "[step: 357] loss: 4.61657190322876\n",
      "[step: 358] loss: 4.616199493408203\n",
      "[step: 359] loss: 4.615833282470703\n",
      "[step: 360] loss: 4.615471363067627\n",
      "[step: 361] loss: 4.615113258361816\n",
      "[step: 362] loss: 4.614758491516113\n",
      "[step: 363] loss: 4.614406585693359\n",
      "[step: 364] loss: 4.61405611038208\n",
      "[step: 365] loss: 4.613708019256592\n",
      "[step: 366] loss: 4.613361835479736\n",
      "[step: 367] loss: 4.613016128540039\n",
      "[step: 368] loss: 4.612671852111816\n",
      "[step: 369] loss: 4.612328052520752\n",
      "[step: 370] loss: 4.6119842529296875\n",
      "[step: 371] loss: 4.611640930175781\n",
      "[step: 372] loss: 4.611297607421875\n",
      "[step: 373] loss: 4.610953330993652\n",
      "[step: 374] loss: 4.61060905456543\n",
      "[step: 375] loss: 4.610264778137207\n",
      "[step: 376] loss: 4.609919548034668\n",
      "[step: 377] loss: 4.609574317932129\n",
      "[step: 378] loss: 4.609228134155273\n",
      "[step: 379] loss: 4.60888147354126\n",
      "[step: 380] loss: 4.608534336090088\n",
      "[step: 381] loss: 4.608186721801758\n",
      "[step: 382] loss: 4.607838153839111\n",
      "[step: 383] loss: 4.607489585876465\n",
      "[step: 384] loss: 4.6071391105651855\n",
      "[step: 385] loss: 4.606789588928223\n",
      "[step: 386] loss: 4.606438636779785\n",
      "[step: 387] loss: 4.606087684631348\n",
      "[step: 388] loss: 4.6057353019714355\n",
      "[step: 389] loss: 4.605382919311523\n",
      "[step: 390] loss: 4.605030059814453\n",
      "[step: 391] loss: 4.604676723480225\n",
      "[step: 392] loss: 4.60432243347168\n",
      "[step: 393] loss: 4.603968143463135\n",
      "[step: 394] loss: 4.603611946105957\n",
      "[step: 395] loss: 4.603257179260254\n",
      "[step: 396] loss: 4.602900505065918\n",
      "[step: 397] loss: 4.602543830871582\n",
      "[step: 398] loss: 4.602186679840088\n",
      "[step: 399] loss: 4.6018290519714355\n",
      "[step: 400] loss: 4.601469993591309\n",
      "[step: 401] loss: 4.60111141204834\n",
      "[step: 402] loss: 4.6007513999938965\n",
      "[step: 403] loss: 4.600391387939453\n",
      "[step: 404] loss: 4.600029468536377\n",
      "[step: 405] loss: 4.599668502807617\n",
      "[step: 406] loss: 4.599306106567383\n",
      "[step: 407] loss: 4.59894323348999\n",
      "[step: 408] loss: 4.598579406738281\n",
      "[step: 409] loss: 4.598214626312256\n",
      "[step: 410] loss: 4.597849369049072\n",
      "[step: 411] loss: 4.5974836349487305\n",
      "[step: 412] loss: 4.597116470336914\n",
      "[step: 413] loss: 4.596749305725098\n",
      "[step: 414] loss: 4.596381664276123\n",
      "[step: 415] loss: 4.596011638641357\n",
      "[step: 416] loss: 4.595641613006592\n",
      "[step: 417] loss: 4.595271110534668\n",
      "[step: 418] loss: 4.5948991775512695\n",
      "[step: 419] loss: 4.594527244567871\n",
      "[step: 420] loss: 4.594152927398682\n",
      "[step: 421] loss: 4.593778610229492\n",
      "[step: 422] loss: 4.593403339385986\n",
      "[step: 423] loss: 4.593026638031006\n",
      "[step: 424] loss: 4.592649936676025\n",
      "[step: 425] loss: 4.59227180480957\n",
      "[step: 426] loss: 4.591892242431641\n",
      "[step: 427] loss: 4.5915117263793945\n",
      "[step: 428] loss: 4.59113073348999\n",
      "[step: 429] loss: 4.5907487869262695\n",
      "[step: 430] loss: 4.590365409851074\n",
      "[step: 431] loss: 4.5899810791015625\n",
      "[step: 432] loss: 4.589594841003418\n",
      "[step: 433] loss: 4.589209079742432\n",
      "[step: 434] loss: 4.588820934295654\n",
      "[step: 435] loss: 4.588432312011719\n",
      "[step: 436] loss: 4.588042259216309\n",
      "[step: 437] loss: 4.587651252746582\n",
      "[step: 438] loss: 4.587259292602539\n",
      "[step: 439] loss: 4.58686637878418\n",
      "[step: 440] loss: 4.586471080780029\n",
      "[step: 441] loss: 4.586075782775879\n",
      "[step: 442] loss: 4.5856781005859375\n",
      "[step: 443] loss: 4.585280418395996\n",
      "[step: 444] loss: 4.584880352020264\n",
      "[step: 445] loss: 4.584480285644531\n",
      "[step: 446] loss: 4.584078311920166\n",
      "[step: 447] loss: 4.583674430847168\n",
      "[step: 448] loss: 4.583270072937012\n",
      "[step: 449] loss: 4.582864284515381\n",
      "[step: 450] loss: 4.582457542419434\n",
      "[step: 451] loss: 4.582048416137695\n",
      "[step: 452] loss: 4.581637859344482\n",
      "[step: 453] loss: 4.581226825714111\n",
      "[step: 454] loss: 4.580814361572266\n",
      "[step: 455] loss: 4.580399513244629\n",
      "[step: 456] loss: 4.579984188079834\n",
      "[step: 457] loss: 4.579566955566406\n",
      "[step: 458] loss: 4.579148292541504\n",
      "[step: 459] loss: 4.578728199005127\n",
      "[step: 460] loss: 4.578306198120117\n",
      "[step: 461] loss: 4.577883720397949\n",
      "[step: 462] loss: 4.577458381652832\n",
      "[step: 463] loss: 4.577032089233398\n",
      "[step: 464] loss: 4.576603889465332\n",
      "[step: 465] loss: 4.576174736022949\n",
      "[step: 466] loss: 4.575743198394775\n",
      "[step: 467] loss: 4.575311183929443\n",
      "[step: 468] loss: 4.57487678527832\n",
      "[step: 469] loss: 4.5744404792785645\n",
      "[step: 470] loss: 4.574002742767334\n",
      "[step: 471] loss: 4.573563098907471\n",
      "[step: 472] loss: 4.573122024536133\n",
      "[step: 473] loss: 4.572679042816162\n",
      "[step: 474] loss: 4.572234630584717\n",
      "[step: 475] loss: 4.5717878341674805\n",
      "[step: 476] loss: 4.5713396072387695\n",
      "[step: 477] loss: 4.570889472961426\n",
      "[step: 478] loss: 4.570437908172607\n",
      "[step: 479] loss: 4.569983959197998\n",
      "[step: 480] loss: 4.569528102874756\n",
      "[step: 481] loss: 4.569069862365723\n",
      "[step: 482] loss: 4.568610668182373\n",
      "[step: 483] loss: 4.568149089813232\n",
      "[step: 484] loss: 4.567686080932617\n",
      "[step: 485] loss: 4.5672197341918945\n",
      "[step: 486] loss: 4.5667524337768555\n",
      "[step: 487] loss: 4.566283226013184\n",
      "[step: 488] loss: 4.565811634063721\n",
      "[step: 489] loss: 4.565337657928467\n",
      "[step: 490] loss: 4.56486177444458\n",
      "[step: 491] loss: 4.5643839836120605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 492] loss: 4.56390380859375\n",
      "[step: 493] loss: 4.563421249389648\n",
      "[step: 494] loss: 4.562937259674072\n",
      "[step: 495] loss: 4.562450885772705\n",
      "[step: 496] loss: 4.561962127685547\n",
      "[step: 497] loss: 4.561470985412598\n",
      "[step: 498] loss: 4.560976982116699\n",
      "[step: 499] loss: 4.560481071472168\n",
      "[step: 500] loss: 4.559983253479004\n",
      "[step: 501] loss: 4.559483051300049\n",
      "[step: 502] loss: 4.558980464935303\n",
      "[step: 503] loss: 4.558475017547607\n",
      "[step: 504] loss: 4.557967185974121\n",
      "[step: 505] loss: 4.5574564933776855\n",
      "[step: 506] loss: 4.556944370269775\n",
      "[step: 507] loss: 4.556429386138916\n",
      "[step: 508] loss: 4.555912017822266\n",
      "[step: 509] loss: 4.555391788482666\n",
      "[step: 510] loss: 4.554868698120117\n",
      "[step: 511] loss: 4.5543437004089355\n",
      "[step: 512] loss: 4.553815841674805\n",
      "[step: 513] loss: 4.553285598754883\n",
      "[step: 514] loss: 4.5527520179748535\n",
      "[step: 515] loss: 4.552215576171875\n",
      "[step: 516] loss: 4.551677703857422\n",
      "[step: 517] loss: 4.551136493682861\n",
      "[step: 518] loss: 4.550591945648193\n",
      "[step: 519] loss: 4.550045490264893\n",
      "[step: 520] loss: 4.549495220184326\n",
      "[step: 521] loss: 4.548942565917969\n",
      "[step: 522] loss: 4.548387050628662\n",
      "[step: 523] loss: 4.5478291511535645\n",
      "[step: 524] loss: 4.547267436981201\n",
      "[step: 525] loss: 4.546703338623047\n",
      "[step: 526] loss: 4.546135902404785\n",
      "[step: 527] loss: 4.545565128326416\n",
      "[step: 528] loss: 4.544991970062256\n",
      "[step: 529] loss: 4.544415473937988\n",
      "[step: 530] loss: 4.543835639953613\n",
      "[step: 531] loss: 4.543252944946289\n",
      "[step: 532] loss: 4.542667865753174\n",
      "[step: 533] loss: 4.542078971862793\n",
      "[step: 534] loss: 4.541486740112305\n",
      "[step: 535] loss: 4.540891647338867\n",
      "[step: 536] loss: 4.540292739868164\n",
      "[step: 537] loss: 4.539690971374512\n",
      "[step: 538] loss: 4.539085388183594\n",
      "[step: 539] loss: 4.538477897644043\n",
      "[step: 540] loss: 4.53786563873291\n",
      "[step: 541] loss: 4.5372514724731445\n",
      "[step: 542] loss: 4.536632537841797\n",
      "[step: 543] loss: 4.536010265350342\n",
      "[step: 544] loss: 4.535385608673096\n",
      "[step: 545] loss: 4.534756660461426\n",
      "[step: 546] loss: 4.53412389755249\n",
      "[step: 547] loss: 4.533487796783447\n",
      "[step: 548] loss: 4.532849311828613\n",
      "[step: 549] loss: 4.532206058502197\n",
      "[step: 550] loss: 4.531558990478516\n",
      "[step: 551] loss: 4.530909061431885\n",
      "[step: 552] loss: 4.5302557945251465\n",
      "[step: 553] loss: 4.529598712921143\n",
      "[step: 554] loss: 4.528937339782715\n",
      "[step: 555] loss: 4.52827262878418\n",
      "[step: 556] loss: 4.527604579925537\n",
      "[step: 557] loss: 4.526932239532471\n",
      "[step: 558] loss: 4.526256561279297\n",
      "[step: 559] loss: 4.525577068328857\n",
      "[step: 560] loss: 4.524893760681152\n",
      "[step: 561] loss: 4.524206638336182\n",
      "[step: 562] loss: 4.523515224456787\n",
      "[step: 563] loss: 4.522820472717285\n",
      "[step: 564] loss: 4.522121429443359\n",
      "[step: 565] loss: 4.521419048309326\n",
      "[step: 566] loss: 4.5207133293151855\n",
      "[step: 567] loss: 4.520002365112305\n",
      "[step: 568] loss: 4.519288539886475\n",
      "[step: 569] loss: 4.518569469451904\n",
      "[step: 570] loss: 4.517848014831543\n",
      "[step: 571] loss: 4.517122268676758\n",
      "[step: 572] loss: 4.516392230987549\n",
      "[step: 573] loss: 4.515658378601074\n",
      "[step: 574] loss: 4.514920234680176\n",
      "[step: 575] loss: 4.514178276062012\n",
      "[step: 576] loss: 4.513432502746582\n",
      "[step: 577] loss: 4.512682914733887\n",
      "[step: 578] loss: 4.511929035186768\n",
      "[step: 579] loss: 4.511171340942383\n",
      "[step: 580] loss: 4.510409355163574\n",
      "[step: 581] loss: 4.5096435546875\n",
      "[step: 582] loss: 4.508873462677002\n",
      "[step: 583] loss: 4.508099555969238\n",
      "[step: 584] loss: 4.507321357727051\n",
      "[step: 585] loss: 4.506539821624756\n",
      "[step: 586] loss: 4.505753517150879\n",
      "[step: 587] loss: 4.5049638748168945\n",
      "[step: 588] loss: 4.504169940948486\n",
      "[step: 589] loss: 4.503372669219971\n",
      "[step: 590] loss: 4.502570629119873\n",
      "[step: 591] loss: 4.501764297485352\n",
      "[step: 592] loss: 4.5009541511535645\n",
      "[step: 593] loss: 4.500141143798828\n",
      "[step: 594] loss: 4.499322891235352\n",
      "[step: 595] loss: 4.498501300811768\n",
      "[step: 596] loss: 4.497675895690918\n",
      "[step: 597] loss: 4.4968461990356445\n",
      "[step: 598] loss: 4.496013164520264\n",
      "[step: 599] loss: 4.495175838470459\n",
      "[step: 600] loss: 4.494334697723389\n",
      "[step: 601] loss: 4.493490219116211\n",
      "[step: 602] loss: 4.492640972137451\n",
      "[step: 603] loss: 4.491788387298584\n",
      "[step: 604] loss: 4.490932464599609\n",
      "[step: 605] loss: 4.490072250366211\n",
      "[step: 606] loss: 4.489208698272705\n",
      "[step: 607] loss: 4.488341331481934\n",
      "[step: 608] loss: 4.487470626831055\n",
      "[step: 609] loss: 4.486595630645752\n",
      "[step: 610] loss: 4.485716819763184\n",
      "[step: 611] loss: 4.484835147857666\n",
      "[step: 612] loss: 4.483949661254883\n",
      "[step: 613] loss: 4.483060836791992\n",
      "[step: 614] loss: 4.482168197631836\n",
      "[step: 615] loss: 4.4812726974487305\n",
      "[step: 616] loss: 4.480373382568359\n",
      "[step: 617] loss: 4.479470729827881\n",
      "[step: 618] loss: 4.478564262390137\n",
      "[step: 619] loss: 4.47765588760376\n",
      "[step: 620] loss: 4.476742744445801\n",
      "[step: 621] loss: 4.475827217102051\n",
      "[step: 622] loss: 4.474908351898193\n",
      "[step: 623] loss: 4.473987102508545\n",
      "[step: 624] loss: 4.473062038421631\n",
      "[step: 625] loss: 4.472133159637451\n",
      "[step: 626] loss: 4.471202850341797\n",
      "[step: 627] loss: 4.470268726348877\n",
      "[step: 628] loss: 4.469331741333008\n",
      "[step: 629] loss: 4.4683918952941895\n",
      "[step: 630] loss: 4.467449188232422\n",
      "[step: 631] loss: 4.466504096984863\n",
      "[step: 632] loss: 4.4655561447143555\n",
      "[step: 633] loss: 4.464605331420898\n",
      "[step: 634] loss: 4.463652610778809\n",
      "[step: 635] loss: 4.462696075439453\n",
      "[step: 636] loss: 4.461738109588623\n",
      "[step: 637] loss: 4.460777282714844\n",
      "[step: 638] loss: 4.459814071655273\n",
      "[step: 639] loss: 4.458848476409912\n",
      "[step: 640] loss: 4.457880973815918\n",
      "[step: 641] loss: 4.456910610198975\n",
      "[step: 642] loss: 4.455937385559082\n",
      "[step: 643] loss: 4.454963684082031\n",
      "[step: 644] loss: 4.453987121582031\n",
      "[step: 645] loss: 4.45300817489624\n",
      "[step: 646] loss: 4.452028274536133\n",
      "[step: 647] loss: 4.451045036315918\n",
      "[step: 648] loss: 4.450060844421387\n",
      "[step: 649] loss: 4.4490742683410645\n",
      "[step: 650] loss: 4.448086261749268\n",
      "[step: 651] loss: 4.447096347808838\n",
      "[step: 652] loss: 4.446104526519775\n",
      "[step: 653] loss: 4.4451117515563965\n",
      "[step: 654] loss: 4.444117069244385\n",
      "[step: 655] loss: 4.44312047958374\n",
      "[step: 656] loss: 4.442122459411621\n",
      "[step: 657] loss: 4.441123962402344\n",
      "[step: 658] loss: 4.440123081207275\n",
      "[step: 659] loss: 4.439120769500732\n",
      "[step: 660] loss: 4.438117980957031\n",
      "[step: 661] loss: 4.437113285064697\n",
      "[step: 662] loss: 4.436107635498047\n",
      "[step: 663] loss: 4.43510103225708\n",
      "[step: 664] loss: 4.434092998504639\n",
      "[step: 665] loss: 4.433084011077881\n",
      "[step: 666] loss: 4.432074069976807\n",
      "[step: 667] loss: 4.431063175201416\n",
      "[step: 668] loss: 4.430051326751709\n",
      "[step: 669] loss: 4.429039001464844\n",
      "[step: 670] loss: 4.428025245666504\n",
      "[step: 671] loss: 4.427011966705322\n",
      "[step: 672] loss: 4.425996780395508\n",
      "[step: 673] loss: 4.424981117248535\n",
      "[step: 674] loss: 4.423964977264404\n",
      "[step: 675] loss: 4.422947883605957\n",
      "[step: 676] loss: 4.421930313110352\n",
      "[step: 677] loss: 4.420912742614746\n",
      "[step: 678] loss: 4.419894218444824\n",
      "[step: 679] loss: 4.418875217437744\n",
      "[step: 680] loss: 4.417856216430664\n",
      "[step: 681] loss: 4.416836261749268\n",
      "[step: 682] loss: 4.415816783905029\n",
      "[step: 683] loss: 4.414795875549316\n",
      "[step: 684] loss: 4.413775444030762\n",
      "[step: 685] loss: 4.412755012512207\n",
      "[step: 686] loss: 4.411734104156494\n",
      "[step: 687] loss: 4.410713195800781\n",
      "[step: 688] loss: 4.40969181060791\n",
      "[step: 689] loss: 4.408669471740723\n",
      "[step: 690] loss: 4.407649040222168\n",
      "[step: 691] loss: 4.406627178192139\n",
      "[step: 692] loss: 4.405605792999268\n",
      "[step: 693] loss: 4.404583930969238\n",
      "[step: 694] loss: 4.403563022613525\n",
      "[step: 695] loss: 4.402541637420654\n",
      "[step: 696] loss: 4.401519775390625\n",
      "[step: 697] loss: 4.400498390197754\n",
      "[step: 698] loss: 4.399477958679199\n",
      "[step: 699] loss: 4.398456573486328\n",
      "[step: 700] loss: 4.397435665130615\n",
      "[step: 701] loss: 4.396414756774902\n",
      "[step: 702] loss: 4.395394325256348\n",
      "[step: 703] loss: 4.394373893737793\n",
      "[step: 704] loss: 4.393353462219238\n",
      "[step: 705] loss: 4.392333984375\n",
      "[step: 706] loss: 4.391314506530762\n",
      "[step: 707] loss: 4.390294075012207\n",
      "[step: 708] loss: 4.389275074005127\n",
      "[step: 709] loss: 4.3882551193237305\n",
      "[step: 710] loss: 4.387236595153809\n",
      "[step: 711] loss: 4.3862175941467285\n",
      "[step: 712] loss: 4.385198593139648\n",
      "[step: 713] loss: 4.384180545806885\n",
      "[step: 714] loss: 4.383162021636963\n",
      "[step: 715] loss: 4.382143974304199\n",
      "[step: 716] loss: 4.3811259269714355\n",
      "[step: 717] loss: 4.38010835647583\n",
      "[step: 718] loss: 4.379090309143066\n",
      "[step: 719] loss: 4.378072261810303\n",
      "[step: 720] loss: 4.3770551681518555\n",
      "[step: 721] loss: 4.376037120819092\n",
      "[step: 722] loss: 4.3750200271606445\n",
      "[step: 723] loss: 4.374002456665039\n",
      "[step: 724] loss: 4.372984886169434\n",
      "[step: 725] loss: 4.371967315673828\n",
      "[step: 726] loss: 4.370950222015381\n",
      "[step: 727] loss: 4.369932174682617\n",
      "[step: 728] loss: 4.3689141273498535\n",
      "[step: 729] loss: 4.36789608001709\n",
      "[step: 730] loss: 4.366878032684326\n",
      "[step: 731] loss: 4.365859031677246\n",
      "[step: 732] loss: 4.364840030670166\n",
      "[step: 733] loss: 4.363821029663086\n",
      "[step: 734] loss: 4.362800598144531\n",
      "[step: 735] loss: 4.361781120300293\n",
      "[step: 736] loss: 4.360760688781738\n",
      "[step: 737] loss: 4.359739303588867\n",
      "[step: 738] loss: 4.358717441558838\n",
      "[step: 739] loss: 4.357694625854492\n",
      "[step: 740] loss: 4.356671333312988\n",
      "[step: 741] loss: 4.355648040771484\n",
      "[step: 742] loss: 4.354622840881348\n",
      "[step: 743] loss: 4.353597164154053\n",
      "[step: 744] loss: 4.3525710105896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 745] loss: 4.351542949676514\n",
      "[step: 746] loss: 4.350513935089111\n",
      "[step: 747] loss: 4.349484443664551\n",
      "[step: 748] loss: 4.348453521728516\n",
      "[step: 749] loss: 4.347420692443848\n",
      "[step: 750] loss: 4.3463873863220215\n",
      "[step: 751] loss: 4.3453521728515625\n",
      "[step: 752] loss: 4.344316005706787\n",
      "[step: 753] loss: 4.343277931213379\n",
      "[step: 754] loss: 4.342237949371338\n",
      "[step: 755] loss: 4.3411970138549805\n",
      "[step: 756] loss: 4.34015417098999\n",
      "[step: 757] loss: 4.339109420776367\n",
      "[step: 758] loss: 4.338062286376953\n",
      "[step: 759] loss: 4.3370137214660645\n",
      "[step: 760] loss: 4.335963249206543\n",
      "[step: 761] loss: 4.334909915924072\n",
      "[step: 762] loss: 4.333854675292969\n",
      "[step: 763] loss: 4.332798004150391\n",
      "[step: 764] loss: 4.331738471984863\n",
      "[step: 765] loss: 4.330676555633545\n",
      "[step: 766] loss: 4.329611778259277\n",
      "[step: 767] loss: 4.328545093536377\n",
      "[step: 768] loss: 4.327475547790527\n",
      "[step: 769] loss: 4.3264031410217285\n",
      "[step: 770] loss: 4.3253278732299805\n",
      "[step: 771] loss: 4.324250221252441\n",
      "[step: 772] loss: 4.323169708251953\n",
      "[step: 773] loss: 4.322085380554199\n",
      "[step: 774] loss: 4.320998668670654\n",
      "[step: 775] loss: 4.31990909576416\n",
      "[step: 776] loss: 4.3188157081604\n",
      "[step: 777] loss: 4.317719459533691\n",
      "[step: 778] loss: 4.316619873046875\n",
      "[step: 779] loss: 4.315516471862793\n",
      "[step: 780] loss: 4.314410209655762\n",
      "[step: 781] loss: 4.313299655914307\n",
      "[step: 782] loss: 4.312185764312744\n",
      "[step: 783] loss: 4.311068534851074\n",
      "[step: 784] loss: 4.309947490692139\n",
      "[step: 785] loss: 4.308822154998779\n",
      "[step: 786] loss: 4.3076934814453125\n",
      "[step: 787] loss: 4.306560516357422\n",
      "[step: 788] loss: 4.305424213409424\n",
      "[step: 789] loss: 4.304283142089844\n",
      "[step: 790] loss: 4.30313777923584\n",
      "[step: 791] loss: 4.301988124847412\n",
      "[step: 792] loss: 4.300835132598877\n",
      "[step: 793] loss: 4.299676895141602\n",
      "[step: 794] loss: 4.2985148429870605\n",
      "[step: 795] loss: 4.297348976135254\n",
      "[step: 796] loss: 4.296176910400391\n",
      "[step: 797] loss: 4.295001983642578\n",
      "[step: 798] loss: 4.293821334838867\n",
      "[step: 799] loss: 4.292635917663574\n",
      "[step: 800] loss: 4.291446208953857\n",
      "[step: 801] loss: 4.290251731872559\n",
      "[step: 802] loss: 4.2890520095825195\n",
      "[step: 803] loss: 4.287847995758057\n",
      "[step: 804] loss: 4.286638259887695\n",
      "[step: 805] loss: 4.28542423248291\n",
      "[step: 806] loss: 4.284205436706543\n",
      "[step: 807] loss: 4.282980918884277\n",
      "[step: 808] loss: 4.2817511558532715\n",
      "[step: 809] loss: 4.280516624450684\n",
      "[step: 810] loss: 4.279276371002197\n",
      "[step: 811] loss: 4.278031349182129\n",
      "[step: 812] loss: 4.276780605316162\n",
      "[step: 813] loss: 4.275525093078613\n",
      "[step: 814] loss: 4.274263858795166\n",
      "[step: 815] loss: 4.2729973793029785\n",
      "[step: 816] loss: 4.271725654602051\n",
      "[step: 817] loss: 4.270448684692383\n",
      "[step: 818] loss: 4.269164562225342\n",
      "[step: 819] loss: 4.267876148223877\n",
      "[step: 820] loss: 4.266582489013672\n",
      "[step: 821] loss: 4.26528263092041\n",
      "[step: 822] loss: 4.26397705078125\n",
      "[step: 823] loss: 4.262665748596191\n",
      "[step: 824] loss: 4.261349201202393\n",
      "[step: 825] loss: 4.260026931762695\n",
      "[step: 826] loss: 4.258699417114258\n",
      "[step: 827] loss: 4.257366180419922\n",
      "[step: 828] loss: 4.256026268005371\n",
      "[step: 829] loss: 4.254681587219238\n",
      "[step: 830] loss: 4.253331184387207\n",
      "[step: 831] loss: 4.251974582672119\n",
      "[step: 832] loss: 4.250612735748291\n",
      "[step: 833] loss: 4.2492451667785645\n",
      "[step: 834] loss: 4.247871398925781\n",
      "[step: 835] loss: 4.246492862701416\n",
      "[step: 836] loss: 4.245107650756836\n",
      "[step: 837] loss: 4.24371862411499\n",
      "[step: 838] loss: 4.24232292175293\n",
      "[step: 839] loss: 4.240921497344971\n",
      "[step: 840] loss: 4.2395148277282715\n",
      "[step: 841] loss: 4.238102436065674\n",
      "[step: 842] loss: 4.236685276031494\n",
      "[step: 843] loss: 4.235261917114258\n",
      "[step: 844] loss: 4.233833312988281\n",
      "[step: 845] loss: 4.232400417327881\n",
      "[step: 846] loss: 4.230961799621582\n",
      "[step: 847] loss: 4.229517936706543\n",
      "[step: 848] loss: 4.228069305419922\n",
      "[step: 849] loss: 4.2266154289245605\n",
      "[step: 850] loss: 4.225156784057617\n",
      "[step: 851] loss: 4.223693370819092\n",
      "[step: 852] loss: 4.222226142883301\n",
      "[step: 853] loss: 4.220752716064453\n",
      "[step: 854] loss: 4.21927547454834\n",
      "[step: 855] loss: 4.217794418334961\n",
      "[step: 856] loss: 4.216308116912842\n",
      "[step: 857] loss: 4.214818000793457\n",
      "[step: 858] loss: 4.213324069976807\n",
      "[step: 859] loss: 4.211825847625732\n",
      "[step: 860] loss: 4.210323810577393\n",
      "[step: 861] loss: 4.208818435668945\n",
      "[step: 862] loss: 4.207309246063232\n",
      "[step: 863] loss: 4.2057976722717285\n",
      "[step: 864] loss: 4.204281806945801\n",
      "[step: 865] loss: 4.202763557434082\n",
      "[step: 866] loss: 4.201241493225098\n",
      "[step: 867] loss: 4.1997175216674805\n",
      "[step: 868] loss: 4.198190689086914\n",
      "[step: 869] loss: 4.196661472320557\n",
      "[step: 870] loss: 4.195130348205566\n",
      "[step: 871] loss: 4.193596839904785\n",
      "[step: 872] loss: 4.192061424255371\n",
      "[step: 873] loss: 4.190524578094482\n",
      "[step: 874] loss: 4.188985824584961\n",
      "[step: 875] loss: 4.187446117401123\n",
      "[step: 876] loss: 4.1859049797058105\n",
      "[step: 877] loss: 4.18436336517334\n",
      "[step: 878] loss: 4.182820796966553\n",
      "[step: 879] loss: 4.181277275085449\n",
      "[step: 880] loss: 4.179734230041504\n",
      "[step: 881] loss: 4.178190231323242\n",
      "[step: 882] loss: 4.176646709442139\n",
      "[step: 883] loss: 4.175103187561035\n",
      "[step: 884] loss: 4.17356014251709\n",
      "[step: 885] loss: 4.1720170974731445\n",
      "[step: 886] loss: 4.170475482940674\n",
      "[step: 887] loss: 4.1689348220825195\n",
      "[step: 888] loss: 4.167395114898682\n",
      "[step: 889] loss: 4.165856838226318\n",
      "[step: 890] loss: 4.16431999206543\n",
      "[step: 891] loss: 4.162784576416016\n",
      "[step: 892] loss: 4.161250591278076\n",
      "[step: 893] loss: 4.159719467163086\n",
      "[step: 894] loss: 4.158189296722412\n",
      "[step: 895] loss: 4.156662464141846\n",
      "[step: 896] loss: 4.155137062072754\n",
      "[step: 897] loss: 4.153614521026611\n",
      "[step: 898] loss: 4.152094841003418\n",
      "[step: 899] loss: 4.150577545166016\n",
      "[step: 900] loss: 4.1490631103515625\n",
      "[step: 901] loss: 4.147551536560059\n",
      "[step: 902] loss: 4.146042823791504\n",
      "[step: 903] loss: 4.144537448883057\n",
      "[step: 904] loss: 4.143035411834717\n",
      "[step: 905] loss: 4.141535758972168\n",
      "[step: 906] loss: 4.140040874481201\n",
      "[step: 907] loss: 4.138547897338867\n",
      "[step: 908] loss: 4.137058734893799\n",
      "[step: 909] loss: 4.135573387145996\n",
      "[step: 910] loss: 4.134091377258301\n",
      "[step: 911] loss: 4.132613182067871\n",
      "[step: 912] loss: 4.131137847900391\n",
      "[step: 913] loss: 4.129666328430176\n",
      "[step: 914] loss: 4.128198146820068\n",
      "[step: 915] loss: 4.126733303070068\n",
      "[step: 916] loss: 4.125272274017334\n",
      "[step: 917] loss: 4.123814582824707\n",
      "[step: 918] loss: 4.122360706329346\n",
      "[step: 919] loss: 4.120909690856934\n",
      "[step: 920] loss: 4.119462490081787\n",
      "[step: 921] loss: 4.118018627166748\n",
      "[step: 922] loss: 4.116577625274658\n",
      "[step: 923] loss: 4.115140438079834\n",
      "[step: 924] loss: 4.113706111907959\n",
      "[step: 925] loss: 4.112275123596191\n",
      "[step: 926] loss: 4.110846519470215\n",
      "[step: 927] loss: 4.109422206878662\n",
      "[step: 928] loss: 4.1080002784729\n",
      "[step: 929] loss: 4.106581211090088\n",
      "[step: 930] loss: 4.105165004730225\n",
      "[step: 931] loss: 4.103752136230469\n",
      "[step: 932] loss: 4.102341651916504\n",
      "[step: 933] loss: 4.10093355178833\n",
      "[step: 934] loss: 4.099528789520264\n",
      "[step: 935] loss: 4.09812593460083\n",
      "[step: 936] loss: 4.096725940704346\n",
      "[step: 937] loss: 4.095328330993652\n",
      "[step: 938] loss: 4.093933582305908\n",
      "[step: 939] loss: 4.092540740966797\n",
      "[step: 940] loss: 4.091150283813477\n",
      "[step: 941] loss: 4.089762210845947\n",
      "[step: 942] loss: 4.088376522064209\n",
      "[step: 943] loss: 4.0869927406311035\n",
      "[step: 944] loss: 4.085611343383789\n",
      "[step: 945] loss: 4.084232330322266\n",
      "[step: 946] loss: 4.082854270935059\n",
      "[step: 947] loss: 4.081480026245117\n",
      "[step: 948] loss: 4.080106735229492\n",
      "[step: 949] loss: 4.0787353515625\n",
      "[step: 950] loss: 4.077366352081299\n",
      "[step: 951] loss: 4.075998783111572\n",
      "[step: 952] loss: 4.074634075164795\n",
      "[step: 953] loss: 4.073270320892334\n",
      "[step: 954] loss: 4.071909427642822\n",
      "[step: 955] loss: 4.070549964904785\n",
      "[step: 956] loss: 4.069192886352539\n",
      "[step: 957] loss: 4.067837238311768\n",
      "[step: 958] loss: 4.066483497619629\n",
      "[step: 959] loss: 4.065131664276123\n",
      "[step: 960] loss: 4.06378173828125\n",
      "[step: 961] loss: 4.062434196472168\n",
      "[step: 962] loss: 4.061088562011719\n",
      "[step: 963] loss: 4.059743881225586\n",
      "[step: 964] loss: 4.058402061462402\n",
      "[step: 965] loss: 4.057062149047852\n",
      "[step: 966] loss: 4.055724143981934\n",
      "[step: 967] loss: 4.054388046264648\n",
      "[step: 968] loss: 4.053053855895996\n",
      "[step: 969] loss: 4.051722526550293\n",
      "[step: 970] loss: 4.050392150878906\n",
      "[step: 971] loss: 4.0490641593933105\n",
      "[step: 972] loss: 4.047738075256348\n",
      "[step: 973] loss: 4.046414375305176\n",
      "[step: 974] loss: 4.045092582702637\n",
      "[step: 975] loss: 4.043773174285889\n",
      "[step: 976] loss: 4.042455673217773\n",
      "[step: 977] loss: 4.041140556335449\n",
      "[step: 978] loss: 4.039826393127441\n",
      "[step: 979] loss: 4.038515567779541\n",
      "[step: 980] loss: 4.037206649780273\n",
      "[step: 981] loss: 4.0358991622924805\n",
      "[step: 982] loss: 4.034594535827637\n",
      "[step: 983] loss: 4.033292293548584\n",
      "[step: 984] loss: 4.031991481781006\n",
      "[step: 985] loss: 4.030693531036377\n",
      "[step: 986] loss: 4.029397487640381\n",
      "[step: 987] loss: 4.028103351593018\n",
      "[step: 988] loss: 4.026811599731445\n",
      "[step: 989] loss: 4.025521278381348\n",
      "[step: 990] loss: 4.024233818054199\n",
      "[step: 991] loss: 4.022948265075684\n",
      "[step: 992] loss: 4.021665096282959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 993] loss: 4.020383834838867\n",
      "[step: 994] loss: 4.019103527069092\n",
      "[step: 995] loss: 4.017827033996582\n",
      "[step: 996] loss: 4.0165510177612305\n",
      "[step: 997] loss: 4.015277862548828\n",
      "[step: 998] loss: 4.014005661010742\n",
      "[step: 999] loss: 4.0127363204956055\n",
      "RMSE: 142.62432861328125\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21852ad9208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #초기화\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training step\n",
    "    for i in range(iterations):\n",
    "        _, step_loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
    "        print(\"[step: {}] loss: {}\".format(i, step_loss))\n",
    "\n",
    "    # Test step\n",
    "    test_predict = minMaxDeNormalizer(sess.run(Y_pred, feed_dict={X: testX}),originalSales)\n",
    "    rmse_val = sess.run(rmse, feed_dict={targets: denormalizedTestY_feed, predictions: test_predict})\n",
    "    print(\"RMSE: {}\".format(rmse_val))\n",
    "\n",
    "    # Plot predictions\n",
    "    plt.plot(denormalizedTestY_feed) #실제 sales 파란색\n",
    "    plt.plot(test_predict)           #예측 sales 주황색\n",
    "    plt.xlabel(\"Time Period\")\n",
    "    plt.ylabel(\"Stock Price\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "denormalizedTestPredictY=[item for sublist in test_predict for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142.6243259319919"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootMeanSquaredError(denormalizedTestY,denormalizedTestPredictY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "121 in denormalizedTestY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
