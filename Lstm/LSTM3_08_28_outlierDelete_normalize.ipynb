{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lstm3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과정 요약:<br> \n",
    "feature: season, day of week, week number, sales <br> \n",
    "feature engineering: outlier delete + normalize + denormalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과요약: RMSE: 0.24234837293624878 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상세과정:\n",
    "주중(1)/주말(2) + 겨울(1)봄(2)여름(3)가을(4) // \n",
    "이미 lstm이라는 것이 sequence 개념이 있으므로 시간축(1~397)를 feature로 설정하는 것은 의미가 없을 듯 하여 LSTM 시도2에서는 제외함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가의견) 개인적으로 이상점을 제거한 후 normalize를 하면 rmse가 커질 수 밖에 없다고 생각함. 다음시도(lstm3)은 이상점을 제거하지 않고 normalize를 하고, lstm4에서는 이상점을 제거하고 normalize를 하지 않는 것을 시도하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가의견2) 처음에는 denormalize과정 없이 rmse를 구했는데, 이것보다는 denormalize를 한 후 rmse를 구하여 모델간 비교를 하는 것이 더 적절한 것 같다. normalize는 어디까지나 변환이니 항상 변환을 할때는 역변환을 하여 원본 데이터 형태m로 생각하는 것이 덜 헷갈리고, 결과값에 대한 더욱 직관적인 이해가 가능할 것 같다. 그리고, 여러 형태의 data transformation이 있는데 normalize 가장 마지막 단계의 data transformation인 것 같다. 다른 로그나 루트 변환을 한 후 normalization을 하고, 그리고 예측값이 모델을 통해 생성되면 바로 denormalize하고...예측(뉴럴) 모델의 input직전과 output직후."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set seednumber(7 or 77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DATA 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 397 entries, 0 to 396\n",
      "Data columns (total 2 columns):\n",
      "date     397 non-null object\n",
      "sales    397 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  sales\n",
       "0  2016-01-01     34\n",
       "1  2016-01-02     41\n",
       "2  2016-01-03     54\n",
       "3  2016-01-04     41\n",
       "4  2016-01-05     35"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['date','sales']\n",
    "\n",
    "txs=pd.read_table('./lstmData/lstmPrac2.csv', sep=',',header=None,names=columns )\n",
    "txs.info()\n",
    "txs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales=list(txs['sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 기본 feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'ds-y'의 ds로부터 api로 얻을 수 있는 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "year, day of week, month, week number를 기본 feature로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year = lambda x: datetime.strptime(x, \"%Y-%m-%d\" ).year  \n",
    "day_of_week = lambda x: datetime.strptime(x, \"%Y-%m-%d\" ).weekday()\n",
    "month = lambda x: datetime.strptime(x, \"%Y-%m-%d\" ).month\n",
    "# please read docs on how week numbers are calculate\n",
    "week_number = lambda x: datetime.strptime(x, \"%Y-%m-%d\" ).strftime('%V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txs['year'] = txs['date'].map(year)\n",
    "txs['month']=txs['date'].map(month)\n",
    "txs['week_number']=txs['date'].map(week_number)\n",
    "txs['day_of_week']=txs['date'].map(day_of_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 추가 feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'ds-y'의 ds로부터 api로 얻을 수 없는 값: 본 feature를 가공한 feature + ds와 무관한 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seasons = [0,0,1,1,1,2,2,2,3,3,3,0] #dec - feb is winter, then spring, summer, fall etc\n",
    "season = lambda x: seasons[(datetime.strptime(x, \"%Y-%m-%d\" ).month-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week_number</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>34</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>41</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>54</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>41</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>35</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>44</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>50</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>42</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-01-09</td>\n",
       "      <td>42</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-01-10</td>\n",
       "      <td>66</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>50</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016-01-12</td>\n",
       "      <td>55</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>56</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>53</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>44</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>54</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>54</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>50</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>40</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>49</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>28</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>72</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>71</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>53</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>43</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016-01-26</td>\n",
       "      <td>38</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>55</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>49</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016-01-29</td>\n",
       "      <td>43</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016-01-30</td>\n",
       "      <td>49</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>16</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>20</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>22</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>20</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>16</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>17</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>97</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>23</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>2017-01-13</td>\n",
       "      <td>100</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>18</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>13</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>21</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2017-01-17</td>\n",
       "      <td>24</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2017-01-18</td>\n",
       "      <td>16</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>18</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>22</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>18</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>24</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>22</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>20</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>22</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>26</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>31</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  sales  year  month week_number  day_of_week  season\n",
       "0    2016-01-01     34  2016      1          53            4       0\n",
       "1    2016-01-02     41  2016      1          53            5       0\n",
       "2    2016-01-03     54  2016      1          53            6       0\n",
       "3    2016-01-04     41  2016      1          01            0       0\n",
       "4    2016-01-05     35  2016      1          01            1       0\n",
       "5    2016-01-06     44  2016      1          01            2       0\n",
       "6    2016-01-07     50  2016      1          01            3       0\n",
       "7    2016-01-08     42  2016      1          01            4       0\n",
       "8    2016-01-09     42  2016      1          01            5       0\n",
       "9    2016-01-10     66  2016      1          01            6       0\n",
       "10   2016-01-11     50  2016      1          02            0       0\n",
       "11   2016-01-12     55  2016      1          02            1       0\n",
       "12   2016-01-13     56  2016      1          02            2       0\n",
       "13   2016-01-14     53  2016      1          02            3       0\n",
       "14   2016-01-15     44  2016      1          02            4       0\n",
       "15   2016-01-16     54  2016      1          02            5       0\n",
       "16   2016-01-17     54  2016      1          02            6       0\n",
       "17   2016-01-18     50  2016      1          03            0       0\n",
       "18   2016-01-19     40  2016      1          03            1       0\n",
       "19   2016-01-20     49  2016      1          03            2       0\n",
       "20   2016-01-21     28  2016      1          03            3       0\n",
       "21   2016-01-22     72  2016      1          03            4       0\n",
       "22   2016-01-23     71  2016      1          03            5       0\n",
       "23   2016-01-24     53  2016      1          03            6       0\n",
       "24   2016-01-25     43  2016      1          04            0       0\n",
       "25   2016-01-26     38  2016      1          04            1       0\n",
       "26   2016-01-27     55  2016      1          04            2       0\n",
       "27   2016-01-28     49  2016      1          04            3       0\n",
       "28   2016-01-29     43  2016      1          04            4       0\n",
       "29   2016-01-30     49  2016      1          04            5       0\n",
       "..          ...    ...   ...    ...         ...          ...     ...\n",
       "367  2017-01-02     16  2017      1          01            0       0\n",
       "368  2017-01-03     20  2017      1          01            1       0\n",
       "369  2017-01-04     12  2017      1          01            2       0\n",
       "370  2017-01-05     11  2017      1          01            3       0\n",
       "371  2017-01-06     22  2017      1          01            4       0\n",
       "372  2017-01-07     20  2017      1          01            5       0\n",
       "373  2017-01-08     16  2017      1          01            6       0\n",
       "374  2017-01-09     17  2017      1          02            0       0\n",
       "375  2017-01-10     97  2017      1          02            1       0\n",
       "376  2017-01-11      0  2017      1          02            2       0\n",
       "377  2017-01-12     23  2017      1          02            3       0\n",
       "378  2017-01-13    100  2017      1          02            4       0\n",
       "379  2017-01-14     18  2017      1          02            5       0\n",
       "380  2017-01-15     13  2017      1          02            6       0\n",
       "381  2017-01-16     21  2017      1          03            0       0\n",
       "382  2017-01-17     24  2017      1          03            1       0\n",
       "383  2017-01-18     16  2017      1          03            2       0\n",
       "384  2017-01-19     18  2017      1          03            3       0\n",
       "385  2017-01-20     22  2017      1          03            4       0\n",
       "386  2017-01-21     18  2017      1          03            5       0\n",
       "387  2017-01-22     11  2017      1          03            6       0\n",
       "388  2017-01-23     24  2017      1          04            0       0\n",
       "389  2017-01-24     22  2017      1          04            1       0\n",
       "390  2017-01-25     20  2017      1          04            2       0\n",
       "391  2017-01-26     22  2017      1          04            3       0\n",
       "392  2017-01-27     26  2017      1          04            4       0\n",
       "393  2017-01-28      0  2017      1          04            5       0\n",
       "394  2017-01-29      0  2017      1          04            6       0\n",
       "395  2017-01-30      5  2017      1          05            0       0\n",
       "396  2017-01-31     31  2017      1          05            1       0\n",
       "\n",
       "[397 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txs['season']=txs['date'].map(season)\n",
    "txs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas를 통해 구한 각 feature는 list()로 우리의 기준type인 list로 변경이 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 합친 후 normalize하여 최종 data 생성: XY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tempxy=[list(txs['season']),list(txs['day_of_week']),list(txs['week_number']),sales]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XY=np.array(tempxy).transpose().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   4.,  53.,  34.],\n",
       "       [  0.,   5.,  53.,  41.],\n",
       "       [  0.,   6.,  53.,  54.],\n",
       "       ..., \n",
       "       [  0.,   6.,   4.,   0.],\n",
       "       [  0.,   0.,   5.,   5.],\n",
       "       [  0.,   1.,   5.,  31.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 추가 가공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 y의 추가 가공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막rmse를 계산할 때 원본 데이터를 복원하기 위해 저장해놓음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "originalSales=sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이상점 제거, bucketization 을 하여 새로운 열을 생성하는 방향으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이상점 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이상점 제거를 위해 평균과 표준편차를 구한다. 이상점의 기준은 일단 평균+-2*sd로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean=np.mean(sales)\n",
    "std=np.std(sales)\n",
    "for i in range(len(sales)):\n",
    "    if (sales[i]<mean-2*std or sales[i]>mean+2*std):\n",
    "         sales[i]=int(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 x의 추가 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 합친 후 normalize하여 최종 data 생성: XY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tempxy=[list(txs['season']),list(txs['day_of_week']),list(txs['week_number']),sales]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xy=np.array(tempxy).transpose().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   4.,  53.,  34.],\n",
       "       [  0.,   5.,  53.,  41.],\n",
       "       [  0.,   6.,  53.,  54.],\n",
       "       ..., \n",
       "       [  0.,   6.,   4.,   0.],\n",
       "       [  0.,   0.,   5.,   5.],\n",
       "       [  0.,   1.,   5.,  31.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minMaxNormalizer(data):\n",
    "    numerator=data-np.min(data)\n",
    "    denominator=np.max(data)-np.min(data)\n",
    "    return numerator/(denominator+1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막rmse를 계산할 때 원본 데이터를 복원하기 위해 저장해놓음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "originalSales=sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization이 필요한 열을 normalize시킴(현재는 sales에 해당하는 마지막 열만 normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xy[:,-1]=minMaxNormalizer(xy[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 열 ex) XY[:,-3]=minMaxNormalizer(XY[:,-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   4.00000000e+00,   5.30000000e+01,\n",
       "          3.40000000e-01],\n",
       "       [  0.00000000e+00,   5.00000000e+00,   5.30000000e+01,\n",
       "          4.10000000e-01],\n",
       "       [  0.00000000e+00,   6.00000000e+00,   5.30000000e+01,\n",
       "          5.39999999e-01],\n",
       "       ..., \n",
       "       [  0.00000000e+00,   6.00000000e+00,   4.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   5.00000000e+00,\n",
       "          5.00000000e-02],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   5.00000000e+00,\n",
       "          3.10000000e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.34,  0.41,  0.54,  0.41,  0.35,  0.44,  0.5 ,  0.42,  0.42,\n",
       "        0.66,  0.5 ,  0.55,  0.56,  0.53,  0.44,  0.54,  0.54,  0.5 ,\n",
       "        0.4 ,  0.49,  0.28,  0.72,  0.71,  0.53,  0.43,  0.38,  0.55,\n",
       "        0.49,  0.43,  0.49,  0.49,  0.44,  0.39,  0.52,  0.45,  0.33,\n",
       "        0.43,  0.4 ,  0.46,  0.49,  0.5 ,  0.37,  0.37,  0.45,  0.48,\n",
       "        0.48,  0.38,  0.6 ,  0.31,  0.35,  0.53,  0.7 ,  0.62,  0.48,\n",
       "        0.51,  0.49,  0.38,  0.32,  0.39,  0.35,  0.3 ,  0.36,  0.31,\n",
       "        0.31,  0.44,  0.41,  0.41,  0.45,  0.46,  0.45,  0.41,  0.47,\n",
       "        0.48,  0.4 ,  0.42,  0.38,  0.38,  0.45,  0.48,  0.62,  0.46,\n",
       "        0.38,  0.62,  0.81,  0.4 ,  0.45,  0.42,  0.53,  0.53,  0.56,\n",
       "        0.53,  0.47,  0.61,  0.64,  0.62,  0.37,  0.65,  0.54,  0.44,\n",
       "        0.46,  0.5 ,  0.43,  0.53,  0.63,  0.52,  0.02,  0.  ,  0.  ,\n",
       "        0.72,  0.59,  0.75,  0.47,  0.44,  0.77,  0.9 ,  0.93,  0.47,\n",
       "        0.61,  0.77,  0.35,  0.5 ,  0.58,  0.33,  0.41,  0.36,  0.64,\n",
       "        0.49,  0.53,  0.6 ,  0.43,  0.41,  0.55,  0.45,  0.18,  0.6 ,\n",
       "        0.69,  0.54,  0.39,  0.5 ,  0.44,  0.54,  0.57,  0.82,  0.57,\n",
       "        0.44,  0.56,  0.51,  0.55,  0.28,  0.56,  0.54,  0.36,  0.12,\n",
       "        0.25,  0.41,  0.11,  0.06,  0.09,  0.35,  0.29,  0.24,  0.23,\n",
       "        0.14,  0.21,  0.2 ,  0.25,  0.23,  0.27,  0.31,  0.16,  0.14,\n",
       "        0.3 ,  0.32,  0.75,  0.35,  0.26,  0.12,  0.21,  0.23,  0.28,\n",
       "        0.25,  0.31,  0.21,  0.17,  0.1 ,  0.29,  0.34,  0.28,  0.2 ,\n",
       "        0.36,  0.23,  0.15,  0.42,  0.28,  0.24,  0.29,  0.2 ,  0.14,\n",
       "        0.18,  0.27,  0.22,  0.31,  0.24,  0.39,  0.31,  0.17,  0.42,\n",
       "        0.29,  0.33,  0.22,  0.39,  0.25,  0.23,  0.25,  0.21,  0.18,\n",
       "        0.24,  0.24,  0.2 ,  0.09,  0.31,  0.33,  0.33,  0.31,  0.27,\n",
       "        0.35,  0.15,  0.25,  0.32,  0.29,  0.32,  0.21,  0.92,  0.19,\n",
       "        0.37,  0.29,  0.33,  0.16,  0.22,  0.25,  0.21,  0.46,  0.34,\n",
       "        0.31,  0.22,  0.3 ,  0.28,  0.14,  0.25,  0.33,  0.28,  0.24,\n",
       "        0.42,  0.26,  0.19,  0.41,  0.34,  0.08,  0.  ,  0.  ,  0.11,\n",
       "        0.16,  0.27,  0.27,  0.21,  0.37,  0.41,  0.23,  0.3 ,  0.25,\n",
       "        0.22,  0.26,  0.29,  0.31,  0.29,  0.12,  0.15,  0.48,  0.18,\n",
       "        0.25,  0.27,  0.25,  0.21,  0.28,  0.24,  0.21,  0.29,  0.35,\n",
       "        0.  ,  0.07,  0.32,  0.19,  0.34,  0.28,  0.23,  0.15,  0.1 ,\n",
       "        0.15,  0.09,  0.78,  0.59,  0.29,  0.23,  0.12,  0.36,  0.13,\n",
       "        0.17,  0.17,  0.16,  0.14,  0.08,  0.16,  0.14,  0.14,  0.15,\n",
       "        0.2 ,  0.24,  0.08,  0.15,  0.17,  0.09,  0.17,  0.13,  0.19,\n",
       "        0.08,  0.14,  0.18,  0.24,  0.16,  0.11,  0.13,  0.1 ,  0.16,\n",
       "        0.11,  0.22,  0.15,  0.18,  0.11,  0.14,  0.34,  0.1 ,  0.13,\n",
       "        0.21,  0.35,  0.15,  0.06,  0.23,  0.22,  0.19,  0.2 ,  0.13,\n",
       "        0.21,  0.1 ,  0.11,  0.11,  0.16,  0.12,  0.15,  0.08,  0.  ,\n",
       "        0.24,  0.19,  0.22,  0.13,  0.12,  0.16,  0.02,  0.16,  0.2 ,\n",
       "        0.12,  0.11,  0.22,  0.2 ,  0.16,  0.17,  0.97,  0.  ,  0.23,\n",
       "        1.  ,  0.18,  0.13,  0.21,  0.24,  0.16,  0.18,  0.22,  0.18,\n",
       "        0.11,  0.24,  0.22,  0.2 ,  0.22,  0.26,  0.  ,  0.  ,  0.05,  0.31])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Denormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측모델을 통해 얻은 sales결과를 denormalize시켜 기존 단위로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minMaxDeNormalizer(data, originalData):\n",
    "    shift=np.min(originalData)\n",
    "    multiplier=np.max(originalData)-np.min(originalData)\n",
    "    return (data+shift)*multiplier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 함수를 마지막 rmse구하기 전에 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MODEL 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 사용 model 정의: RNN LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 해당 model의 train parameters 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_dim은 y값 도출을 위한 feature 가지수(독립변수 가지수 +1(y포함))\n",
    "data_dim=4\n",
    "\n",
    "#data_dim크기의 data 한 묶음이 seq_length만큼 input으로 들어가\n",
    "seq_length=5\n",
    "\n",
    "#output_dim(=forecastDays)만큼의 다음날 y_data를 예측\n",
    "forecastDays=1\n",
    "output_dim=forecastDays\n",
    "\n",
    "#hidden_dim은 정말 임의로 설정\n",
    "hidden_dim=10\n",
    "\n",
    "#learning rate은 배우는 속도(너무 크지도, 작지도 않게 설정)\n",
    "learning_rate=0.01\n",
    "\n",
    "#iterations는 반복 횟수\n",
    "iterations=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 사용 model, train parameter에 맞추어 dataset(XY) 변환: dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.     4.    53.     0.34]\n",
      " [  0.     5.    53.     0.41]\n",
      " [  0.     6.    53.     0.54]\n",
      " [  0.     0.     1.     0.41]\n",
      " [  0.     1.     1.     0.35]] -> [ 0.44]\n",
      "[[  0.     5.    53.     0.41]\n",
      " [  0.     6.    53.     0.54]\n",
      " [  0.     0.     1.     0.41]\n",
      " [  0.     1.     1.     0.35]\n",
      " [  0.     2.     1.     0.44]] -> [ 0.5]\n",
      "[[  0.     6.    53.     0.54]\n",
      " [  0.     0.     1.     0.41]\n",
      " [  0.     1.     1.     0.35]\n",
      " [  0.     2.     1.     0.44]\n",
      " [  0.     3.     1.     0.5 ]] -> [ 0.42]\n",
      "[[ 0.    0.    1.    0.41]\n",
      " [ 0.    1.    1.    0.35]\n",
      " [ 0.    2.    1.    0.44]\n",
      " [ 0.    3.    1.    0.5 ]\n",
      " [ 0.    4.    1.    0.42]] -> [ 0.42]\n",
      "[[ 0.    1.    1.    0.35]\n",
      " [ 0.    2.    1.    0.44]\n",
      " [ 0.    3.    1.    0.5 ]\n",
      " [ 0.    4.    1.    0.42]\n",
      " [ 0.    5.    1.    0.42]] -> [ 0.66]\n",
      "[[ 0.    2.    1.    0.44]\n",
      " [ 0.    3.    1.    0.5 ]\n",
      " [ 0.    4.    1.    0.42]\n",
      " [ 0.    5.    1.    0.42]\n",
      " [ 0.    6.    1.    0.66]] -> [ 0.5]\n",
      "[[ 0.    3.    1.    0.5 ]\n",
      " [ 0.    4.    1.    0.42]\n",
      " [ 0.    5.    1.    0.42]\n",
      " [ 0.    6.    1.    0.66]\n",
      " [ 0.    0.    2.    0.5 ]] -> [ 0.55]\n",
      "[[ 0.    4.    1.    0.42]\n",
      " [ 0.    5.    1.    0.42]\n",
      " [ 0.    6.    1.    0.66]\n",
      " [ 0.    0.    2.    0.5 ]\n",
      " [ 0.    1.    2.    0.55]] -> [ 0.56]\n",
      "[[ 0.    5.    1.    0.42]\n",
      " [ 0.    6.    1.    0.66]\n",
      " [ 0.    0.    2.    0.5 ]\n",
      " [ 0.    1.    2.    0.55]\n",
      " [ 0.    2.    2.    0.56]] -> [ 0.53]\n",
      "[[ 0.    6.    1.    0.66]\n",
      " [ 0.    0.    2.    0.5 ]\n",
      " [ 0.    1.    2.    0.55]\n",
      " [ 0.    2.    2.    0.56]\n",
      " [ 0.    3.    2.    0.53]] -> [ 0.44]\n",
      "[[ 0.    0.    2.    0.5 ]\n",
      " [ 0.    1.    2.    0.55]\n",
      " [ 0.    2.    2.    0.56]\n",
      " [ 0.    3.    2.    0.53]\n",
      " [ 0.    4.    2.    0.44]] -> [ 0.54]\n",
      "[[ 0.    1.    2.    0.55]\n",
      " [ 0.    2.    2.    0.56]\n",
      " [ 0.    3.    2.    0.53]\n",
      " [ 0.    4.    2.    0.44]\n",
      " [ 0.    5.    2.    0.54]] -> [ 0.54]\n",
      "[[ 0.    2.    2.    0.56]\n",
      " [ 0.    3.    2.    0.53]\n",
      " [ 0.    4.    2.    0.44]\n",
      " [ 0.    5.    2.    0.54]\n",
      " [ 0.    6.    2.    0.54]] -> [ 0.5]\n",
      "[[ 0.    3.    2.    0.53]\n",
      " [ 0.    4.    2.    0.44]\n",
      " [ 0.    5.    2.    0.54]\n",
      " [ 0.    6.    2.    0.54]\n",
      " [ 0.    0.    3.    0.5 ]] -> [ 0.4]\n",
      "[[ 0.    4.    2.    0.44]\n",
      " [ 0.    5.    2.    0.54]\n",
      " [ 0.    6.    2.    0.54]\n",
      " [ 0.    0.    3.    0.5 ]\n",
      " [ 0.    1.    3.    0.4 ]] -> [ 0.49]\n",
      "[[ 0.    5.    2.    0.54]\n",
      " [ 0.    6.    2.    0.54]\n",
      " [ 0.    0.    3.    0.5 ]\n",
      " [ 0.    1.    3.    0.4 ]\n",
      " [ 0.    2.    3.    0.49]] -> [ 0.28]\n",
      "[[ 0.    6.    2.    0.54]\n",
      " [ 0.    0.    3.    0.5 ]\n",
      " [ 0.    1.    3.    0.4 ]\n",
      " [ 0.    2.    3.    0.49]\n",
      " [ 0.    3.    3.    0.28]] -> [ 0.72]\n",
      "[[ 0.    0.    3.    0.5 ]\n",
      " [ 0.    1.    3.    0.4 ]\n",
      " [ 0.    2.    3.    0.49]\n",
      " [ 0.    3.    3.    0.28]\n",
      " [ 0.    4.    3.    0.72]] -> [ 0.71]\n",
      "[[ 0.    1.    3.    0.4 ]\n",
      " [ 0.    2.    3.    0.49]\n",
      " [ 0.    3.    3.    0.28]\n",
      " [ 0.    4.    3.    0.72]\n",
      " [ 0.    5.    3.    0.71]] -> [ 0.53]\n",
      "[[ 0.    2.    3.    0.49]\n",
      " [ 0.    3.    3.    0.28]\n",
      " [ 0.    4.    3.    0.72]\n",
      " [ 0.    5.    3.    0.71]\n",
      " [ 0.    6.    3.    0.53]] -> [ 0.43]\n",
      "[[ 0.    3.    3.    0.28]\n",
      " [ 0.    4.    3.    0.72]\n",
      " [ 0.    5.    3.    0.71]\n",
      " [ 0.    6.    3.    0.53]\n",
      " [ 0.    0.    4.    0.43]] -> [ 0.38]\n",
      "[[ 0.    4.    3.    0.72]\n",
      " [ 0.    5.    3.    0.71]\n",
      " [ 0.    6.    3.    0.53]\n",
      " [ 0.    0.    4.    0.43]\n",
      " [ 0.    1.    4.    0.38]] -> [ 0.55]\n",
      "[[ 0.    5.    3.    0.71]\n",
      " [ 0.    6.    3.    0.53]\n",
      " [ 0.    0.    4.    0.43]\n",
      " [ 0.    1.    4.    0.38]\n",
      " [ 0.    2.    4.    0.55]] -> [ 0.49]\n",
      "[[ 0.    6.    3.    0.53]\n",
      " [ 0.    0.    4.    0.43]\n",
      " [ 0.    1.    4.    0.38]\n",
      " [ 0.    2.    4.    0.55]\n",
      " [ 0.    3.    4.    0.49]] -> [ 0.43]\n",
      "[[ 0.    0.    4.    0.43]\n",
      " [ 0.    1.    4.    0.38]\n",
      " [ 0.    2.    4.    0.55]\n",
      " [ 0.    3.    4.    0.49]\n",
      " [ 0.    4.    4.    0.43]] -> [ 0.49]\n",
      "[[ 0.    1.    4.    0.38]\n",
      " [ 0.    2.    4.    0.55]\n",
      " [ 0.    3.    4.    0.49]\n",
      " [ 0.    4.    4.    0.43]\n",
      " [ 0.    5.    4.    0.49]] -> [ 0.49]\n",
      "[[ 0.    2.    4.    0.55]\n",
      " [ 0.    3.    4.    0.49]\n",
      " [ 0.    4.    4.    0.43]\n",
      " [ 0.    5.    4.    0.49]\n",
      " [ 0.    6.    4.    0.49]] -> [ 0.44]\n",
      "[[ 0.    3.    4.    0.49]\n",
      " [ 0.    4.    4.    0.43]\n",
      " [ 0.    5.    4.    0.49]\n",
      " [ 0.    6.    4.    0.49]\n",
      " [ 0.    0.    5.    0.44]] -> [ 0.39]\n",
      "[[ 0.    4.    4.    0.43]\n",
      " [ 0.    5.    4.    0.49]\n",
      " [ 0.    6.    4.    0.49]\n",
      " [ 0.    0.    5.    0.44]\n",
      " [ 0.    1.    5.    0.39]] -> [ 0.52]\n",
      "[[ 0.    5.    4.    0.49]\n",
      " [ 0.    6.    4.    0.49]\n",
      " [ 0.    0.    5.    0.44]\n",
      " [ 0.    1.    5.    0.39]\n",
      " [ 0.    2.    5.    0.52]] -> [ 0.45]\n",
      "[[ 0.    6.    4.    0.49]\n",
      " [ 0.    0.    5.    0.44]\n",
      " [ 0.    1.    5.    0.39]\n",
      " [ 0.    2.    5.    0.52]\n",
      " [ 0.    3.    5.    0.45]] -> [ 0.33]\n",
      "[[ 0.    0.    5.    0.44]\n",
      " [ 0.    1.    5.    0.39]\n",
      " [ 0.    2.    5.    0.52]\n",
      " [ 0.    3.    5.    0.45]\n",
      " [ 0.    4.    5.    0.33]] -> [ 0.43]\n",
      "[[ 0.    1.    5.    0.39]\n",
      " [ 0.    2.    5.    0.52]\n",
      " [ 0.    3.    5.    0.45]\n",
      " [ 0.    4.    5.    0.33]\n",
      " [ 0.    5.    5.    0.43]] -> [ 0.4]\n",
      "[[ 0.    2.    5.    0.52]\n",
      " [ 0.    3.    5.    0.45]\n",
      " [ 0.    4.    5.    0.33]\n",
      " [ 0.    5.    5.    0.43]\n",
      " [ 0.    6.    5.    0.4 ]] -> [ 0.46]\n",
      "[[ 0.    3.    5.    0.45]\n",
      " [ 0.    4.    5.    0.33]\n",
      " [ 0.    5.    5.    0.43]\n",
      " [ 0.    6.    5.    0.4 ]\n",
      " [ 0.    0.    6.    0.46]] -> [ 0.49]\n",
      "[[ 0.    4.    5.    0.33]\n",
      " [ 0.    5.    5.    0.43]\n",
      " [ 0.    6.    5.    0.4 ]\n",
      " [ 0.    0.    6.    0.46]\n",
      " [ 0.    1.    6.    0.49]] -> [ 0.5]\n",
      "[[ 0.    5.    5.    0.43]\n",
      " [ 0.    6.    5.    0.4 ]\n",
      " [ 0.    0.    6.    0.46]\n",
      " [ 0.    1.    6.    0.49]\n",
      " [ 0.    2.    6.    0.5 ]] -> [ 0.37]\n",
      "[[ 0.    6.    5.    0.4 ]\n",
      " [ 0.    0.    6.    0.46]\n",
      " [ 0.    1.    6.    0.49]\n",
      " [ 0.    2.    6.    0.5 ]\n",
      " [ 0.    3.    6.    0.37]] -> [ 0.37]\n",
      "[[ 0.    0.    6.    0.46]\n",
      " [ 0.    1.    6.    0.49]\n",
      " [ 0.    2.    6.    0.5 ]\n",
      " [ 0.    3.    6.    0.37]\n",
      " [ 0.    4.    6.    0.37]] -> [ 0.45]\n",
      "[[ 0.    1.    6.    0.49]\n",
      " [ 0.    2.    6.    0.5 ]\n",
      " [ 0.    3.    6.    0.37]\n",
      " [ 0.    4.    6.    0.37]\n",
      " [ 0.    5.    6.    0.45]] -> [ 0.48]\n",
      "[[ 0.    2.    6.    0.5 ]\n",
      " [ 0.    3.    6.    0.37]\n",
      " [ 0.    4.    6.    0.37]\n",
      " [ 0.    5.    6.    0.45]\n",
      " [ 0.    6.    6.    0.48]] -> [ 0.48]\n",
      "[[ 0.    3.    6.    0.37]\n",
      " [ 0.    4.    6.    0.37]\n",
      " [ 0.    5.    6.    0.45]\n",
      " [ 0.    6.    6.    0.48]\n",
      " [ 0.    0.    7.    0.48]] -> [ 0.38]\n",
      "[[ 0.    4.    6.    0.37]\n",
      " [ 0.    5.    6.    0.45]\n",
      " [ 0.    6.    6.    0.48]\n",
      " [ 0.    0.    7.    0.48]\n",
      " [ 0.    1.    7.    0.38]] -> [ 0.6]\n",
      "[[ 0.    5.    6.    0.45]\n",
      " [ 0.    6.    6.    0.48]\n",
      " [ 0.    0.    7.    0.48]\n",
      " [ 0.    1.    7.    0.38]\n",
      " [ 0.    2.    7.    0.6 ]] -> [ 0.31]\n",
      "[[ 0.    6.    6.    0.48]\n",
      " [ 0.    0.    7.    0.48]\n",
      " [ 0.    1.    7.    0.38]\n",
      " [ 0.    2.    7.    0.6 ]\n",
      " [ 0.    3.    7.    0.31]] -> [ 0.35]\n",
      "[[ 0.    0.    7.    0.48]\n",
      " [ 0.    1.    7.    0.38]\n",
      " [ 0.    2.    7.    0.6 ]\n",
      " [ 0.    3.    7.    0.31]\n",
      " [ 0.    4.    7.    0.35]] -> [ 0.53]\n",
      "[[ 0.    1.    7.    0.38]\n",
      " [ 0.    2.    7.    0.6 ]\n",
      " [ 0.    3.    7.    0.31]\n",
      " [ 0.    4.    7.    0.35]\n",
      " [ 0.    5.    7.    0.53]] -> [ 0.7]\n",
      "[[ 0.    2.    7.    0.6 ]\n",
      " [ 0.    3.    7.    0.31]\n",
      " [ 0.    4.    7.    0.35]\n",
      " [ 0.    5.    7.    0.53]\n",
      " [ 0.    6.    7.    0.7 ]] -> [ 0.62]\n",
      "[[ 0.    3.    7.    0.31]\n",
      " [ 0.    4.    7.    0.35]\n",
      " [ 0.    5.    7.    0.53]\n",
      " [ 0.    6.    7.    0.7 ]\n",
      " [ 0.    0.    8.    0.62]] -> [ 0.48]\n",
      "[[ 0.    4.    7.    0.35]\n",
      " [ 0.    5.    7.    0.53]\n",
      " [ 0.    6.    7.    0.7 ]\n",
      " [ 0.    0.    8.    0.62]\n",
      " [ 0.    1.    8.    0.48]] -> [ 0.51]\n",
      "[[ 0.    5.    7.    0.53]\n",
      " [ 0.    6.    7.    0.7 ]\n",
      " [ 0.    0.    8.    0.62]\n",
      " [ 0.    1.    8.    0.48]\n",
      " [ 0.    2.    8.    0.51]] -> [ 0.49]\n",
      "[[ 0.    6.    7.    0.7 ]\n",
      " [ 0.    0.    8.    0.62]\n",
      " [ 0.    1.    8.    0.48]\n",
      " [ 0.    2.    8.    0.51]\n",
      " [ 0.    3.    8.    0.49]] -> [ 0.38]\n",
      "[[ 0.    0.    8.    0.62]\n",
      " [ 0.    1.    8.    0.48]\n",
      " [ 0.    2.    8.    0.51]\n",
      " [ 0.    3.    8.    0.49]\n",
      " [ 0.    4.    8.    0.38]] -> [ 0.32]\n",
      "[[ 0.    1.    8.    0.48]\n",
      " [ 0.    2.    8.    0.51]\n",
      " [ 0.    3.    8.    0.49]\n",
      " [ 0.    4.    8.    0.38]\n",
      " [ 0.    5.    8.    0.32]] -> [ 0.39]\n",
      "[[ 0.    2.    8.    0.51]\n",
      " [ 0.    3.    8.    0.49]\n",
      " [ 0.    4.    8.    0.38]\n",
      " [ 0.    5.    8.    0.32]\n",
      " [ 0.    6.    8.    0.39]] -> [ 0.35]\n",
      "[[ 0.    3.    8.    0.49]\n",
      " [ 0.    4.    8.    0.38]\n",
      " [ 0.    5.    8.    0.32]\n",
      " [ 0.    6.    8.    0.39]\n",
      " [ 0.    0.    9.    0.35]] -> [ 0.3]\n",
      "[[ 0.    4.    8.    0.38]\n",
      " [ 0.    5.    8.    0.32]\n",
      " [ 0.    6.    8.    0.39]\n",
      " [ 0.    0.    9.    0.35]\n",
      " [ 1.    1.    9.    0.3 ]] -> [ 0.36]\n",
      "[[ 0.    5.    8.    0.32]\n",
      " [ 0.    6.    8.    0.39]\n",
      " [ 0.    0.    9.    0.35]\n",
      " [ 1.    1.    9.    0.3 ]\n",
      " [ 1.    2.    9.    0.36]] -> [ 0.31]\n",
      "[[ 0.    6.    8.    0.39]\n",
      " [ 0.    0.    9.    0.35]\n",
      " [ 1.    1.    9.    0.3 ]\n",
      " [ 1.    2.    9.    0.36]\n",
      " [ 1.    3.    9.    0.31]] -> [ 0.31]\n",
      "[[ 0.    0.    9.    0.35]\n",
      " [ 1.    1.    9.    0.3 ]\n",
      " [ 1.    2.    9.    0.36]\n",
      " [ 1.    3.    9.    0.31]\n",
      " [ 1.    4.    9.    0.31]] -> [ 0.44]\n",
      "[[ 1.    1.    9.    0.3 ]\n",
      " [ 1.    2.    9.    0.36]\n",
      " [ 1.    3.    9.    0.31]\n",
      " [ 1.    4.    9.    0.31]\n",
      " [ 1.    5.    9.    0.44]] -> [ 0.41]\n",
      "[[ 1.    2.    9.    0.36]\n",
      " [ 1.    3.    9.    0.31]\n",
      " [ 1.    4.    9.    0.31]\n",
      " [ 1.    5.    9.    0.44]\n",
      " [ 1.    6.    9.    0.41]] -> [ 0.41]\n",
      "[[  1.     3.     9.     0.31]\n",
      " [  1.     4.     9.     0.31]\n",
      " [  1.     5.     9.     0.44]\n",
      " [  1.     6.     9.     0.41]\n",
      " [  1.     0.    10.     0.41]] -> [ 0.45]\n",
      "[[  1.     4.     9.     0.31]\n",
      " [  1.     5.     9.     0.44]\n",
      " [  1.     6.     9.     0.41]\n",
      " [  1.     0.    10.     0.41]\n",
      " [  1.     1.    10.     0.45]] -> [ 0.46]\n",
      "[[  1.     5.     9.     0.44]\n",
      " [  1.     6.     9.     0.41]\n",
      " [  1.     0.    10.     0.41]\n",
      " [  1.     1.    10.     0.45]\n",
      " [  1.     2.    10.     0.46]] -> [ 0.45]\n",
      "[[  1.     6.     9.     0.41]\n",
      " [  1.     0.    10.     0.41]\n",
      " [  1.     1.    10.     0.45]\n",
      " [  1.     2.    10.     0.46]\n",
      " [  1.     3.    10.     0.45]] -> [ 0.41]\n",
      "[[  1.     0.    10.     0.41]\n",
      " [  1.     1.    10.     0.45]\n",
      " [  1.     2.    10.     0.46]\n",
      " [  1.     3.    10.     0.45]\n",
      " [  1.     4.    10.     0.41]] -> [ 0.47]\n",
      "[[  1.     1.    10.     0.45]\n",
      " [  1.     2.    10.     0.46]\n",
      " [  1.     3.    10.     0.45]\n",
      " [  1.     4.    10.     0.41]\n",
      " [  1.     5.    10.     0.47]] -> [ 0.48]\n",
      "[[  1.     2.    10.     0.46]\n",
      " [  1.     3.    10.     0.45]\n",
      " [  1.     4.    10.     0.41]\n",
      " [  1.     5.    10.     0.47]\n",
      " [  1.     6.    10.     0.48]] -> [ 0.4]\n",
      "[[  1.     3.    10.     0.45]\n",
      " [  1.     4.    10.     0.41]\n",
      " [  1.     5.    10.     0.47]\n",
      " [  1.     6.    10.     0.48]\n",
      " [  1.     0.    11.     0.4 ]] -> [ 0.42]\n",
      "[[  1.     4.    10.     0.41]\n",
      " [  1.     5.    10.     0.47]\n",
      " [  1.     6.    10.     0.48]\n",
      " [  1.     0.    11.     0.4 ]\n",
      " [  1.     1.    11.     0.42]] -> [ 0.38]\n",
      "[[  1.     5.    10.     0.47]\n",
      " [  1.     6.    10.     0.48]\n",
      " [  1.     0.    11.     0.4 ]\n",
      " [  1.     1.    11.     0.42]\n",
      " [  1.     2.    11.     0.38]] -> [ 0.38]\n",
      "[[  1.     6.    10.     0.48]\n",
      " [  1.     0.    11.     0.4 ]\n",
      " [  1.     1.    11.     0.42]\n",
      " [  1.     2.    11.     0.38]\n",
      " [  1.     3.    11.     0.38]] -> [ 0.45]\n",
      "[[  1.     0.    11.     0.4 ]\n",
      " [  1.     1.    11.     0.42]\n",
      " [  1.     2.    11.     0.38]\n",
      " [  1.     3.    11.     0.38]\n",
      " [  1.     4.    11.     0.45]] -> [ 0.48]\n",
      "[[  1.     1.    11.     0.42]\n",
      " [  1.     2.    11.     0.38]\n",
      " [  1.     3.    11.     0.38]\n",
      " [  1.     4.    11.     0.45]\n",
      " [  1.     5.    11.     0.48]] -> [ 0.62]\n",
      "[[  1.     2.    11.     0.38]\n",
      " [  1.     3.    11.     0.38]\n",
      " [  1.     4.    11.     0.45]\n",
      " [  1.     5.    11.     0.48]\n",
      " [  1.     6.    11.     0.62]] -> [ 0.46]\n",
      "[[  1.     3.    11.     0.38]\n",
      " [  1.     4.    11.     0.45]\n",
      " [  1.     5.    11.     0.48]\n",
      " [  1.     6.    11.     0.62]\n",
      " [  1.     0.    12.     0.46]] -> [ 0.38]\n",
      "[[  1.     4.    11.     0.45]\n",
      " [  1.     5.    11.     0.48]\n",
      " [  1.     6.    11.     0.62]\n",
      " [  1.     0.    12.     0.46]\n",
      " [  1.     1.    12.     0.38]] -> [ 0.62]\n",
      "[[  1.     5.    11.     0.48]\n",
      " [  1.     6.    11.     0.62]\n",
      " [  1.     0.    12.     0.46]\n",
      " [  1.     1.    12.     0.38]\n",
      " [  1.     2.    12.     0.62]] -> [ 0.81]\n",
      "[[  1.     6.    11.     0.62]\n",
      " [  1.     0.    12.     0.46]\n",
      " [  1.     1.    12.     0.38]\n",
      " [  1.     2.    12.     0.62]\n",
      " [  1.     3.    12.     0.81]] -> [ 0.4]\n",
      "[[  1.     0.    12.     0.46]\n",
      " [  1.     1.    12.     0.38]\n",
      " [  1.     2.    12.     0.62]\n",
      " [  1.     3.    12.     0.81]\n",
      " [  1.     4.    12.     0.4 ]] -> [ 0.45]\n",
      "[[  1.     1.    12.     0.38]\n",
      " [  1.     2.    12.     0.62]\n",
      " [  1.     3.    12.     0.81]\n",
      " [  1.     4.    12.     0.4 ]\n",
      " [  1.     5.    12.     0.45]] -> [ 0.42]\n",
      "[[  1.     2.    12.     0.62]\n",
      " [  1.     3.    12.     0.81]\n",
      " [  1.     4.    12.     0.4 ]\n",
      " [  1.     5.    12.     0.45]\n",
      " [  1.     6.    12.     0.42]] -> [ 0.53]\n",
      "[[  1.     3.    12.     0.81]\n",
      " [  1.     4.    12.     0.4 ]\n",
      " [  1.     5.    12.     0.45]\n",
      " [  1.     6.    12.     0.42]\n",
      " [  1.     0.    13.     0.53]] -> [ 0.53]\n",
      "[[  1.     4.    12.     0.4 ]\n",
      " [  1.     5.    12.     0.45]\n",
      " [  1.     6.    12.     0.42]\n",
      " [  1.     0.    13.     0.53]\n",
      " [  1.     1.    13.     0.53]] -> [ 0.56]\n",
      "[[  1.     5.    12.     0.45]\n",
      " [  1.     6.    12.     0.42]\n",
      " [  1.     0.    13.     0.53]\n",
      " [  1.     1.    13.     0.53]\n",
      " [  1.     2.    13.     0.56]] -> [ 0.53]\n",
      "[[  1.     6.    12.     0.42]\n",
      " [  1.     0.    13.     0.53]\n",
      " [  1.     1.    13.     0.53]\n",
      " [  1.     2.    13.     0.56]\n",
      " [  1.     3.    13.     0.53]] -> [ 0.47]\n",
      "[[  1.     0.    13.     0.53]\n",
      " [  1.     1.    13.     0.53]\n",
      " [  1.     2.    13.     0.56]\n",
      " [  1.     3.    13.     0.53]\n",
      " [  1.     4.    13.     0.47]] -> [ 0.61]\n",
      "[[  1.     1.    13.     0.53]\n",
      " [  1.     2.    13.     0.56]\n",
      " [  1.     3.    13.     0.53]\n",
      " [  1.     4.    13.     0.47]\n",
      " [  1.     5.    13.     0.61]] -> [ 0.64]\n",
      "[[  1.     2.    13.     0.56]\n",
      " [  1.     3.    13.     0.53]\n",
      " [  1.     4.    13.     0.47]\n",
      " [  1.     5.    13.     0.61]\n",
      " [  1.     6.    13.     0.64]] -> [ 0.62]\n",
      "[[  1.     3.    13.     0.53]\n",
      " [  1.     4.    13.     0.47]\n",
      " [  1.     5.    13.     0.61]\n",
      " [  1.     6.    13.     0.64]\n",
      " [  1.     0.    14.     0.62]] -> [ 0.37]\n",
      "[[  1.     4.    13.     0.47]\n",
      " [  1.     5.    13.     0.61]\n",
      " [  1.     6.    13.     0.64]\n",
      " [  1.     0.    14.     0.62]\n",
      " [  1.     1.    14.     0.37]] -> [ 0.65]\n",
      "[[  1.     5.    13.     0.61]\n",
      " [  1.     6.    13.     0.64]\n",
      " [  1.     0.    14.     0.62]\n",
      " [  1.     1.    14.     0.37]\n",
      " [  1.     2.    14.     0.65]] -> [ 0.54]\n",
      "[[  1.     6.    13.     0.64]\n",
      " [  1.     0.    14.     0.62]\n",
      " [  1.     1.    14.     0.37]\n",
      " [  1.     2.    14.     0.65]\n",
      " [  1.     3.    14.     0.54]] -> [ 0.44]\n",
      "[[  1.     0.    14.     0.62]\n",
      " [  1.     1.    14.     0.37]\n",
      " [  1.     2.    14.     0.65]\n",
      " [  1.     3.    14.     0.54]\n",
      " [  1.     4.    14.     0.44]] -> [ 0.46]\n",
      "[[  1.     1.    14.     0.37]\n",
      " [  1.     2.    14.     0.65]\n",
      " [  1.     3.    14.     0.54]\n",
      " [  1.     4.    14.     0.44]\n",
      " [  1.     5.    14.     0.46]] -> [ 0.5]\n",
      "[[  1.     2.    14.     0.65]\n",
      " [  1.     3.    14.     0.54]\n",
      " [  1.     4.    14.     0.44]\n",
      " [  1.     5.    14.     0.46]\n",
      " [  1.     6.    14.     0.5 ]] -> [ 0.43]\n",
      "[[  1.     3.    14.     0.54]\n",
      " [  1.     4.    14.     0.44]\n",
      " [  1.     5.    14.     0.46]\n",
      " [  1.     6.    14.     0.5 ]\n",
      " [  1.     0.    15.     0.43]] -> [ 0.53]\n",
      "[[  1.     4.    14.     0.44]\n",
      " [  1.     5.    14.     0.46]\n",
      " [  1.     6.    14.     0.5 ]\n",
      " [  1.     0.    15.     0.43]\n",
      " [  1.     1.    15.     0.53]] -> [ 0.63]\n",
      "[[  1.     5.    14.     0.46]\n",
      " [  1.     6.    14.     0.5 ]\n",
      " [  1.     0.    15.     0.43]\n",
      " [  1.     1.    15.     0.53]\n",
      " [  1.     2.    15.     0.63]] -> [ 0.52]\n",
      "[[  1.     6.    14.     0.5 ]\n",
      " [  1.     0.    15.     0.43]\n",
      " [  1.     1.    15.     0.53]\n",
      " [  1.     2.    15.     0.63]\n",
      " [  1.     3.    15.     0.52]] -> [ 0.02]\n",
      "[[  1.     0.    15.     0.43]\n",
      " [  1.     1.    15.     0.53]\n",
      " [  1.     2.    15.     0.63]\n",
      " [  1.     3.    15.     0.52]\n",
      " [  1.     4.    15.     0.02]] -> [ 0.]\n",
      "[[  1.     1.    15.     0.53]\n",
      " [  1.     2.    15.     0.63]\n",
      " [  1.     3.    15.     0.52]\n",
      " [  1.     4.    15.     0.02]\n",
      " [  1.     5.    15.     0.  ]] -> [ 0.]\n",
      "[[  1.     2.    15.     0.63]\n",
      " [  1.     3.    15.     0.52]\n",
      " [  1.     4.    15.     0.02]\n",
      " [  1.     5.    15.     0.  ]\n",
      " [  1.     6.    15.     0.  ]] -> [ 0.72]\n",
      "[[  1.     3.    15.     0.52]\n",
      " [  1.     4.    15.     0.02]\n",
      " [  1.     5.    15.     0.  ]\n",
      " [  1.     6.    15.     0.  ]\n",
      " [  1.     0.    16.     0.72]] -> [ 0.59]\n",
      "[[  1.     4.    15.     0.02]\n",
      " [  1.     5.    15.     0.  ]\n",
      " [  1.     6.    15.     0.  ]\n",
      " [  1.     0.    16.     0.72]\n",
      " [  1.     1.    16.     0.59]] -> [ 0.75]\n",
      "[[  1.     5.    15.     0.  ]\n",
      " [  1.     6.    15.     0.  ]\n",
      " [  1.     0.    16.     0.72]\n",
      " [  1.     1.    16.     0.59]\n",
      " [  1.     2.    16.     0.75]] -> [ 0.47]\n",
      "[[  1.     6.    15.     0.  ]\n",
      " [  1.     0.    16.     0.72]\n",
      " [  1.     1.    16.     0.59]\n",
      " [  1.     2.    16.     0.75]\n",
      " [  1.     3.    16.     0.47]] -> [ 0.44]\n",
      "[[  1.     0.    16.     0.72]\n",
      " [  1.     1.    16.     0.59]\n",
      " [  1.     2.    16.     0.75]\n",
      " [  1.     3.    16.     0.47]\n",
      " [  1.     4.    16.     0.44]] -> [ 0.77]\n",
      "[[  1.     1.    16.     0.59]\n",
      " [  1.     2.    16.     0.75]\n",
      " [  1.     3.    16.     0.47]\n",
      " [  1.     4.    16.     0.44]\n",
      " [  1.     5.    16.     0.77]] -> [ 0.9]\n",
      "[[  1.     2.    16.     0.75]\n",
      " [  1.     3.    16.     0.47]\n",
      " [  1.     4.    16.     0.44]\n",
      " [  1.     5.    16.     0.77]\n",
      " [  1.     6.    16.     0.9 ]] -> [ 0.93]\n",
      "[[  1.     3.    16.     0.47]\n",
      " [  1.     4.    16.     0.44]\n",
      " [  1.     5.    16.     0.77]\n",
      " [  1.     6.    16.     0.9 ]\n",
      " [  1.     0.    17.     0.93]] -> [ 0.47]\n",
      "[[  1.     4.    16.     0.44]\n",
      " [  1.     5.    16.     0.77]\n",
      " [  1.     6.    16.     0.9 ]\n",
      " [  1.     0.    17.     0.93]\n",
      " [  1.     1.    17.     0.47]] -> [ 0.61]\n",
      "[[  1.     5.    16.     0.77]\n",
      " [  1.     6.    16.     0.9 ]\n",
      " [  1.     0.    17.     0.93]\n",
      " [  1.     1.    17.     0.47]\n",
      " [  1.     2.    17.     0.61]] -> [ 0.77]\n",
      "[[  1.     6.    16.     0.9 ]\n",
      " [  1.     0.    17.     0.93]\n",
      " [  1.     1.    17.     0.47]\n",
      " [  1.     2.    17.     0.61]\n",
      " [  1.     3.    17.     0.77]] -> [ 0.35]\n",
      "[[  1.     0.    17.     0.93]\n",
      " [  1.     1.    17.     0.47]\n",
      " [  1.     2.    17.     0.61]\n",
      " [  1.     3.    17.     0.77]\n",
      " [  1.     4.    17.     0.35]] -> [ 0.5]\n",
      "[[  1.     1.    17.     0.47]\n",
      " [  1.     2.    17.     0.61]\n",
      " [  1.     3.    17.     0.77]\n",
      " [  1.     4.    17.     0.35]\n",
      " [  1.     5.    17.     0.5 ]] -> [ 0.58]\n",
      "[[  1.     2.    17.     0.61]\n",
      " [  1.     3.    17.     0.77]\n",
      " [  1.     4.    17.     0.35]\n",
      " [  1.     5.    17.     0.5 ]\n",
      " [  1.     6.    17.     0.58]] -> [ 0.33]\n",
      "[[  1.     3.    17.     0.77]\n",
      " [  1.     4.    17.     0.35]\n",
      " [  1.     5.    17.     0.5 ]\n",
      " [  1.     6.    17.     0.58]\n",
      " [  1.     0.    18.     0.33]] -> [ 0.41]\n",
      "[[  1.     4.    17.     0.35]\n",
      " [  1.     5.    17.     0.5 ]\n",
      " [  1.     6.    17.     0.58]\n",
      " [  1.     0.    18.     0.33]\n",
      " [  1.     1.    18.     0.41]] -> [ 0.36]\n",
      "[[  1.     5.    17.     0.5 ]\n",
      " [  1.     6.    17.     0.58]\n",
      " [  1.     0.    18.     0.33]\n",
      " [  1.     1.    18.     0.41]\n",
      " [  1.     2.    18.     0.36]] -> [ 0.64]\n",
      "[[  1.     6.    17.     0.58]\n",
      " [  1.     0.    18.     0.33]\n",
      " [  1.     1.    18.     0.41]\n",
      " [  1.     2.    18.     0.36]\n",
      " [  1.     3.    18.     0.64]] -> [ 0.49]\n",
      "[[  1.     0.    18.     0.33]\n",
      " [  1.     1.    18.     0.41]\n",
      " [  1.     2.    18.     0.36]\n",
      " [  1.     3.    18.     0.64]\n",
      " [  1.     4.    18.     0.49]] -> [ 0.53]\n",
      "[[  1.     1.    18.     0.41]\n",
      " [  1.     2.    18.     0.36]\n",
      " [  1.     3.    18.     0.64]\n",
      " [  1.     4.    18.     0.49]\n",
      " [  1.     5.    18.     0.53]] -> [ 0.6]\n",
      "[[  1.     2.    18.     0.36]\n",
      " [  1.     3.    18.     0.64]\n",
      " [  1.     4.    18.     0.49]\n",
      " [  1.     5.    18.     0.53]\n",
      " [  1.     6.    18.     0.6 ]] -> [ 0.43]\n",
      "[[  1.     3.    18.     0.64]\n",
      " [  1.     4.    18.     0.49]\n",
      " [  1.     5.    18.     0.53]\n",
      " [  1.     6.    18.     0.6 ]\n",
      " [  1.     0.    19.     0.43]] -> [ 0.41]\n",
      "[[  1.     4.    18.     0.49]\n",
      " [  1.     5.    18.     0.53]\n",
      " [  1.     6.    18.     0.6 ]\n",
      " [  1.     0.    19.     0.43]\n",
      " [  1.     1.    19.     0.41]] -> [ 0.55]\n",
      "[[  1.     5.    18.     0.53]\n",
      " [  1.     6.    18.     0.6 ]\n",
      " [  1.     0.    19.     0.43]\n",
      " [  1.     1.    19.     0.41]\n",
      " [  1.     2.    19.     0.55]] -> [ 0.45]\n",
      "[[  1.     6.    18.     0.6 ]\n",
      " [  1.     0.    19.     0.43]\n",
      " [  1.     1.    19.     0.41]\n",
      " [  1.     2.    19.     0.55]\n",
      " [  1.     3.    19.     0.45]] -> [ 0.18]\n",
      "[[  1.     0.    19.     0.43]\n",
      " [  1.     1.    19.     0.41]\n",
      " [  1.     2.    19.     0.55]\n",
      " [  1.     3.    19.     0.45]\n",
      " [  1.     4.    19.     0.18]] -> [ 0.6]\n",
      "[[  1.     1.    19.     0.41]\n",
      " [  1.     2.    19.     0.55]\n",
      " [  1.     3.    19.     0.45]\n",
      " [  1.     4.    19.     0.18]\n",
      " [  1.     5.    19.     0.6 ]] -> [ 0.69]\n",
      "[[  1.     2.    19.     0.55]\n",
      " [  1.     3.    19.     0.45]\n",
      " [  1.     4.    19.     0.18]\n",
      " [  1.     5.    19.     0.6 ]\n",
      " [  1.     6.    19.     0.69]] -> [ 0.54]\n",
      "[[  1.     3.    19.     0.45]\n",
      " [  1.     4.    19.     0.18]\n",
      " [  1.     5.    19.     0.6 ]\n",
      " [  1.     6.    19.     0.69]\n",
      " [  1.     0.    20.     0.54]] -> [ 0.39]\n",
      "[[  1.     4.    19.     0.18]\n",
      " [  1.     5.    19.     0.6 ]\n",
      " [  1.     6.    19.     0.69]\n",
      " [  1.     0.    20.     0.54]\n",
      " [  1.     1.    20.     0.39]] -> [ 0.5]\n",
      "[[  1.     5.    19.     0.6 ]\n",
      " [  1.     6.    19.     0.69]\n",
      " [  1.     0.    20.     0.54]\n",
      " [  1.     1.    20.     0.39]\n",
      " [  1.     2.    20.     0.5 ]] -> [ 0.44]\n",
      "[[  1.     6.    19.     0.69]\n",
      " [  1.     0.    20.     0.54]\n",
      " [  1.     1.    20.     0.39]\n",
      " [  1.     2.    20.     0.5 ]\n",
      " [  1.     3.    20.     0.44]] -> [ 0.54]\n",
      "[[  1.     0.    20.     0.54]\n",
      " [  1.     1.    20.     0.39]\n",
      " [  1.     2.    20.     0.5 ]\n",
      " [  1.     3.    20.     0.44]\n",
      " [  1.     4.    20.     0.54]] -> [ 0.57]\n",
      "[[  1.     1.    20.     0.39]\n",
      " [  1.     2.    20.     0.5 ]\n",
      " [  1.     3.    20.     0.44]\n",
      " [  1.     4.    20.     0.54]\n",
      " [  1.     5.    20.     0.57]] -> [ 0.82]\n",
      "[[  1.     2.    20.     0.5 ]\n",
      " [  1.     3.    20.     0.44]\n",
      " [  1.     4.    20.     0.54]\n",
      " [  1.     5.    20.     0.57]\n",
      " [  1.     6.    20.     0.82]] -> [ 0.57]\n",
      "[[  1.     3.    20.     0.44]\n",
      " [  1.     4.    20.     0.54]\n",
      " [  1.     5.    20.     0.57]\n",
      " [  1.     6.    20.     0.82]\n",
      " [  1.     0.    21.     0.57]] -> [ 0.44]\n",
      "[[  1.     4.    20.     0.54]\n",
      " [  1.     5.    20.     0.57]\n",
      " [  1.     6.    20.     0.82]\n",
      " [  1.     0.    21.     0.57]\n",
      " [  1.     1.    21.     0.44]] -> [ 0.56]\n",
      "[[  1.     5.    20.     0.57]\n",
      " [  1.     6.    20.     0.82]\n",
      " [  1.     0.    21.     0.57]\n",
      " [  1.     1.    21.     0.44]\n",
      " [  1.     2.    21.     0.56]] -> [ 0.51]\n",
      "[[  1.     6.    20.     0.82]\n",
      " [  1.     0.    21.     0.57]\n",
      " [  1.     1.    21.     0.44]\n",
      " [  1.     2.    21.     0.56]\n",
      " [  1.     3.    21.     0.51]] -> [ 0.55]\n",
      "[[  1.     0.    21.     0.57]\n",
      " [  1.     1.    21.     0.44]\n",
      " [  1.     2.    21.     0.56]\n",
      " [  1.     3.    21.     0.51]\n",
      " [  1.     4.    21.     0.55]] -> [ 0.28]\n",
      "[[  1.     1.    21.     0.44]\n",
      " [  1.     2.    21.     0.56]\n",
      " [  1.     3.    21.     0.51]\n",
      " [  1.     4.    21.     0.55]\n",
      " [  1.     5.    21.     0.28]] -> [ 0.56]\n",
      "[[  1.     2.    21.     0.56]\n",
      " [  1.     3.    21.     0.51]\n",
      " [  1.     4.    21.     0.55]\n",
      " [  1.     5.    21.     0.28]\n",
      " [  1.     6.    21.     0.56]] -> [ 0.54]\n",
      "[[  1.     3.    21.     0.51]\n",
      " [  1.     4.    21.     0.55]\n",
      " [  1.     5.    21.     0.28]\n",
      " [  1.     6.    21.     0.56]\n",
      " [  1.     0.    22.     0.54]] -> [ 0.36]\n",
      "[[  1.     4.    21.     0.55]\n",
      " [  1.     5.    21.     0.28]\n",
      " [  1.     6.    21.     0.56]\n",
      " [  1.     0.    22.     0.54]\n",
      " [  1.     1.    22.     0.36]] -> [ 0.12]\n",
      "[[  1.     5.    21.     0.28]\n",
      " [  1.     6.    21.     0.56]\n",
      " [  1.     0.    22.     0.54]\n",
      " [  1.     1.    22.     0.36]\n",
      " [  2.     2.    22.     0.12]] -> [ 0.25]\n",
      "[[  1.     6.    21.     0.56]\n",
      " [  1.     0.    22.     0.54]\n",
      " [  1.     1.    22.     0.36]\n",
      " [  2.     2.    22.     0.12]\n",
      " [  2.     3.    22.     0.25]] -> [ 0.41]\n",
      "[[  1.     0.    22.     0.54]\n",
      " [  1.     1.    22.     0.36]\n",
      " [  2.     2.    22.     0.12]\n",
      " [  2.     3.    22.     0.25]\n",
      " [  2.     4.    22.     0.41]] -> [ 0.11]\n",
      "[[  1.     1.    22.     0.36]\n",
      " [  2.     2.    22.     0.12]\n",
      " [  2.     3.    22.     0.25]\n",
      " [  2.     4.    22.     0.41]\n",
      " [  2.     5.    22.     0.11]] -> [ 0.06]\n",
      "[[  2.     2.    22.     0.12]\n",
      " [  2.     3.    22.     0.25]\n",
      " [  2.     4.    22.     0.41]\n",
      " [  2.     5.    22.     0.11]\n",
      " [  2.     6.    22.     0.06]] -> [ 0.09]\n",
      "[[  2.     3.    22.     0.25]\n",
      " [  2.     4.    22.     0.41]\n",
      " [  2.     5.    22.     0.11]\n",
      " [  2.     6.    22.     0.06]\n",
      " [  2.     0.    23.     0.09]] -> [ 0.35]\n",
      "[[  2.     4.    22.     0.41]\n",
      " [  2.     5.    22.     0.11]\n",
      " [  2.     6.    22.     0.06]\n",
      " [  2.     0.    23.     0.09]\n",
      " [  2.     1.    23.     0.35]] -> [ 0.29]\n",
      "[[  2.     5.    22.     0.11]\n",
      " [  2.     6.    22.     0.06]\n",
      " [  2.     0.    23.     0.09]\n",
      " [  2.     1.    23.     0.35]\n",
      " [  2.     2.    23.     0.29]] -> [ 0.24]\n",
      "[[  2.     6.    22.     0.06]\n",
      " [  2.     0.    23.     0.09]\n",
      " [  2.     1.    23.     0.35]\n",
      " [  2.     2.    23.     0.29]\n",
      " [  2.     3.    23.     0.24]] -> [ 0.23]\n",
      "[[  2.     0.    23.     0.09]\n",
      " [  2.     1.    23.     0.35]\n",
      " [  2.     2.    23.     0.29]\n",
      " [  2.     3.    23.     0.24]\n",
      " [  2.     4.    23.     0.23]] -> [ 0.14]\n",
      "[[  2.     1.    23.     0.35]\n",
      " [  2.     2.    23.     0.29]\n",
      " [  2.     3.    23.     0.24]\n",
      " [  2.     4.    23.     0.23]\n",
      " [  2.     5.    23.     0.14]] -> [ 0.21]\n",
      "[[  2.     2.    23.     0.29]\n",
      " [  2.     3.    23.     0.24]\n",
      " [  2.     4.    23.     0.23]\n",
      " [  2.     5.    23.     0.14]\n",
      " [  2.     6.    23.     0.21]] -> [ 0.2]\n",
      "[[  2.     3.    23.     0.24]\n",
      " [  2.     4.    23.     0.23]\n",
      " [  2.     5.    23.     0.14]\n",
      " [  2.     6.    23.     0.21]\n",
      " [  2.     0.    24.     0.2 ]] -> [ 0.25]\n",
      "[[  2.     4.    23.     0.23]\n",
      " [  2.     5.    23.     0.14]\n",
      " [  2.     6.    23.     0.21]\n",
      " [  2.     0.    24.     0.2 ]\n",
      " [  2.     1.    24.     0.25]] -> [ 0.23]\n",
      "[[  2.     5.    23.     0.14]\n",
      " [  2.     6.    23.     0.21]\n",
      " [  2.     0.    24.     0.2 ]\n",
      " [  2.     1.    24.     0.25]\n",
      " [  2.     2.    24.     0.23]] -> [ 0.27]\n",
      "[[  2.     6.    23.     0.21]\n",
      " [  2.     0.    24.     0.2 ]\n",
      " [  2.     1.    24.     0.25]\n",
      " [  2.     2.    24.     0.23]\n",
      " [  2.     3.    24.     0.27]] -> [ 0.31]\n",
      "[[  2.     0.    24.     0.2 ]\n",
      " [  2.     1.    24.     0.25]\n",
      " [  2.     2.    24.     0.23]\n",
      " [  2.     3.    24.     0.27]\n",
      " [  2.     4.    24.     0.31]] -> [ 0.16]\n",
      "[[  2.     1.    24.     0.25]\n",
      " [  2.     2.    24.     0.23]\n",
      " [  2.     3.    24.     0.27]\n",
      " [  2.     4.    24.     0.31]\n",
      " [  2.     5.    24.     0.16]] -> [ 0.14]\n",
      "[[  2.     2.    24.     0.23]\n",
      " [  2.     3.    24.     0.27]\n",
      " [  2.     4.    24.     0.31]\n",
      " [  2.     5.    24.     0.16]\n",
      " [  2.     6.    24.     0.14]] -> [ 0.3]\n",
      "[[  2.     3.    24.     0.27]\n",
      " [  2.     4.    24.     0.31]\n",
      " [  2.     5.    24.     0.16]\n",
      " [  2.     6.    24.     0.14]\n",
      " [  2.     0.    25.     0.3 ]] -> [ 0.32]\n",
      "[[  2.     4.    24.     0.31]\n",
      " [  2.     5.    24.     0.16]\n",
      " [  2.     6.    24.     0.14]\n",
      " [  2.     0.    25.     0.3 ]\n",
      " [  2.     1.    25.     0.32]] -> [ 0.75]\n",
      "[[  2.     5.    24.     0.16]\n",
      " [  2.     6.    24.     0.14]\n",
      " [  2.     0.    25.     0.3 ]\n",
      " [  2.     1.    25.     0.32]\n",
      " [  2.     2.    25.     0.75]] -> [ 0.35]\n",
      "[[  2.     6.    24.     0.14]\n",
      " [  2.     0.    25.     0.3 ]\n",
      " [  2.     1.    25.     0.32]\n",
      " [  2.     2.    25.     0.75]\n",
      " [  2.     3.    25.     0.35]] -> [ 0.26]\n",
      "[[  2.     0.    25.     0.3 ]\n",
      " [  2.     1.    25.     0.32]\n",
      " [  2.     2.    25.     0.75]\n",
      " [  2.     3.    25.     0.35]\n",
      " [  2.     4.    25.     0.26]] -> [ 0.12]\n",
      "[[  2.     1.    25.     0.32]\n",
      " [  2.     2.    25.     0.75]\n",
      " [  2.     3.    25.     0.35]\n",
      " [  2.     4.    25.     0.26]\n",
      " [  2.     5.    25.     0.12]] -> [ 0.21]\n",
      "[[  2.     2.    25.     0.75]\n",
      " [  2.     3.    25.     0.35]\n",
      " [  2.     4.    25.     0.26]\n",
      " [  2.     5.    25.     0.12]\n",
      " [  2.     6.    25.     0.21]] -> [ 0.23]\n",
      "[[  2.     3.    25.     0.35]\n",
      " [  2.     4.    25.     0.26]\n",
      " [  2.     5.    25.     0.12]\n",
      " [  2.     6.    25.     0.21]\n",
      " [  2.     0.    26.     0.23]] -> [ 0.28]\n",
      "[[  2.     4.    25.     0.26]\n",
      " [  2.     5.    25.     0.12]\n",
      " [  2.     6.    25.     0.21]\n",
      " [  2.     0.    26.     0.23]\n",
      " [  2.     1.    26.     0.28]] -> [ 0.25]\n",
      "[[  2.     5.    25.     0.12]\n",
      " [  2.     6.    25.     0.21]\n",
      " [  2.     0.    26.     0.23]\n",
      " [  2.     1.    26.     0.28]\n",
      " [  2.     2.    26.     0.25]] -> [ 0.31]\n",
      "[[  2.     6.    25.     0.21]\n",
      " [  2.     0.    26.     0.23]\n",
      " [  2.     1.    26.     0.28]\n",
      " [  2.     2.    26.     0.25]\n",
      " [  2.     3.    26.     0.31]] -> [ 0.21]\n",
      "[[  2.     0.    26.     0.23]\n",
      " [  2.     1.    26.     0.28]\n",
      " [  2.     2.    26.     0.25]\n",
      " [  2.     3.    26.     0.31]\n",
      " [  2.     4.    26.     0.21]] -> [ 0.17]\n",
      "[[  2.     1.    26.     0.28]\n",
      " [  2.     2.    26.     0.25]\n",
      " [  2.     3.    26.     0.31]\n",
      " [  2.     4.    26.     0.21]\n",
      " [  2.     5.    26.     0.17]] -> [ 0.1]\n",
      "[[  2.     2.    26.     0.25]\n",
      " [  2.     3.    26.     0.31]\n",
      " [  2.     4.    26.     0.21]\n",
      " [  2.     5.    26.     0.17]\n",
      " [  2.     6.    26.     0.1 ]] -> [ 0.29]\n",
      "[[  2.     3.    26.     0.31]\n",
      " [  2.     4.    26.     0.21]\n",
      " [  2.     5.    26.     0.17]\n",
      " [  2.     6.    26.     0.1 ]\n",
      " [  2.     0.    27.     0.29]] -> [ 0.34]\n",
      "[[  2.     4.    26.     0.21]\n",
      " [  2.     5.    26.     0.17]\n",
      " [  2.     6.    26.     0.1 ]\n",
      " [  2.     0.    27.     0.29]\n",
      " [  2.     1.    27.     0.34]] -> [ 0.28]\n",
      "[[  2.     5.    26.     0.17]\n",
      " [  2.     6.    26.     0.1 ]\n",
      " [  2.     0.    27.     0.29]\n",
      " [  2.     1.    27.     0.34]\n",
      " [  2.     2.    27.     0.28]] -> [ 0.2]\n",
      "[[  2.     6.    26.     0.1 ]\n",
      " [  2.     0.    27.     0.29]\n",
      " [  2.     1.    27.     0.34]\n",
      " [  2.     2.    27.     0.28]\n",
      " [  2.     3.    27.     0.2 ]] -> [ 0.36]\n",
      "[[  2.     0.    27.     0.29]\n",
      " [  2.     1.    27.     0.34]\n",
      " [  2.     2.    27.     0.28]\n",
      " [  2.     3.    27.     0.2 ]\n",
      " [  2.     4.    27.     0.36]] -> [ 0.23]\n",
      "[[  2.     1.    27.     0.34]\n",
      " [  2.     2.    27.     0.28]\n",
      " [  2.     3.    27.     0.2 ]\n",
      " [  2.     4.    27.     0.36]\n",
      " [  2.     5.    27.     0.23]] -> [ 0.15]\n",
      "[[  2.     2.    27.     0.28]\n",
      " [  2.     3.    27.     0.2 ]\n",
      " [  2.     4.    27.     0.36]\n",
      " [  2.     5.    27.     0.23]\n",
      " [  2.     6.    27.     0.15]] -> [ 0.42]\n",
      "[[  2.     3.    27.     0.2 ]\n",
      " [  2.     4.    27.     0.36]\n",
      " [  2.     5.    27.     0.23]\n",
      " [  2.     6.    27.     0.15]\n",
      " [  2.     0.    28.     0.42]] -> [ 0.28]\n",
      "[[  2.     4.    27.     0.36]\n",
      " [  2.     5.    27.     0.23]\n",
      " [  2.     6.    27.     0.15]\n",
      " [  2.     0.    28.     0.42]\n",
      " [  2.     1.    28.     0.28]] -> [ 0.24]\n",
      "[[  2.     5.    27.     0.23]\n",
      " [  2.     6.    27.     0.15]\n",
      " [  2.     0.    28.     0.42]\n",
      " [  2.     1.    28.     0.28]\n",
      " [  2.     2.    28.     0.24]] -> [ 0.29]\n",
      "[[  2.     6.    27.     0.15]\n",
      " [  2.     0.    28.     0.42]\n",
      " [  2.     1.    28.     0.28]\n",
      " [  2.     2.    28.     0.24]\n",
      " [  2.     3.    28.     0.29]] -> [ 0.2]\n",
      "[[  2.     0.    28.     0.42]\n",
      " [  2.     1.    28.     0.28]\n",
      " [  2.     2.    28.     0.24]\n",
      " [  2.     3.    28.     0.29]\n",
      " [  2.     4.    28.     0.2 ]] -> [ 0.14]\n",
      "[[  2.     1.    28.     0.28]\n",
      " [  2.     2.    28.     0.24]\n",
      " [  2.     3.    28.     0.29]\n",
      " [  2.     4.    28.     0.2 ]\n",
      " [  2.     5.    28.     0.14]] -> [ 0.18]\n",
      "[[  2.     2.    28.     0.24]\n",
      " [  2.     3.    28.     0.29]\n",
      " [  2.     4.    28.     0.2 ]\n",
      " [  2.     5.    28.     0.14]\n",
      " [  2.     6.    28.     0.18]] -> [ 0.27]\n",
      "[[  2.     3.    28.     0.29]\n",
      " [  2.     4.    28.     0.2 ]\n",
      " [  2.     5.    28.     0.14]\n",
      " [  2.     6.    28.     0.18]\n",
      " [  2.     0.    29.     0.27]] -> [ 0.22]\n",
      "[[  2.     4.    28.     0.2 ]\n",
      " [  2.     5.    28.     0.14]\n",
      " [  2.     6.    28.     0.18]\n",
      " [  2.     0.    29.     0.27]\n",
      " [  2.     1.    29.     0.22]] -> [ 0.31]\n",
      "[[  2.     5.    28.     0.14]\n",
      " [  2.     6.    28.     0.18]\n",
      " [  2.     0.    29.     0.27]\n",
      " [  2.     1.    29.     0.22]\n",
      " [  2.     2.    29.     0.31]] -> [ 0.24]\n",
      "[[  2.     6.    28.     0.18]\n",
      " [  2.     0.    29.     0.27]\n",
      " [  2.     1.    29.     0.22]\n",
      " [  2.     2.    29.     0.31]\n",
      " [  2.     3.    29.     0.24]] -> [ 0.39]\n",
      "[[  2.     0.    29.     0.27]\n",
      " [  2.     1.    29.     0.22]\n",
      " [  2.     2.    29.     0.31]\n",
      " [  2.     3.    29.     0.24]\n",
      " [  2.     4.    29.     0.39]] -> [ 0.31]\n",
      "[[  2.     1.    29.     0.22]\n",
      " [  2.     2.    29.     0.31]\n",
      " [  2.     3.    29.     0.24]\n",
      " [  2.     4.    29.     0.39]\n",
      " [  2.     5.    29.     0.31]] -> [ 0.17]\n",
      "[[  2.     2.    29.     0.31]\n",
      " [  2.     3.    29.     0.24]\n",
      " [  2.     4.    29.     0.39]\n",
      " [  2.     5.    29.     0.31]\n",
      " [  2.     6.    29.     0.17]] -> [ 0.42]\n",
      "[[  2.     3.    29.     0.24]\n",
      " [  2.     4.    29.     0.39]\n",
      " [  2.     5.    29.     0.31]\n",
      " [  2.     6.    29.     0.17]\n",
      " [  2.     0.    30.     0.42]] -> [ 0.29]\n",
      "[[  2.     4.    29.     0.39]\n",
      " [  2.     5.    29.     0.31]\n",
      " [  2.     6.    29.     0.17]\n",
      " [  2.     0.    30.     0.42]\n",
      " [  2.     1.    30.     0.29]] -> [ 0.33]\n",
      "[[  2.     5.    29.     0.31]\n",
      " [  2.     6.    29.     0.17]\n",
      " [  2.     0.    30.     0.42]\n",
      " [  2.     1.    30.     0.29]\n",
      " [  2.     2.    30.     0.33]] -> [ 0.22]\n",
      "[[  2.     6.    29.     0.17]\n",
      " [  2.     0.    30.     0.42]\n",
      " [  2.     1.    30.     0.29]\n",
      " [  2.     2.    30.     0.33]\n",
      " [  2.     3.    30.     0.22]] -> [ 0.39]\n",
      "[[  2.     0.    30.     0.42]\n",
      " [  2.     1.    30.     0.29]\n",
      " [  2.     2.    30.     0.33]\n",
      " [  2.     3.    30.     0.22]\n",
      " [  2.     4.    30.     0.39]] -> [ 0.25]\n",
      "[[  2.     1.    30.     0.29]\n",
      " [  2.     2.    30.     0.33]\n",
      " [  2.     3.    30.     0.22]\n",
      " [  2.     4.    30.     0.39]\n",
      " [  2.     5.    30.     0.25]] -> [ 0.23]\n",
      "[[  2.     2.    30.     0.33]\n",
      " [  2.     3.    30.     0.22]\n",
      " [  2.     4.    30.     0.39]\n",
      " [  2.     5.    30.     0.25]\n",
      " [  2.     6.    30.     0.23]] -> [ 0.25]\n",
      "[[  2.     3.    30.     0.22]\n",
      " [  2.     4.    30.     0.39]\n",
      " [  2.     5.    30.     0.25]\n",
      " [  2.     6.    30.     0.23]\n",
      " [  2.     0.    31.     0.25]] -> [ 0.21]\n",
      "[[  2.     4.    30.     0.39]\n",
      " [  2.     5.    30.     0.25]\n",
      " [  2.     6.    30.     0.23]\n",
      " [  2.     0.    31.     0.25]\n",
      " [  2.     1.    31.     0.21]] -> [ 0.18]\n",
      "[[  2.     5.    30.     0.25]\n",
      " [  2.     6.    30.     0.23]\n",
      " [  2.     0.    31.     0.25]\n",
      " [  2.     1.    31.     0.21]\n",
      " [  2.     2.    31.     0.18]] -> [ 0.24]\n",
      "[[  2.     6.    30.     0.23]\n",
      " [  2.     0.    31.     0.25]\n",
      " [  2.     1.    31.     0.21]\n",
      " [  2.     2.    31.     0.18]\n",
      " [  2.     3.    31.     0.24]] -> [ 0.24]\n",
      "[[  2.     0.    31.     0.25]\n",
      " [  2.     1.    31.     0.21]\n",
      " [  2.     2.    31.     0.18]\n",
      " [  2.     3.    31.     0.24]\n",
      " [  2.     4.    31.     0.24]] -> [ 0.2]\n",
      "[[  2.     1.    31.     0.21]\n",
      " [  2.     2.    31.     0.18]\n",
      " [  2.     3.    31.     0.24]\n",
      " [  2.     4.    31.     0.24]\n",
      " [  2.     5.    31.     0.2 ]] -> [ 0.09]\n",
      "[[  2.     2.    31.     0.18]\n",
      " [  2.     3.    31.     0.24]\n",
      " [  2.     4.    31.     0.24]\n",
      " [  2.     5.    31.     0.2 ]\n",
      " [  2.     6.    31.     0.09]] -> [ 0.31]\n",
      "[[  2.     3.    31.     0.24]\n",
      " [  2.     4.    31.     0.24]\n",
      " [  2.     5.    31.     0.2 ]\n",
      " [  2.     6.    31.     0.09]\n",
      " [  2.     0.    32.     0.31]] -> [ 0.33]\n",
      "[[  2.     4.    31.     0.24]\n",
      " [  2.     5.    31.     0.2 ]\n",
      " [  2.     6.    31.     0.09]\n",
      " [  2.     0.    32.     0.31]\n",
      " [  2.     1.    32.     0.33]] -> [ 0.33]\n",
      "[[  2.     5.    31.     0.2 ]\n",
      " [  2.     6.    31.     0.09]\n",
      " [  2.     0.    32.     0.31]\n",
      " [  2.     1.    32.     0.33]\n",
      " [  2.     2.    32.     0.33]] -> [ 0.31]\n",
      "[[  2.     6.    31.     0.09]\n",
      " [  2.     0.    32.     0.31]\n",
      " [  2.     1.    32.     0.33]\n",
      " [  2.     2.    32.     0.33]\n",
      " [  2.     3.    32.     0.31]] -> [ 0.27]\n",
      "[[  2.     0.    32.     0.31]\n",
      " [  2.     1.    32.     0.33]\n",
      " [  2.     2.    32.     0.33]\n",
      " [  2.     3.    32.     0.31]\n",
      " [  2.     4.    32.     0.27]] -> [ 0.35]\n",
      "[[  2.     1.    32.     0.33]\n",
      " [  2.     2.    32.     0.33]\n",
      " [  2.     3.    32.     0.31]\n",
      " [  2.     4.    32.     0.27]\n",
      " [  2.     5.    32.     0.35]] -> [ 0.15]\n",
      "[[  2.     2.    32.     0.33]\n",
      " [  2.     3.    32.     0.31]\n",
      " [  2.     4.    32.     0.27]\n",
      " [  2.     5.    32.     0.35]\n",
      " [  2.     6.    32.     0.15]] -> [ 0.25]\n",
      "[[  2.     3.    32.     0.31]\n",
      " [  2.     4.    32.     0.27]\n",
      " [  2.     5.    32.     0.35]\n",
      " [  2.     6.    32.     0.15]\n",
      " [  2.     0.    33.     0.25]] -> [ 0.32]\n",
      "[[  2.     4.    32.     0.27]\n",
      " [  2.     5.    32.     0.35]\n",
      " [  2.     6.    32.     0.15]\n",
      " [  2.     0.    33.     0.25]\n",
      " [  2.     1.    33.     0.32]] -> [ 0.29]\n",
      "[[  2.     5.    32.     0.35]\n",
      " [  2.     6.    32.     0.15]\n",
      " [  2.     0.    33.     0.25]\n",
      " [  2.     1.    33.     0.32]\n",
      " [  2.     2.    33.     0.29]] -> [ 0.32]\n",
      "[[  2.     6.    32.     0.15]\n",
      " [  2.     0.    33.     0.25]\n",
      " [  2.     1.    33.     0.32]\n",
      " [  2.     2.    33.     0.29]\n",
      " [  2.     3.    33.     0.32]] -> [ 0.21]\n",
      "[[  2.     0.    33.     0.25]\n",
      " [  2.     1.    33.     0.32]\n",
      " [  2.     2.    33.     0.29]\n",
      " [  2.     3.    33.     0.32]\n",
      " [  2.     4.    33.     0.21]] -> [ 0.92]\n",
      "[[  2.     1.    33.     0.32]\n",
      " [  2.     2.    33.     0.29]\n",
      " [  2.     3.    33.     0.32]\n",
      " [  2.     4.    33.     0.21]\n",
      " [  2.     5.    33.     0.92]] -> [ 0.19]\n",
      "[[  2.     2.    33.     0.29]\n",
      " [  2.     3.    33.     0.32]\n",
      " [  2.     4.    33.     0.21]\n",
      " [  2.     5.    33.     0.92]\n",
      " [  2.     6.    33.     0.19]] -> [ 0.37]\n",
      "[[  2.     3.    33.     0.32]\n",
      " [  2.     4.    33.     0.21]\n",
      " [  2.     5.    33.     0.92]\n",
      " [  2.     6.    33.     0.19]\n",
      " [  2.     0.    34.     0.37]] -> [ 0.29]\n",
      "[[  2.     4.    33.     0.21]\n",
      " [  2.     5.    33.     0.92]\n",
      " [  2.     6.    33.     0.19]\n",
      " [  2.     0.    34.     0.37]\n",
      " [  2.     1.    34.     0.29]] -> [ 0.33]\n",
      "[[  2.     5.    33.     0.92]\n",
      " [  2.     6.    33.     0.19]\n",
      " [  2.     0.    34.     0.37]\n",
      " [  2.     1.    34.     0.29]\n",
      " [  2.     2.    34.     0.33]] -> [ 0.16]\n",
      "[[  2.     6.    33.     0.19]\n",
      " [  2.     0.    34.     0.37]\n",
      " [  2.     1.    34.     0.29]\n",
      " [  2.     2.    34.     0.33]\n",
      " [  2.     3.    34.     0.16]] -> [ 0.22]\n",
      "[[  2.     0.    34.     0.37]\n",
      " [  2.     1.    34.     0.29]\n",
      " [  2.     2.    34.     0.33]\n",
      " [  2.     3.    34.     0.16]\n",
      " [  2.     4.    34.     0.22]] -> [ 0.25]\n",
      "[[  2.     1.    34.     0.29]\n",
      " [  2.     2.    34.     0.33]\n",
      " [  2.     3.    34.     0.16]\n",
      " [  2.     4.    34.     0.22]\n",
      " [  2.     5.    34.     0.25]] -> [ 0.21]\n",
      "[[  2.     2.    34.     0.33]\n",
      " [  2.     3.    34.     0.16]\n",
      " [  2.     4.    34.     0.22]\n",
      " [  2.     5.    34.     0.25]\n",
      " [  2.     6.    34.     0.21]] -> [ 0.46]\n",
      "[[  2.     3.    34.     0.16]\n",
      " [  2.     4.    34.     0.22]\n",
      " [  2.     5.    34.     0.25]\n",
      " [  2.     6.    34.     0.21]\n",
      " [  2.     0.    35.     0.46]] -> [ 0.34]\n",
      "[[  2.     4.    34.     0.22]\n",
      " [  2.     5.    34.     0.25]\n",
      " [  2.     6.    34.     0.21]\n",
      " [  2.     0.    35.     0.46]\n",
      " [  2.     1.    35.     0.34]] -> [ 0.31]\n",
      "[[  2.     5.    34.     0.25]\n",
      " [  2.     6.    34.     0.21]\n",
      " [  2.     0.    35.     0.46]\n",
      " [  2.     1.    35.     0.34]\n",
      " [  2.     2.    35.     0.31]] -> [ 0.22]\n",
      "[[  2.     6.    34.     0.21]\n",
      " [  2.     0.    35.     0.46]\n",
      " [  2.     1.    35.     0.34]\n",
      " [  2.     2.    35.     0.31]\n",
      " [  3.     3.    35.     0.22]] -> [ 0.3]\n",
      "[[  2.     0.    35.     0.46]\n",
      " [  2.     1.    35.     0.34]\n",
      " [  2.     2.    35.     0.31]\n",
      " [  3.     3.    35.     0.22]\n",
      " [  3.     4.    35.     0.3 ]] -> [ 0.28]\n",
      "[[  2.     1.    35.     0.34]\n",
      " [  2.     2.    35.     0.31]\n",
      " [  3.     3.    35.     0.22]\n",
      " [  3.     4.    35.     0.3 ]\n",
      " [  3.     5.    35.     0.28]] -> [ 0.14]\n",
      "[[  2.     2.    35.     0.31]\n",
      " [  3.     3.    35.     0.22]\n",
      " [  3.     4.    35.     0.3 ]\n",
      " [  3.     5.    35.     0.28]\n",
      " [  3.     6.    35.     0.14]] -> [ 0.25]\n",
      "[[  3.     3.    35.     0.22]\n",
      " [  3.     4.    35.     0.3 ]\n",
      " [  3.     5.    35.     0.28]\n",
      " [  3.     6.    35.     0.14]\n",
      " [  3.     0.    36.     0.25]] -> [ 0.33]\n",
      "[[  3.     4.    35.     0.3 ]\n",
      " [  3.     5.    35.     0.28]\n",
      " [  3.     6.    35.     0.14]\n",
      " [  3.     0.    36.     0.25]\n",
      " [  3.     1.    36.     0.33]] -> [ 0.28]\n",
      "[[  3.     5.    35.     0.28]\n",
      " [  3.     6.    35.     0.14]\n",
      " [  3.     0.    36.     0.25]\n",
      " [  3.     1.    36.     0.33]\n",
      " [  3.     2.    36.     0.28]] -> [ 0.24]\n",
      "[[  3.     6.    35.     0.14]\n",
      " [  3.     0.    36.     0.25]\n",
      " [  3.     1.    36.     0.33]\n",
      " [  3.     2.    36.     0.28]\n",
      " [  3.     3.    36.     0.24]] -> [ 0.42]\n",
      "[[  3.     0.    36.     0.25]\n",
      " [  3.     1.    36.     0.33]\n",
      " [  3.     2.    36.     0.28]\n",
      " [  3.     3.    36.     0.24]\n",
      " [  3.     4.    36.     0.42]] -> [ 0.26]\n",
      "[[  3.     1.    36.     0.33]\n",
      " [  3.     2.    36.     0.28]\n",
      " [  3.     3.    36.     0.24]\n",
      " [  3.     4.    36.     0.42]\n",
      " [  3.     5.    36.     0.26]] -> [ 0.19]\n",
      "[[  3.     2.    36.     0.28]\n",
      " [  3.     3.    36.     0.24]\n",
      " [  3.     4.    36.     0.42]\n",
      " [  3.     5.    36.     0.26]\n",
      " [  3.     6.    36.     0.19]] -> [ 0.41]\n",
      "[[  3.     3.    36.     0.24]\n",
      " [  3.     4.    36.     0.42]\n",
      " [  3.     5.    36.     0.26]\n",
      " [  3.     6.    36.     0.19]\n",
      " [  3.     0.    37.     0.41]] -> [ 0.34]\n",
      "[[  3.     4.    36.     0.42]\n",
      " [  3.     5.    36.     0.26]\n",
      " [  3.     6.    36.     0.19]\n",
      " [  3.     0.    37.     0.41]\n",
      " [  3.     1.    37.     0.34]] -> [ 0.08]\n",
      "[[  3.     5.    36.     0.26]\n",
      " [  3.     6.    36.     0.19]\n",
      " [  3.     0.    37.     0.41]\n",
      " [  3.     1.    37.     0.34]\n",
      " [  3.     2.    37.     0.08]] -> [ 0.]\n",
      "[[  3.     6.    36.     0.19]\n",
      " [  3.     0.    37.     0.41]\n",
      " [  3.     1.    37.     0.34]\n",
      " [  3.     2.    37.     0.08]\n",
      " [  3.     3.    37.     0.  ]] -> [ 0.]\n",
      "[[  3.     0.    37.     0.41]\n",
      " [  3.     1.    37.     0.34]\n",
      " [  3.     2.    37.     0.08]\n",
      " [  3.     3.    37.     0.  ]\n",
      " [  3.     4.    37.     0.  ]] -> [ 0.11]\n",
      "[[  3.     1.    37.     0.34]\n",
      " [  3.     2.    37.     0.08]\n",
      " [  3.     3.    37.     0.  ]\n",
      " [  3.     4.    37.     0.  ]\n",
      " [  3.     5.    37.     0.11]] -> [ 0.16]\n",
      "[[  3.     2.    37.     0.08]\n",
      " [  3.     3.    37.     0.  ]\n",
      " [  3.     4.    37.     0.  ]\n",
      " [  3.     5.    37.     0.11]\n",
      " [  3.     6.    37.     0.16]] -> [ 0.27]\n",
      "[[  3.     3.    37.     0.  ]\n",
      " [  3.     4.    37.     0.  ]\n",
      " [  3.     5.    37.     0.11]\n",
      " [  3.     6.    37.     0.16]\n",
      " [  3.     0.    38.     0.27]] -> [ 0.27]\n",
      "[[  3.     4.    37.     0.  ]\n",
      " [  3.     5.    37.     0.11]\n",
      " [  3.     6.    37.     0.16]\n",
      " [  3.     0.    38.     0.27]\n",
      " [  3.     1.    38.     0.27]] -> [ 0.21]\n",
      "[[  3.     5.    37.     0.11]\n",
      " [  3.     6.    37.     0.16]\n",
      " [  3.     0.    38.     0.27]\n",
      " [  3.     1.    38.     0.27]\n",
      " [  3.     2.    38.     0.21]] -> [ 0.37]\n",
      "[[  3.     6.    37.     0.16]\n",
      " [  3.     0.    38.     0.27]\n",
      " [  3.     1.    38.     0.27]\n",
      " [  3.     2.    38.     0.21]\n",
      " [  3.     3.    38.     0.37]] -> [ 0.41]\n",
      "[[  3.     0.    38.     0.27]\n",
      " [  3.     1.    38.     0.27]\n",
      " [  3.     2.    38.     0.21]\n",
      " [  3.     3.    38.     0.37]\n",
      " [  3.     4.    38.     0.41]] -> [ 0.23]\n",
      "[[  3.     1.    38.     0.27]\n",
      " [  3.     2.    38.     0.21]\n",
      " [  3.     3.    38.     0.37]\n",
      " [  3.     4.    38.     0.41]\n",
      " [  3.     5.    38.     0.23]] -> [ 0.3]\n",
      "[[  3.     2.    38.     0.21]\n",
      " [  3.     3.    38.     0.37]\n",
      " [  3.     4.    38.     0.41]\n",
      " [  3.     5.    38.     0.23]\n",
      " [  3.     6.    38.     0.3 ]] -> [ 0.25]\n",
      "[[  3.     3.    38.     0.37]\n",
      " [  3.     4.    38.     0.41]\n",
      " [  3.     5.    38.     0.23]\n",
      " [  3.     6.    38.     0.3 ]\n",
      " [  3.     0.    39.     0.25]] -> [ 0.22]\n",
      "[[  3.     4.    38.     0.41]\n",
      " [  3.     5.    38.     0.23]\n",
      " [  3.     6.    38.     0.3 ]\n",
      " [  3.     0.    39.     0.25]\n",
      " [  3.     1.    39.     0.22]] -> [ 0.26]\n",
      "[[  3.     5.    38.     0.23]\n",
      " [  3.     6.    38.     0.3 ]\n",
      " [  3.     0.    39.     0.25]\n",
      " [  3.     1.    39.     0.22]\n",
      " [  3.     2.    39.     0.26]] -> [ 0.29]\n",
      "[[  3.     6.    38.     0.3 ]\n",
      " [  3.     0.    39.     0.25]\n",
      " [  3.     1.    39.     0.22]\n",
      " [  3.     2.    39.     0.26]\n",
      " [  3.     3.    39.     0.29]] -> [ 0.31]\n",
      "[[  3.     0.    39.     0.25]\n",
      " [  3.     1.    39.     0.22]\n",
      " [  3.     2.    39.     0.26]\n",
      " [  3.     3.    39.     0.29]\n",
      " [  3.     4.    39.     0.31]] -> [ 0.29]\n",
      "[[  3.     1.    39.     0.22]\n",
      " [  3.     2.    39.     0.26]\n",
      " [  3.     3.    39.     0.29]\n",
      " [  3.     4.    39.     0.31]\n",
      " [  3.     5.    39.     0.29]] -> [ 0.12]\n",
      "[[  3.     2.    39.     0.26]\n",
      " [  3.     3.    39.     0.29]\n",
      " [  3.     4.    39.     0.31]\n",
      " [  3.     5.    39.     0.29]\n",
      " [  3.     6.    39.     0.12]] -> [ 0.15]\n",
      "[[  3.     3.    39.     0.29]\n",
      " [  3.     4.    39.     0.31]\n",
      " [  3.     5.    39.     0.29]\n",
      " [  3.     6.    39.     0.12]\n",
      " [  3.     0.    40.     0.15]] -> [ 0.48]\n",
      "[[  3.     4.    39.     0.31]\n",
      " [  3.     5.    39.     0.29]\n",
      " [  3.     6.    39.     0.12]\n",
      " [  3.     0.    40.     0.15]\n",
      " [  3.     1.    40.     0.48]] -> [ 0.18]\n",
      "[[  3.     5.    39.     0.29]\n",
      " [  3.     6.    39.     0.12]\n",
      " [  3.     0.    40.     0.15]\n",
      " [  3.     1.    40.     0.48]\n",
      " [  3.     2.    40.     0.18]] -> [ 0.25]\n",
      "[[  3.     6.    39.     0.12]\n",
      " [  3.     0.    40.     0.15]\n",
      " [  3.     1.    40.     0.48]\n",
      " [  3.     2.    40.     0.18]\n",
      " [  3.     3.    40.     0.25]] -> [ 0.27]\n",
      "[[  3.     0.    40.     0.15]\n",
      " [  3.     1.    40.     0.48]\n",
      " [  3.     2.    40.     0.18]\n",
      " [  3.     3.    40.     0.25]\n",
      " [  3.     4.    40.     0.27]] -> [ 0.25]\n",
      "[[  3.     1.    40.     0.48]\n",
      " [  3.     2.    40.     0.18]\n",
      " [  3.     3.    40.     0.25]\n",
      " [  3.     4.    40.     0.27]\n",
      " [  3.     5.    40.     0.25]] -> [ 0.21]\n",
      "[[  3.     2.    40.     0.18]\n",
      " [  3.     3.    40.     0.25]\n",
      " [  3.     4.    40.     0.27]\n",
      " [  3.     5.    40.     0.25]\n",
      " [  3.     6.    40.     0.21]] -> [ 0.28]\n",
      "[[  3.     3.    40.     0.25]\n",
      " [  3.     4.    40.     0.27]\n",
      " [  3.     5.    40.     0.25]\n",
      " [  3.     6.    40.     0.21]\n",
      " [  3.     0.    41.     0.28]] -> [ 0.24]\n",
      "[[  3.     4.    40.     0.27]\n",
      " [  3.     5.    40.     0.25]\n",
      " [  3.     6.    40.     0.21]\n",
      " [  3.     0.    41.     0.28]\n",
      " [  3.     1.    41.     0.24]] -> [ 0.21]\n",
      "[[  3.     5.    40.     0.25]\n",
      " [  3.     6.    40.     0.21]\n",
      " [  3.     0.    41.     0.28]\n",
      " [  3.     1.    41.     0.24]\n",
      " [  3.     2.    41.     0.21]] -> [ 0.29]\n",
      "[[  3.     6.    40.     0.21]\n",
      " [  3.     0.    41.     0.28]\n",
      " [  3.     1.    41.     0.24]\n",
      " [  3.     2.    41.     0.21]\n",
      " [  3.     3.    41.     0.29]] -> [ 0.35]\n",
      "[[  3.     0.    41.     0.28]\n",
      " [  3.     1.    41.     0.24]\n",
      " [  3.     2.    41.     0.21]\n",
      " [  3.     3.    41.     0.29]\n",
      " [  3.     4.    41.     0.35]] -> [ 0.]\n",
      "[[  3.     1.    41.     0.24]\n",
      " [  3.     2.    41.     0.21]\n",
      " [  3.     3.    41.     0.29]\n",
      " [  3.     4.    41.     0.35]\n",
      " [  3.     5.    41.     0.  ]] -> [ 0.07]\n",
      "[[  3.     2.    41.     0.21]\n",
      " [  3.     3.    41.     0.29]\n",
      " [  3.     4.    41.     0.35]\n",
      " [  3.     5.    41.     0.  ]\n",
      " [  3.     6.    41.     0.07]] -> [ 0.32]\n",
      "[[  3.     3.    41.     0.29]\n",
      " [  3.     4.    41.     0.35]\n",
      " [  3.     5.    41.     0.  ]\n",
      " [  3.     6.    41.     0.07]\n",
      " [  3.     0.    42.     0.32]] -> [ 0.19]\n",
      "[[  3.     4.    41.     0.35]\n",
      " [  3.     5.    41.     0.  ]\n",
      " [  3.     6.    41.     0.07]\n",
      " [  3.     0.    42.     0.32]\n",
      " [  3.     1.    42.     0.19]] -> [ 0.34]\n",
      "[[  3.     5.    41.     0.  ]\n",
      " [  3.     6.    41.     0.07]\n",
      " [  3.     0.    42.     0.32]\n",
      " [  3.     1.    42.     0.19]\n",
      " [  3.     2.    42.     0.34]] -> [ 0.28]\n",
      "[[  3.     6.    41.     0.07]\n",
      " [  3.     0.    42.     0.32]\n",
      " [  3.     1.    42.     0.19]\n",
      " [  3.     2.    42.     0.34]\n",
      " [  3.     3.    42.     0.28]] -> [ 0.23]\n",
      "[[  3.     0.    42.     0.32]\n",
      " [  3.     1.    42.     0.19]\n",
      " [  3.     2.    42.     0.34]\n",
      " [  3.     3.    42.     0.28]\n",
      " [  3.     4.    42.     0.23]] -> [ 0.15]\n",
      "[[  3.     1.    42.     0.19]\n",
      " [  3.     2.    42.     0.34]\n",
      " [  3.     3.    42.     0.28]\n",
      " [  3.     4.    42.     0.23]\n",
      " [  3.     5.    42.     0.15]] -> [ 0.1]\n",
      "[[  3.     2.    42.     0.34]\n",
      " [  3.     3.    42.     0.28]\n",
      " [  3.     4.    42.     0.23]\n",
      " [  3.     5.    42.     0.15]\n",
      " [  3.     6.    42.     0.1 ]] -> [ 0.15]\n",
      "[[  3.     3.    42.     0.28]\n",
      " [  3.     4.    42.     0.23]\n",
      " [  3.     5.    42.     0.15]\n",
      " [  3.     6.    42.     0.1 ]\n",
      " [  3.     0.    43.     0.15]] -> [ 0.09]\n",
      "[[  3.     4.    42.     0.23]\n",
      " [  3.     5.    42.     0.15]\n",
      " [  3.     6.    42.     0.1 ]\n",
      " [  3.     0.    43.     0.15]\n",
      " [  3.     1.    43.     0.09]] -> [ 0.78]\n",
      "[[  3.     5.    42.     0.15]\n",
      " [  3.     6.    42.     0.1 ]\n",
      " [  3.     0.    43.     0.15]\n",
      " [  3.     1.    43.     0.09]\n",
      " [  3.     2.    43.     0.78]] -> [ 0.59]\n",
      "[[  3.     6.    42.     0.1 ]\n",
      " [  3.     0.    43.     0.15]\n",
      " [  3.     1.    43.     0.09]\n",
      " [  3.     2.    43.     0.78]\n",
      " [  3.     3.    43.     0.59]] -> [ 0.29]\n",
      "[[  3.     0.    43.     0.15]\n",
      " [  3.     1.    43.     0.09]\n",
      " [  3.     2.    43.     0.78]\n",
      " [  3.     3.    43.     0.59]\n",
      " [  3.     4.    43.     0.29]] -> [ 0.23]\n",
      "[[  3.     1.    43.     0.09]\n",
      " [  3.     2.    43.     0.78]\n",
      " [  3.     3.    43.     0.59]\n",
      " [  3.     4.    43.     0.29]\n",
      " [  3.     5.    43.     0.23]] -> [ 0.12]\n",
      "[[  3.     2.    43.     0.78]\n",
      " [  3.     3.    43.     0.59]\n",
      " [  3.     4.    43.     0.29]\n",
      " [  3.     5.    43.     0.23]\n",
      " [  3.     6.    43.     0.12]] -> [ 0.36]\n",
      "[[  3.     3.    43.     0.59]\n",
      " [  3.     4.    43.     0.29]\n",
      " [  3.     5.    43.     0.23]\n",
      " [  3.     6.    43.     0.12]\n",
      " [  3.     0.    44.     0.36]] -> [ 0.13]\n",
      "[[  3.     4.    43.     0.29]\n",
      " [  3.     5.    43.     0.23]\n",
      " [  3.     6.    43.     0.12]\n",
      " [  3.     0.    44.     0.36]\n",
      " [  3.     1.    44.     0.13]] -> [ 0.17]\n",
      "[[  3.     5.    43.     0.23]\n",
      " [  3.     6.    43.     0.12]\n",
      " [  3.     0.    44.     0.36]\n",
      " [  3.     1.    44.     0.13]\n",
      " [  3.     2.    44.     0.17]] -> [ 0.17]\n",
      "[[  3.     6.    43.     0.12]\n",
      " [  3.     0.    44.     0.36]\n",
      " [  3.     1.    44.     0.13]\n",
      " [  3.     2.    44.     0.17]\n",
      " [  3.     3.    44.     0.17]] -> [ 0.16]\n",
      "[[  3.     0.    44.     0.36]\n",
      " [  3.     1.    44.     0.13]\n",
      " [  3.     2.    44.     0.17]\n",
      " [  3.     3.    44.     0.17]\n",
      " [  3.     4.    44.     0.16]] -> [ 0.14]\n",
      "[[  3.     1.    44.     0.13]\n",
      " [  3.     2.    44.     0.17]\n",
      " [  3.     3.    44.     0.17]\n",
      " [  3.     4.    44.     0.16]\n",
      " [  3.     5.    44.     0.14]] -> [ 0.08]\n",
      "[[  3.     2.    44.     0.17]\n",
      " [  3.     3.    44.     0.17]\n",
      " [  3.     4.    44.     0.16]\n",
      " [  3.     5.    44.     0.14]\n",
      " [  3.     6.    44.     0.08]] -> [ 0.16]\n",
      "[[  3.     3.    44.     0.17]\n",
      " [  3.     4.    44.     0.16]\n",
      " [  3.     5.    44.     0.14]\n",
      " [  3.     6.    44.     0.08]\n",
      " [  3.     0.    45.     0.16]] -> [ 0.14]\n",
      "[[  3.     4.    44.     0.16]\n",
      " [  3.     5.    44.     0.14]\n",
      " [  3.     6.    44.     0.08]\n",
      " [  3.     0.    45.     0.16]\n",
      " [  3.     1.    45.     0.14]] -> [ 0.14]\n",
      "[[  3.     5.    44.     0.14]\n",
      " [  3.     6.    44.     0.08]\n",
      " [  3.     0.    45.     0.16]\n",
      " [  3.     1.    45.     0.14]\n",
      " [  3.     2.    45.     0.14]] -> [ 0.15]\n",
      "[[  3.     6.    44.     0.08]\n",
      " [  3.     0.    45.     0.16]\n",
      " [  3.     1.    45.     0.14]\n",
      " [  3.     2.    45.     0.14]\n",
      " [  3.     3.    45.     0.15]] -> [ 0.2]\n",
      "[[  3.     0.    45.     0.16]\n",
      " [  3.     1.    45.     0.14]\n",
      " [  3.     2.    45.     0.14]\n",
      " [  3.     3.    45.     0.15]\n",
      " [  3.     4.    45.     0.2 ]] -> [ 0.24]\n",
      "[[  3.     1.    45.     0.14]\n",
      " [  3.     2.    45.     0.14]\n",
      " [  3.     3.    45.     0.15]\n",
      " [  3.     4.    45.     0.2 ]\n",
      " [  3.     5.    45.     0.24]] -> [ 0.08]\n",
      "[[  3.     2.    45.     0.14]\n",
      " [  3.     3.    45.     0.15]\n",
      " [  3.     4.    45.     0.2 ]\n",
      " [  3.     5.    45.     0.24]\n",
      " [  3.     6.    45.     0.08]] -> [ 0.15]\n",
      "[[  3.     3.    45.     0.15]\n",
      " [  3.     4.    45.     0.2 ]\n",
      " [  3.     5.    45.     0.24]\n",
      " [  3.     6.    45.     0.08]\n",
      " [  3.     0.    46.     0.15]] -> [ 0.17]\n",
      "[[  3.     4.    45.     0.2 ]\n",
      " [  3.     5.    45.     0.24]\n",
      " [  3.     6.    45.     0.08]\n",
      " [  3.     0.    46.     0.15]\n",
      " [  3.     1.    46.     0.17]] -> [ 0.09]\n",
      "[[  3.     5.    45.     0.24]\n",
      " [  3.     6.    45.     0.08]\n",
      " [  3.     0.    46.     0.15]\n",
      " [  3.     1.    46.     0.17]\n",
      " [  3.     2.    46.     0.09]] -> [ 0.17]\n",
      "[[  3.     6.    45.     0.08]\n",
      " [  3.     0.    46.     0.15]\n",
      " [  3.     1.    46.     0.17]\n",
      " [  3.     2.    46.     0.09]\n",
      " [  3.     3.    46.     0.17]] -> [ 0.13]\n",
      "[[  3.     0.    46.     0.15]\n",
      " [  3.     1.    46.     0.17]\n",
      " [  3.     2.    46.     0.09]\n",
      " [  3.     3.    46.     0.17]\n",
      " [  3.     4.    46.     0.13]] -> [ 0.19]\n",
      "[[  3.     1.    46.     0.17]\n",
      " [  3.     2.    46.     0.09]\n",
      " [  3.     3.    46.     0.17]\n",
      " [  3.     4.    46.     0.13]\n",
      " [  3.     5.    46.     0.19]] -> [ 0.08]\n",
      "[[  3.     2.    46.     0.09]\n",
      " [  3.     3.    46.     0.17]\n",
      " [  3.     4.    46.     0.13]\n",
      " [  3.     5.    46.     0.19]\n",
      " [  3.     6.    46.     0.08]] -> [ 0.14]\n",
      "[[  3.     3.    46.     0.17]\n",
      " [  3.     4.    46.     0.13]\n",
      " [  3.     5.    46.     0.19]\n",
      " [  3.     6.    46.     0.08]\n",
      " [  3.     0.    47.     0.14]] -> [ 0.18]\n",
      "[[  3.     4.    46.     0.13]\n",
      " [  3.     5.    46.     0.19]\n",
      " [  3.     6.    46.     0.08]\n",
      " [  3.     0.    47.     0.14]\n",
      " [  3.     1.    47.     0.18]] -> [ 0.24]\n",
      "[[  3.     5.    46.     0.19]\n",
      " [  3.     6.    46.     0.08]\n",
      " [  3.     0.    47.     0.14]\n",
      " [  3.     1.    47.     0.18]\n",
      " [  3.     2.    47.     0.24]] -> [ 0.16]\n",
      "[[  3.     6.    46.     0.08]\n",
      " [  3.     0.    47.     0.14]\n",
      " [  3.     1.    47.     0.18]\n",
      " [  3.     2.    47.     0.24]\n",
      " [  3.     3.    47.     0.16]] -> [ 0.11]\n",
      "[[  3.     0.    47.     0.14]\n",
      " [  3.     1.    47.     0.18]\n",
      " [  3.     2.    47.     0.24]\n",
      " [  3.     3.    47.     0.16]\n",
      " [  3.     4.    47.     0.11]] -> [ 0.13]\n",
      "[[  3.     1.    47.     0.18]\n",
      " [  3.     2.    47.     0.24]\n",
      " [  3.     3.    47.     0.16]\n",
      " [  3.     4.    47.     0.11]\n",
      " [  3.     5.    47.     0.13]] -> [ 0.1]\n",
      "[[  3.     2.    47.     0.24]\n",
      " [  3.     3.    47.     0.16]\n",
      " [  3.     4.    47.     0.11]\n",
      " [  3.     5.    47.     0.13]\n",
      " [  3.     6.    47.     0.1 ]] -> [ 0.16]\n",
      "[[  3.     3.    47.     0.16]\n",
      " [  3.     4.    47.     0.11]\n",
      " [  3.     5.    47.     0.13]\n",
      " [  3.     6.    47.     0.1 ]\n",
      " [  3.     0.    48.     0.16]] -> [ 0.11]\n",
      "[[  3.     4.    47.     0.11]\n",
      " [  3.     5.    47.     0.13]\n",
      " [  3.     6.    47.     0.1 ]\n",
      " [  3.     0.    48.     0.16]\n",
      " [  3.     1.    48.     0.11]] -> [ 0.22]\n",
      "[[  3.     5.    47.     0.13]\n",
      " [  3.     6.    47.     0.1 ]\n",
      " [  3.     0.    48.     0.16]\n",
      " [  3.     1.    48.     0.11]\n",
      " [  3.     2.    48.     0.22]] -> [ 0.15]\n",
      "[[  3.     6.    47.     0.1 ]\n",
      " [  3.     0.    48.     0.16]\n",
      " [  3.     1.    48.     0.11]\n",
      " [  3.     2.    48.     0.22]\n",
      " [  0.     3.    48.     0.15]] -> [ 0.18]\n",
      "[[  3.     0.    48.     0.16]\n",
      " [  3.     1.    48.     0.11]\n",
      " [  3.     2.    48.     0.22]\n",
      " [  0.     3.    48.     0.15]\n",
      " [  0.     4.    48.     0.18]] -> [ 0.11]\n",
      "[[  3.     1.    48.     0.11]\n",
      " [  3.     2.    48.     0.22]\n",
      " [  0.     3.    48.     0.15]\n",
      " [  0.     4.    48.     0.18]\n",
      " [  0.     5.    48.     0.11]] -> [ 0.14]\n",
      "[[  3.     2.    48.     0.22]\n",
      " [  0.     3.    48.     0.15]\n",
      " [  0.     4.    48.     0.18]\n",
      " [  0.     5.    48.     0.11]\n",
      " [  0.     6.    48.     0.14]] -> [ 0.34]\n",
      "[[  0.     3.    48.     0.15]\n",
      " [  0.     4.    48.     0.18]\n",
      " [  0.     5.    48.     0.11]\n",
      " [  0.     6.    48.     0.14]\n",
      " [  0.     0.    49.     0.34]] -> [ 0.1]\n",
      "[[  0.     4.    48.     0.18]\n",
      " [  0.     5.    48.     0.11]\n",
      " [  0.     6.    48.     0.14]\n",
      " [  0.     0.    49.     0.34]\n",
      " [  0.     1.    49.     0.1 ]] -> [ 0.13]\n",
      "[[  0.     5.    48.     0.11]\n",
      " [  0.     6.    48.     0.14]\n",
      " [  0.     0.    49.     0.34]\n",
      " [  0.     1.    49.     0.1 ]\n",
      " [  0.     2.    49.     0.13]] -> [ 0.21]\n",
      "[[  0.     6.    48.     0.14]\n",
      " [  0.     0.    49.     0.34]\n",
      " [  0.     1.    49.     0.1 ]\n",
      " [  0.     2.    49.     0.13]\n",
      " [  0.     3.    49.     0.21]] -> [ 0.35]\n",
      "[[  0.     0.    49.     0.34]\n",
      " [  0.     1.    49.     0.1 ]\n",
      " [  0.     2.    49.     0.13]\n",
      " [  0.     3.    49.     0.21]\n",
      " [  0.     4.    49.     0.35]] -> [ 0.15]\n",
      "[[  0.     1.    49.     0.1 ]\n",
      " [  0.     2.    49.     0.13]\n",
      " [  0.     3.    49.     0.21]\n",
      " [  0.     4.    49.     0.35]\n",
      " [  0.     5.    49.     0.15]] -> [ 0.06]\n",
      "[[  0.     2.    49.     0.13]\n",
      " [  0.     3.    49.     0.21]\n",
      " [  0.     4.    49.     0.35]\n",
      " [  0.     5.    49.     0.15]\n",
      " [  0.     6.    49.     0.06]] -> [ 0.23]\n",
      "[[  0.     3.    49.     0.21]\n",
      " [  0.     4.    49.     0.35]\n",
      " [  0.     5.    49.     0.15]\n",
      " [  0.     6.    49.     0.06]\n",
      " [  0.     0.    50.     0.23]] -> [ 0.22]\n",
      "[[  0.     4.    49.     0.35]\n",
      " [  0.     5.    49.     0.15]\n",
      " [  0.     6.    49.     0.06]\n",
      " [  0.     0.    50.     0.23]\n",
      " [  0.     1.    50.     0.22]] -> [ 0.19]\n",
      "[[  0.     5.    49.     0.15]\n",
      " [  0.     6.    49.     0.06]\n",
      " [  0.     0.    50.     0.23]\n",
      " [  0.     1.    50.     0.22]\n",
      " [  0.     2.    50.     0.19]] -> [ 0.2]\n",
      "[[  0.     6.    49.     0.06]\n",
      " [  0.     0.    50.     0.23]\n",
      " [  0.     1.    50.     0.22]\n",
      " [  0.     2.    50.     0.19]\n",
      " [  0.     3.    50.     0.2 ]] -> [ 0.13]\n",
      "[[  0.     0.    50.     0.23]\n",
      " [  0.     1.    50.     0.22]\n",
      " [  0.     2.    50.     0.19]\n",
      " [  0.     3.    50.     0.2 ]\n",
      " [  0.     4.    50.     0.13]] -> [ 0.21]\n",
      "[[  0.     1.    50.     0.22]\n",
      " [  0.     2.    50.     0.19]\n",
      " [  0.     3.    50.     0.2 ]\n",
      " [  0.     4.    50.     0.13]\n",
      " [  0.     5.    50.     0.21]] -> [ 0.1]\n",
      "[[  0.     2.    50.     0.19]\n",
      " [  0.     3.    50.     0.2 ]\n",
      " [  0.     4.    50.     0.13]\n",
      " [  0.     5.    50.     0.21]\n",
      " [  0.     6.    50.     0.1 ]] -> [ 0.11]\n",
      "[[  0.     3.    50.     0.2 ]\n",
      " [  0.     4.    50.     0.13]\n",
      " [  0.     5.    50.     0.21]\n",
      " [  0.     6.    50.     0.1 ]\n",
      " [  0.     0.    51.     0.11]] -> [ 0.11]\n",
      "[[  0.     4.    50.     0.13]\n",
      " [  0.     5.    50.     0.21]\n",
      " [  0.     6.    50.     0.1 ]\n",
      " [  0.     0.    51.     0.11]\n",
      " [  0.     1.    51.     0.11]] -> [ 0.16]\n",
      "[[  0.     5.    50.     0.21]\n",
      " [  0.     6.    50.     0.1 ]\n",
      " [  0.     0.    51.     0.11]\n",
      " [  0.     1.    51.     0.11]\n",
      " [  0.     2.    51.     0.16]] -> [ 0.12]\n",
      "[[  0.     6.    50.     0.1 ]\n",
      " [  0.     0.    51.     0.11]\n",
      " [  0.     1.    51.     0.11]\n",
      " [  0.     2.    51.     0.16]\n",
      " [  0.     3.    51.     0.12]] -> [ 0.15]\n",
      "[[  0.     0.    51.     0.11]\n",
      " [  0.     1.    51.     0.11]\n",
      " [  0.     2.    51.     0.16]\n",
      " [  0.     3.    51.     0.12]\n",
      " [  0.     4.    51.     0.15]] -> [ 0.08]\n",
      "[[  0.     1.    51.     0.11]\n",
      " [  0.     2.    51.     0.16]\n",
      " [  0.     3.    51.     0.12]\n",
      " [  0.     4.    51.     0.15]\n",
      " [  0.     5.    51.     0.08]] -> [ 0.]\n",
      "[[  0.     2.    51.     0.16]\n",
      " [  0.     3.    51.     0.12]\n",
      " [  0.     4.    51.     0.15]\n",
      " [  0.     5.    51.     0.08]\n",
      " [  0.     6.    51.     0.  ]] -> [ 0.24]\n",
      "[[  0.     3.    51.     0.12]\n",
      " [  0.     4.    51.     0.15]\n",
      " [  0.     5.    51.     0.08]\n",
      " [  0.     6.    51.     0.  ]\n",
      " [  0.     0.    52.     0.24]] -> [ 0.19]\n",
      "[[  0.     4.    51.     0.15]\n",
      " [  0.     5.    51.     0.08]\n",
      " [  0.     6.    51.     0.  ]\n",
      " [  0.     0.    52.     0.24]\n",
      " [  0.     1.    52.     0.19]] -> [ 0.22]\n",
      "[[  0.     5.    51.     0.08]\n",
      " [  0.     6.    51.     0.  ]\n",
      " [  0.     0.    52.     0.24]\n",
      " [  0.     1.    52.     0.19]\n",
      " [  0.     2.    52.     0.22]] -> [ 0.13]\n",
      "[[  0.     6.    51.     0.  ]\n",
      " [  0.     0.    52.     0.24]\n",
      " [  0.     1.    52.     0.19]\n",
      " [  0.     2.    52.     0.22]\n",
      " [  0.     3.    52.     0.13]] -> [ 0.12]\n",
      "[[  0.     0.    52.     0.24]\n",
      " [  0.     1.    52.     0.19]\n",
      " [  0.     2.    52.     0.22]\n",
      " [  0.     3.    52.     0.13]\n",
      " [  0.     4.    52.     0.12]] -> [ 0.16]\n",
      "[[  0.     1.    52.     0.19]\n",
      " [  0.     2.    52.     0.22]\n",
      " [  0.     3.    52.     0.13]\n",
      " [  0.     4.    52.     0.12]\n",
      " [  0.     5.    52.     0.16]] -> [ 0.02]\n",
      "[[  0.00000000e+00   2.00000000e+00   5.20000000e+01   2.20000000e-01]\n",
      " [  0.00000000e+00   3.00000000e+00   5.20000000e+01   1.30000000e-01]\n",
      " [  0.00000000e+00   4.00000000e+00   5.20000000e+01   1.20000000e-01]\n",
      " [  0.00000000e+00   5.00000000e+00   5.20000000e+01   1.60000000e-01]\n",
      " [  0.00000000e+00   6.00000000e+00   5.20000000e+01   2.00000000e-02]] -> [ 0.16]\n",
      "[[  0.00000000e+00   3.00000000e+00   5.20000000e+01   1.30000000e-01]\n",
      " [  0.00000000e+00   4.00000000e+00   5.20000000e+01   1.20000000e-01]\n",
      " [  0.00000000e+00   5.00000000e+00   5.20000000e+01   1.60000000e-01]\n",
      " [  0.00000000e+00   6.00000000e+00   5.20000000e+01   2.00000000e-02]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   1.60000000e-01]] -> [ 0.2]\n",
      "[[  0.00000000e+00   4.00000000e+00   5.20000000e+01   1.20000000e-01]\n",
      " [  0.00000000e+00   5.00000000e+00   5.20000000e+01   1.60000000e-01]\n",
      " [  0.00000000e+00   6.00000000e+00   5.20000000e+01   2.00000000e-02]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   1.60000000e-01]\n",
      " [  0.00000000e+00   1.00000000e+00   1.00000000e+00   2.00000000e-01]] -> [ 0.12]\n",
      "[[  0.00000000e+00   5.00000000e+00   5.20000000e+01   1.60000000e-01]\n",
      " [  0.00000000e+00   6.00000000e+00   5.20000000e+01   2.00000000e-02]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   1.60000000e-01]\n",
      " [  0.00000000e+00   1.00000000e+00   1.00000000e+00   2.00000000e-01]\n",
      " [  0.00000000e+00   2.00000000e+00   1.00000000e+00   1.20000000e-01]] -> [ 0.11]\n",
      "[[  0.00000000e+00   6.00000000e+00   5.20000000e+01   2.00000000e-02]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   1.60000000e-01]\n",
      " [  0.00000000e+00   1.00000000e+00   1.00000000e+00   2.00000000e-01]\n",
      " [  0.00000000e+00   2.00000000e+00   1.00000000e+00   1.20000000e-01]\n",
      " [  0.00000000e+00   3.00000000e+00   1.00000000e+00   1.10000000e-01]] -> [ 0.22]\n",
      "[[ 0.    0.    1.    0.16]\n",
      " [ 0.    1.    1.    0.2 ]\n",
      " [ 0.    2.    1.    0.12]\n",
      " [ 0.    3.    1.    0.11]\n",
      " [ 0.    4.    1.    0.22]] -> [ 0.2]\n",
      "[[ 0.    1.    1.    0.2 ]\n",
      " [ 0.    2.    1.    0.12]\n",
      " [ 0.    3.    1.    0.11]\n",
      " [ 0.    4.    1.    0.22]\n",
      " [ 0.    5.    1.    0.2 ]] -> [ 0.16]\n",
      "[[ 0.    2.    1.    0.12]\n",
      " [ 0.    3.    1.    0.11]\n",
      " [ 0.    4.    1.    0.22]\n",
      " [ 0.    5.    1.    0.2 ]\n",
      " [ 0.    6.    1.    0.16]] -> [ 0.17]\n",
      "[[ 0.    3.    1.    0.11]\n",
      " [ 0.    4.    1.    0.22]\n",
      " [ 0.    5.    1.    0.2 ]\n",
      " [ 0.    6.    1.    0.16]\n",
      " [ 0.    0.    2.    0.17]] -> [ 0.97]\n",
      "[[ 0.    4.    1.    0.22]\n",
      " [ 0.    5.    1.    0.2 ]\n",
      " [ 0.    6.    1.    0.16]\n",
      " [ 0.    0.    2.    0.17]\n",
      " [ 0.    1.    2.    0.97]] -> [ 0.]\n",
      "[[ 0.    5.    1.    0.2 ]\n",
      " [ 0.    6.    1.    0.16]\n",
      " [ 0.    0.    2.    0.17]\n",
      " [ 0.    1.    2.    0.97]\n",
      " [ 0.    2.    2.    0.  ]] -> [ 0.23]\n",
      "[[ 0.    6.    1.    0.16]\n",
      " [ 0.    0.    2.    0.17]\n",
      " [ 0.    1.    2.    0.97]\n",
      " [ 0.    2.    2.    0.  ]\n",
      " [ 0.    3.    2.    0.23]] -> [ 1.]\n",
      "[[ 0.    0.    2.    0.17]\n",
      " [ 0.    1.    2.    0.97]\n",
      " [ 0.    2.    2.    0.  ]\n",
      " [ 0.    3.    2.    0.23]\n",
      " [ 0.    4.    2.    1.  ]] -> [ 0.18]\n",
      "[[ 0.    1.    2.    0.97]\n",
      " [ 0.    2.    2.    0.  ]\n",
      " [ 0.    3.    2.    0.23]\n",
      " [ 0.    4.    2.    1.  ]\n",
      " [ 0.    5.    2.    0.18]] -> [ 0.13]\n",
      "[[ 0.    2.    2.    0.  ]\n",
      " [ 0.    3.    2.    0.23]\n",
      " [ 0.    4.    2.    1.  ]\n",
      " [ 0.    5.    2.    0.18]\n",
      " [ 0.    6.    2.    0.13]] -> [ 0.21]\n",
      "[[ 0.    3.    2.    0.23]\n",
      " [ 0.    4.    2.    1.  ]\n",
      " [ 0.    5.    2.    0.18]\n",
      " [ 0.    6.    2.    0.13]\n",
      " [ 0.    0.    3.    0.21]] -> [ 0.24]\n",
      "[[ 0.    4.    2.    1.  ]\n",
      " [ 0.    5.    2.    0.18]\n",
      " [ 0.    6.    2.    0.13]\n",
      " [ 0.    0.    3.    0.21]\n",
      " [ 0.    1.    3.    0.24]] -> [ 0.16]\n",
      "[[ 0.    5.    2.    0.18]\n",
      " [ 0.    6.    2.    0.13]\n",
      " [ 0.    0.    3.    0.21]\n",
      " [ 0.    1.    3.    0.24]\n",
      " [ 0.    2.    3.    0.16]] -> [ 0.18]\n",
      "[[ 0.    6.    2.    0.13]\n",
      " [ 0.    0.    3.    0.21]\n",
      " [ 0.    1.    3.    0.24]\n",
      " [ 0.    2.    3.    0.16]\n",
      " [ 0.    3.    3.    0.18]] -> [ 0.22]\n",
      "[[ 0.    0.    3.    0.21]\n",
      " [ 0.    1.    3.    0.24]\n",
      " [ 0.    2.    3.    0.16]\n",
      " [ 0.    3.    3.    0.18]\n",
      " [ 0.    4.    3.    0.22]] -> [ 0.18]\n",
      "[[ 0.    1.    3.    0.24]\n",
      " [ 0.    2.    3.    0.16]\n",
      " [ 0.    3.    3.    0.18]\n",
      " [ 0.    4.    3.    0.22]\n",
      " [ 0.    5.    3.    0.18]] -> [ 0.11]\n",
      "[[ 0.    2.    3.    0.16]\n",
      " [ 0.    3.    3.    0.18]\n",
      " [ 0.    4.    3.    0.22]\n",
      " [ 0.    5.    3.    0.18]\n",
      " [ 0.    6.    3.    0.11]] -> [ 0.24]\n",
      "[[ 0.    3.    3.    0.18]\n",
      " [ 0.    4.    3.    0.22]\n",
      " [ 0.    5.    3.    0.18]\n",
      " [ 0.    6.    3.    0.11]\n",
      " [ 0.    0.    4.    0.24]] -> [ 0.22]\n",
      "[[ 0.    4.    3.    0.22]\n",
      " [ 0.    5.    3.    0.18]\n",
      " [ 0.    6.    3.    0.11]\n",
      " [ 0.    0.    4.    0.24]\n",
      " [ 0.    1.    4.    0.22]] -> [ 0.2]\n",
      "[[ 0.    5.    3.    0.18]\n",
      " [ 0.    6.    3.    0.11]\n",
      " [ 0.    0.    4.    0.24]\n",
      " [ 0.    1.    4.    0.22]\n",
      " [ 0.    2.    4.    0.2 ]] -> [ 0.22]\n",
      "[[ 0.    6.    3.    0.11]\n",
      " [ 0.    0.    4.    0.24]\n",
      " [ 0.    1.    4.    0.22]\n",
      " [ 0.    2.    4.    0.2 ]\n",
      " [ 0.    3.    4.    0.22]] -> [ 0.26]\n",
      "[[ 0.    0.    4.    0.24]\n",
      " [ 0.    1.    4.    0.22]\n",
      " [ 0.    2.    4.    0.2 ]\n",
      " [ 0.    3.    4.    0.22]\n",
      " [ 0.    4.    4.    0.26]] -> [ 0.]\n",
      "[[ 0.    1.    4.    0.22]\n",
      " [ 0.    2.    4.    0.2 ]\n",
      " [ 0.    3.    4.    0.22]\n",
      " [ 0.    4.    4.    0.26]\n",
      " [ 0.    5.    4.    0.  ]] -> [ 0.]\n",
      "[[ 0.    2.    4.    0.2 ]\n",
      " [ 0.    3.    4.    0.22]\n",
      " [ 0.    4.    4.    0.26]\n",
      " [ 0.    5.    4.    0.  ]\n",
      " [ 0.    6.    4.    0.  ]] -> [ 0.05]\n",
      "[[ 0.    3.    4.    0.22]\n",
      " [ 0.    4.    4.    0.26]\n",
      " [ 0.    5.    4.    0.  ]\n",
      " [ 0.    6.    4.    0.  ]\n",
      " [ 0.    0.    5.    0.05]] -> [ 0.31]\n"
     ]
    }
   ],
   "source": [
    "x=xy\n",
    "y=xy[:,[-1]]\n",
    "\n",
    "#build a series dataset(seq_length에 해당하는 전날 X와 다음 forecastDays에 해당하는 Y)\n",
    "dataX=[]\n",
    "dataY=[]\n",
    "for i in range(0, len(y)-seq_length):\n",
    "    _x=x[i:i+seq_length]\n",
    "    _y=y[i+seq_length]\n",
    "    #     _y=Y[i+seq_length:i+seq_length+forecastDays]\n",
    "    print(_x,\"->\",_y)\n",
    "    dataX.append(_x)\n",
    "    dataY.append(_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = int(len(dataY) * 0.7)\n",
    "test_size = len(dataY) - train_size\n",
    "trainX, testX = np.array(dataX[0:train_size]), np.array(dataX[train_size:])\n",
    "trainY, testY = np.array(dataY[0:train_size]), np.array(dataY[train_size:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 input place holders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X의 경우 input type과 [batch size, sequence length, input data dimension(feature+1))]\n",
    "\n",
    "Y의 경우 input type과 [batch size, 원하는 output 의 개수(forecastDays)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=tf.placeholder(tf.float32, [None, seq_length, data_dim])\n",
    "Y=tf.placeholder(tf.float32, [None, forecastDays])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 build LSTM network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lstm network의 \n",
    "\n",
    "    기본단위 cell, \n",
    "    \n",
    "    사용 driver, \n",
    "    \n",
    "    예측 y 산출방식, \n",
    "    \n",
    "    loss 함수, \n",
    "    \n",
    "    사용 optimizer 정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### lstm의 한 기본단위인 cell을 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cell의 결과값을 fully connected layer로 한 번 더 가공할 것이기 때문에 cell의 output dimension인 num_units=hidden_dim로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_dim, state_is_tuple=True, activation=tf.tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic rnn이라는 driver를 가동"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.dynamic_rnn의 input은 cell, input, input type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.dynamic_rnn의 output은 outputs와 states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs, _states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 마지막 cell의 output을 이용하여 Y_pred 도출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputs[:, -1]: cell의 outputs 중 마지막 하나만 이용(we use the last cell's output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_dim: fully connected의 최종출력개수는 output_dim(=forecastDays) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "activation_fn= None: 분류 문제가 아니라 회귀 문제이므로 activation_fn은 none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = tf.contrib.layers.fully_connected(outputs[:, -1], output_dim, activation_fn= None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.square(Y_pred - Y))  # sum of the squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimizer정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss를 줄이는 방향으로 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model 평가 with RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "denormalizedTestY=originalSales[train_size+seq_length:]\n",
    "denormalizedTestY_feed=np.array([[i] for i in denormalizedTestY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = tf.placeholder(tf.float32, [None, 1])\n",
    "predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rootMeanSquaredError(a,b):\n",
    "    sum=0\n",
    "    for i in range(len(a)):\n",
    "        sum=sum+(a[i]-b[i])**2\n",
    "    return np.sqrt( sum/len(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 0] loss: 61.159820556640625\n",
      "[step: 1] loss: 16.39006805419922\n",
      "[step: 2] loss: 13.055374145507812\n",
      "[step: 3] loss: 17.95273208618164\n",
      "[step: 4] loss: 16.769330978393555\n",
      "[step: 5] loss: 13.101293563842773\n",
      "[step: 6] loss: 9.802703857421875\n",
      "[step: 7] loss: 7.84617280960083\n",
      "[step: 8] loss: 7.198201656341553\n",
      "[step: 9] loss: 7.4416093826293945\n",
      "[step: 10] loss: 8.067333221435547\n",
      "[step: 11] loss: 8.64244270324707\n",
      "[step: 12] loss: 8.910738945007324\n",
      "[step: 13] loss: 8.808085441589355\n",
      "[step: 14] loss: 8.409947395324707\n",
      "[step: 15] loss: 7.856630802154541\n",
      "[step: 16] loss: 7.2908935546875\n",
      "[step: 17] loss: 6.820185661315918\n",
      "[step: 18] loss: 6.5014824867248535\n",
      "[step: 19] loss: 6.342205047607422\n",
      "[step: 20] loss: 6.311091423034668\n",
      "[step: 21] loss: 6.354420185089111\n",
      "[step: 22] loss: 6.4136271476745605\n",
      "[step: 23] loss: 6.4406538009643555\n",
      "[step: 24] loss: 6.408166885375977\n",
      "[step: 25] loss: 6.313457489013672\n",
      "[step: 26] loss: 6.175878047943115\n",
      "[step: 27] loss: 6.028083324432373\n",
      "[step: 28] loss: 5.903416633605957\n",
      "[step: 29] loss: 5.824082851409912\n",
      "[step: 30] loss: 5.794501781463623\n",
      "[step: 31] loss: 5.801697731018066\n",
      "[step: 32] loss: 5.821744918823242\n",
      "[step: 33] loss: 5.829476833343506\n",
      "[step: 34] loss: 5.807833194732666\n",
      "[step: 35] loss: 5.753568172454834\n",
      "[step: 36] loss: 5.6775054931640625\n",
      "[step: 37] loss: 5.599646091461182\n",
      "[step: 38] loss: 5.541024208068848\n",
      "[step: 39] loss: 5.514577388763428\n",
      "[step: 40] loss: 5.517705917358398\n",
      "[step: 41] loss: 5.531798362731934\n",
      "[step: 42] loss: 5.534252643585205\n",
      "[step: 43] loss: 5.5153021812438965\n",
      "[step: 44] loss: 5.482224941253662\n",
      "[step: 45] loss: 5.449501991271973\n",
      "[step: 46] loss: 5.427186012268066\n",
      "[step: 47] loss: 5.415872573852539\n",
      "[step: 48] loss: 5.408817768096924\n",
      "[step: 49] loss: 5.397494316101074\n",
      "[step: 50] loss: 5.3768486976623535\n",
      "[step: 51] loss: 5.348074436187744\n",
      "[step: 52] loss: 5.318083763122559\n",
      "[step: 53] loss: 5.295531272888184\n",
      "[step: 54] loss: 5.284536361694336\n",
      "[step: 55] loss: 5.280114650726318\n",
      "[step: 56] loss: 5.271467208862305\n",
      "[step: 57] loss: 5.252566814422607\n",
      "[step: 58] loss: 5.227852821350098\n",
      "[step: 59] loss: 5.206116199493408\n",
      "[step: 60] loss: 5.191412925720215\n",
      "[step: 61] loss: 5.180825233459473\n",
      "[step: 62] loss: 5.168903827667236\n",
      "[step: 63] loss: 5.152877330780029\n",
      "[step: 64] loss: 5.134452819824219\n",
      "[step: 65] loss: 5.117722988128662\n",
      "[step: 66] loss: 5.105219841003418\n",
      "[step: 67] loss: 5.09533166885376\n",
      "[step: 68] loss: 5.0838518142700195\n",
      "[step: 69] loss: 5.068639755249023\n",
      "[step: 70] loss: 5.05186128616333\n",
      "[step: 71] loss: 5.037041664123535\n",
      "[step: 72] loss: 5.025036334991455\n",
      "[step: 73] loss: 5.013699054718018\n",
      "[step: 74] loss: 5.000824928283691\n",
      "[step: 75] loss: 4.986615180969238\n",
      "[step: 76] loss: 4.97314453125\n",
      "[step: 77] loss: 4.96159553527832\n",
      "[step: 78] loss: 4.950684070587158\n",
      "[step: 79] loss: 4.9384684562683105\n",
      "[step: 80] loss: 4.925069332122803\n",
      "[step: 81] loss: 4.912274360656738\n",
      "[step: 82] loss: 4.900949001312256\n",
      "[step: 83] loss: 4.890161514282227\n",
      "[step: 84] loss: 4.878762722015381\n",
      "[step: 85] loss: 4.866890907287598\n",
      "[step: 86] loss: 4.855527400970459\n",
      "[step: 87] loss: 4.845005512237549\n",
      "[step: 88] loss: 4.834568023681641\n",
      "[step: 89] loss: 4.823564529418945\n",
      "[step: 90] loss: 4.812373161315918\n",
      "[step: 91] loss: 4.801735877990723\n",
      "[step: 92] loss: 4.79164981842041\n",
      "[step: 93] loss: 4.78151273727417\n",
      "[step: 94] loss: 4.77108097076416\n",
      "[step: 95] loss: 4.760741710662842\n",
      "[step: 96] loss: 4.750807285308838\n",
      "[step: 97] loss: 4.74102783203125\n",
      "[step: 98] loss: 4.731057643890381\n",
      "[step: 99] loss: 4.721044063568115\n",
      "[step: 100] loss: 4.711332321166992\n",
      "[step: 101] loss: 4.701904296875\n",
      "[step: 102] loss: 4.692464351654053\n",
      "[step: 103] loss: 4.682944297790527\n",
      "[step: 104] loss: 4.673551559448242\n",
      "[step: 105] loss: 4.664389133453369\n",
      "[step: 106] loss: 4.6553053855896\n",
      "[step: 107] loss: 4.646206378936768\n",
      "[step: 108] loss: 4.637221336364746\n",
      "[step: 109] loss: 4.628459930419922\n",
      "[step: 110] loss: 4.619822978973389\n",
      "[step: 111] loss: 4.6111931800842285\n",
      "[step: 112] loss: 4.602625846862793\n",
      "[step: 113] loss: 4.5942230224609375\n",
      "[step: 114] loss: 4.585945129394531\n",
      "[step: 115] loss: 4.5777153968811035\n",
      "[step: 116] loss: 4.569561958312988\n",
      "[step: 117] loss: 4.561544895172119\n",
      "[step: 118] loss: 4.553630352020264\n",
      "[step: 119] loss: 4.545757293701172\n",
      "[step: 120] loss: 4.537942886352539\n",
      "[step: 121] loss: 4.530244827270508\n",
      "[step: 122] loss: 4.522644996643066\n",
      "[step: 123] loss: 4.5150980949401855\n",
      "[step: 124] loss: 4.507618427276611\n",
      "[step: 125] loss: 4.500229835510254\n",
      "[step: 126] loss: 4.492908000946045\n",
      "[step: 127] loss: 4.485630512237549\n",
      "[step: 128] loss: 4.478415489196777\n",
      "[step: 129] loss: 4.471278667449951\n",
      "[step: 130] loss: 4.464196681976318\n",
      "[step: 131] loss: 4.457152843475342\n",
      "[step: 132] loss: 4.450168609619141\n",
      "[step: 133] loss: 4.443245887756348\n",
      "[step: 134] loss: 4.4363694190979\n",
      "[step: 135] loss: 4.429539203643799\n",
      "[step: 136] loss: 4.4227681159973145\n",
      "[step: 137] loss: 4.416053295135498\n",
      "[step: 138] loss: 4.409386157989502\n",
      "[step: 139] loss: 4.402782440185547\n",
      "[step: 140] loss: 4.396246910095215\n",
      "[step: 141] loss: 4.389774799346924\n",
      "[step: 142] loss: 4.383366107940674\n",
      "[step: 143] loss: 4.377030849456787\n",
      "[step: 144] loss: 4.370771884918213\n",
      "[step: 145] loss: 4.364583492279053\n",
      "[step: 146] loss: 4.358469486236572\n",
      "[step: 147] loss: 4.35243034362793\n",
      "[step: 148] loss: 4.34645414352417\n",
      "[step: 149] loss: 4.340542793273926\n",
      "[step: 150] loss: 4.3346967697143555\n",
      "[step: 151] loss: 4.3289079666137695\n",
      "[step: 152] loss: 4.32316780090332\n",
      "[step: 153] loss: 4.317478179931641\n",
      "[step: 154] loss: 4.311830997467041\n",
      "[step: 155] loss: 4.306219100952148\n",
      "[step: 156] loss: 4.300644874572754\n",
      "[step: 157] loss: 4.295103073120117\n",
      "[step: 158] loss: 4.289590358734131\n",
      "[step: 159] loss: 4.28410530090332\n",
      "[step: 160] loss: 4.278647422790527\n",
      "[step: 161] loss: 4.273212432861328\n",
      "[step: 162] loss: 4.267800807952881\n",
      "[step: 163] loss: 4.262412071228027\n",
      "[step: 164] loss: 4.257044315338135\n",
      "[step: 165] loss: 4.251698017120361\n",
      "[step: 166] loss: 4.246371269226074\n",
      "[step: 167] loss: 4.241062641143799\n",
      "[step: 168] loss: 4.235774993896484\n",
      "[step: 169] loss: 4.23050594329834\n",
      "[step: 170] loss: 4.225256443023682\n",
      "[step: 171] loss: 4.220027923583984\n",
      "[step: 172] loss: 4.214818954467773\n",
      "[step: 173] loss: 4.20963191986084\n",
      "[step: 174] loss: 4.204464912414551\n",
      "[step: 175] loss: 4.199319839477539\n",
      "[step: 176] loss: 4.194197654724121\n",
      "[step: 177] loss: 4.189096927642822\n",
      "[step: 178] loss: 4.184016227722168\n",
      "[step: 179] loss: 4.178958415985107\n",
      "[step: 180] loss: 4.173920154571533\n",
      "[step: 181] loss: 4.168901443481445\n",
      "[step: 182] loss: 4.163899898529053\n",
      "[step: 183] loss: 4.158914089202881\n",
      "[step: 184] loss: 4.153941631317139\n",
      "[step: 185] loss: 4.148979187011719\n",
      "[step: 186] loss: 4.1440229415893555\n",
      "[step: 187] loss: 4.139070510864258\n",
      "[step: 188] loss: 4.1341166496276855\n",
      "[step: 189] loss: 4.129156112670898\n",
      "[step: 190] loss: 4.124185085296631\n",
      "[step: 191] loss: 4.119196891784668\n",
      "[step: 192] loss: 4.1141862869262695\n",
      "[step: 193] loss: 4.109147548675537\n",
      "[step: 194] loss: 4.104074001312256\n",
      "[step: 195] loss: 4.098959445953369\n",
      "[step: 196] loss: 4.093796253204346\n",
      "[step: 197] loss: 4.08858060836792\n",
      "[step: 198] loss: 4.083305835723877\n",
      "[step: 199] loss: 4.077966213226318\n",
      "[step: 200] loss: 4.072559356689453\n",
      "[step: 201] loss: 4.067081928253174\n",
      "[step: 202] loss: 4.061532497406006\n",
      "[step: 203] loss: 4.055912017822266\n",
      "[step: 204] loss: 4.050222396850586\n",
      "[step: 205] loss: 4.044469833374023\n",
      "[step: 206] loss: 4.038660049438477\n",
      "[step: 207] loss: 4.032800197601318\n",
      "[step: 208] loss: 4.026902198791504\n",
      "[step: 209] loss: 4.020974636077881\n",
      "[step: 210] loss: 4.0150275230407715\n",
      "[step: 211] loss: 4.009072303771973\n",
      "[step: 212] loss: 4.00311803817749\n",
      "[step: 213] loss: 3.997175931930542\n",
      "[step: 214] loss: 3.9912521839141846\n",
      "[step: 215] loss: 3.9853568077087402\n",
      "[step: 216] loss: 3.979498863220215\n",
      "[step: 217] loss: 3.9736881256103516\n",
      "[step: 218] loss: 3.9679300785064697\n",
      "[step: 219] loss: 3.962233066558838\n",
      "[step: 220] loss: 3.956601858139038\n",
      "[step: 221] loss: 3.9510409832000732\n",
      "[step: 222] loss: 3.945551633834839\n",
      "[step: 223] loss: 3.9401333332061768\n",
      "[step: 224] loss: 3.9347832202911377\n",
      "[step: 225] loss: 3.929499626159668\n",
      "[step: 226] loss: 3.9242758750915527\n",
      "[step: 227] loss: 3.919105291366577\n",
      "[step: 228] loss: 3.9139840602874756\n",
      "[step: 229] loss: 3.908905267715454\n",
      "[step: 230] loss: 3.903866767883301\n",
      "[step: 231] loss: 3.8988635540008545\n",
      "[step: 232] loss: 3.893894672393799\n",
      "[step: 233] loss: 3.888958692550659\n",
      "[step: 234] loss: 3.884056568145752\n",
      "[step: 235] loss: 3.8791885375976562\n",
      "[step: 236] loss: 3.8743550777435303\n",
      "[step: 237] loss: 3.869558095932007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 238] loss: 3.864800214767456\n",
      "[step: 239] loss: 3.8600833415985107\n",
      "[step: 240] loss: 3.855410575866699\n",
      "[step: 241] loss: 3.8507838249206543\n",
      "[step: 242] loss: 3.846205711364746\n",
      "[step: 243] loss: 3.841677188873291\n",
      "[step: 244] loss: 3.837198495864868\n",
      "[step: 245] loss: 3.8327693939208984\n",
      "[step: 246] loss: 3.8283896446228027\n",
      "[step: 247] loss: 3.8240559101104736\n",
      "[step: 248] loss: 3.8197686672210693\n",
      "[step: 249] loss: 3.8155219554901123\n",
      "[step: 250] loss: 3.811314105987549\n",
      "[step: 251] loss: 3.807140588760376\n",
      "[step: 252] loss: 3.802999973297119\n",
      "[step: 253] loss: 3.7988860607147217\n",
      "[step: 254] loss: 3.7947959899902344\n",
      "[step: 255] loss: 3.7907261848449707\n",
      "[step: 256] loss: 3.7866709232330322\n",
      "[step: 257] loss: 3.7826266288757324\n",
      "[step: 258] loss: 3.7785887718200684\n",
      "[step: 259] loss: 3.7745532989501953\n",
      "[step: 260] loss: 3.770515203475952\n",
      "[step: 261] loss: 3.7664716243743896\n",
      "[step: 262] loss: 3.7624189853668213\n",
      "[step: 263] loss: 3.758356809616089\n",
      "[step: 264] loss: 3.7542834281921387\n",
      "[step: 265] loss: 3.7502024173736572\n",
      "[step: 266] loss: 3.7461137771606445\n",
      "[step: 267] loss: 3.7420272827148438\n",
      "[step: 268] loss: 3.7379469871520996\n",
      "[step: 269] loss: 3.733882188796997\n",
      "[step: 270] loss: 3.7298386096954346\n",
      "[step: 271] loss: 3.7258219718933105\n",
      "[step: 272] loss: 3.7218289375305176\n",
      "[step: 273] loss: 3.7178547382354736\n",
      "[step: 274] loss: 3.7138874530792236\n",
      "[step: 275] loss: 3.7099149227142334\n",
      "[step: 276] loss: 3.7059273719787598\n",
      "[step: 277] loss: 3.701916217803955\n",
      "[step: 278] loss: 3.6978843212127686\n",
      "[step: 279] loss: 3.6938350200653076\n",
      "[step: 280] loss: 3.689775228500366\n",
      "[step: 281] loss: 3.6857101917266846\n",
      "[step: 282] loss: 3.681644916534424\n",
      "[step: 283] loss: 3.677578926086426\n",
      "[step: 284] loss: 3.6735126972198486\n",
      "[step: 285] loss: 3.669443130493164\n",
      "[step: 286] loss: 3.6653716564178467\n",
      "[step: 287] loss: 3.661294460296631\n",
      "[step: 288] loss: 3.6572115421295166\n",
      "[step: 289] loss: 3.6531200408935547\n",
      "[step: 290] loss: 3.6490180492401123\n",
      "[step: 291] loss: 3.644902467727661\n",
      "[step: 292] loss: 3.6407723426818848\n",
      "[step: 293] loss: 3.636626720428467\n",
      "[step: 294] loss: 3.6324708461761475\n",
      "[step: 295] loss: 3.6283063888549805\n",
      "[step: 296] loss: 3.6241352558135986\n",
      "[step: 297] loss: 3.6199593544006348\n",
      "[step: 298] loss: 3.6157777309417725\n",
      "[step: 299] loss: 3.611589193344116\n",
      "[step: 300] loss: 3.6073901653289795\n",
      "[step: 301] loss: 3.6031789779663086\n",
      "[step: 302] loss: 3.598954677581787\n",
      "[step: 303] loss: 3.594717264175415\n",
      "[step: 304] loss: 3.5904674530029297\n",
      "[step: 305] loss: 3.5862069129943848\n",
      "[step: 306] loss: 3.5819380283355713\n",
      "[step: 307] loss: 3.5776591300964355\n",
      "[step: 308] loss: 3.5733730792999268\n",
      "[step: 309] loss: 3.569080114364624\n",
      "[step: 310] loss: 3.564779281616211\n",
      "[step: 311] loss: 3.560471773147583\n",
      "[step: 312] loss: 3.556157112121582\n",
      "[step: 313] loss: 3.5518364906311035\n",
      "[step: 314] loss: 3.5475099086761475\n",
      "[step: 315] loss: 3.5431790351867676\n",
      "[step: 316] loss: 3.538844347000122\n",
      "[step: 317] loss: 3.5345065593719482\n",
      "[step: 318] loss: 3.5301673412323\n",
      "[step: 319] loss: 3.525827407836914\n",
      "[step: 320] loss: 3.521486282348633\n",
      "[step: 321] loss: 3.5171444416046143\n",
      "[step: 322] loss: 3.512802839279175\n",
      "[step: 323] loss: 3.5084617137908936\n",
      "[step: 324] loss: 3.504122257232666\n",
      "[step: 325] loss: 3.4997849464416504\n",
      "[step: 326] loss: 3.4954493045806885\n",
      "[step: 327] loss: 3.4911181926727295\n",
      "[step: 328] loss: 3.486790180206299\n",
      "[step: 329] loss: 3.48246693611145\n",
      "[step: 330] loss: 3.4781477451324463\n",
      "[step: 331] loss: 3.4738337993621826\n",
      "[step: 332] loss: 3.469525098800659\n",
      "[step: 333] loss: 3.4652225971221924\n",
      "[step: 334] loss: 3.4609262943267822\n",
      "[step: 335] loss: 3.4566352367401123\n",
      "[step: 336] loss: 3.4523520469665527\n",
      "[step: 337] loss: 3.4480738639831543\n",
      "[step: 338] loss: 3.4438040256500244\n",
      "[step: 339] loss: 3.4395391941070557\n",
      "[step: 340] loss: 3.4352810382843018\n",
      "[step: 341] loss: 3.4310288429260254\n",
      "[step: 342] loss: 3.4267826080322266\n",
      "[step: 343] loss: 3.4225428104400635\n",
      "[step: 344] loss: 3.4183075428009033\n",
      "[step: 345] loss: 3.4140784740448\n",
      "[step: 346] loss: 3.4098548889160156\n",
      "[step: 347] loss: 3.4056344032287598\n",
      "[step: 348] loss: 3.401419162750244\n",
      "[step: 349] loss: 3.3972082138061523\n",
      "[step: 350] loss: 3.393000364303589\n",
      "[step: 351] loss: 3.388796329498291\n",
      "[step: 352] loss: 3.3845951557159424\n",
      "[step: 353] loss: 3.3803985118865967\n",
      "[step: 354] loss: 3.3762059211730957\n",
      "[step: 355] loss: 3.3720157146453857\n",
      "[step: 356] loss: 3.367830276489258\n",
      "[step: 357] loss: 3.363649368286133\n",
      "[step: 358] loss: 3.3594720363616943\n",
      "[step: 359] loss: 3.3553009033203125\n",
      "[step: 360] loss: 3.351135730743408\n",
      "[step: 361] loss: 3.346977472305298\n",
      "[step: 362] loss: 3.342827320098877\n",
      "[step: 363] loss: 3.3386855125427246\n",
      "[step: 364] loss: 3.3345530033111572\n",
      "[step: 365] loss: 3.3304314613342285\n",
      "[step: 366] loss: 3.3263213634490967\n",
      "[step: 367] loss: 3.3222250938415527\n",
      "[step: 368] loss: 3.318141460418701\n",
      "[step: 369] loss: 3.3140788078308105\n",
      "[step: 370] loss: 3.310049295425415\n",
      "[step: 371] loss: 3.306105852127075\n",
      "[step: 372] loss: 3.302464723587036\n",
      "[step: 373] loss: 3.299859046936035\n",
      "[step: 374] loss: 3.3003997802734375\n",
      "[step: 375] loss: 3.305020332336426\n",
      "[step: 376] loss: 3.3033664226531982\n",
      "[step: 377] loss: 3.287282705307007\n",
      "[step: 378] loss: 3.279853343963623\n",
      "[step: 379] loss: 3.285166025161743\n",
      "[step: 380] loss: 3.2786426544189453\n",
      "[step: 381] loss: 3.2676656246185303\n",
      "[step: 382] loss: 3.26956844329834\n",
      "[step: 383] loss: 3.2667784690856934\n",
      "[step: 384] loss: 3.2569801807403564\n",
      "[step: 385] loss: 3.256537437438965\n",
      "[step: 386] loss: 3.2545952796936035\n",
      "[step: 387] loss: 3.2464354038238525\n",
      "[step: 388] loss: 3.2446937561035156\n",
      "[step: 389] loss: 3.2428700923919678\n",
      "[step: 390] loss: 3.2359538078308105\n",
      "[step: 391] loss: 3.233487606048584\n",
      "[step: 392] loss: 3.2315309047698975\n",
      "[step: 393] loss: 3.225602388381958\n",
      "[step: 394] loss: 3.2226719856262207\n",
      "[step: 395] loss: 3.220524787902832\n",
      "[step: 396] loss: 3.215414524078369\n",
      "[step: 397] loss: 3.2120909690856934\n",
      "[step: 398] loss: 3.20981502532959\n",
      "[step: 399] loss: 3.205336093902588\n",
      "[step: 400] loss: 3.2017199993133545\n",
      "[step: 401] loss: 3.199320077896118\n",
      "[step: 402] loss: 3.1953208446502686\n",
      "[step: 403] loss: 3.191544771194458\n",
      "[step: 404] loss: 3.188958168029785\n",
      "[step: 405] loss: 3.1853606700897217\n",
      "[step: 406] loss: 3.181523561477661\n",
      "[step: 407] loss: 3.178678512573242\n",
      "[step: 408] loss: 3.175402879714966\n",
      "[step: 409] loss: 3.171602487564087\n",
      "[step: 410] loss: 3.1684703826904297\n",
      "[step: 411] loss: 3.1653897762298584\n",
      "[step: 412] loss: 3.1617274284362793\n",
      "[step: 413] loss: 3.1583340167999268\n",
      "[step: 414] loss: 3.1552698612213135\n",
      "[step: 415] loss: 3.151811361312866\n",
      "[step: 416] loss: 3.1482632160186768\n",
      "[step: 417] loss: 3.1450483798980713\n",
      "[step: 418] loss: 3.141756057739258\n",
      "[step: 419] loss: 3.1382217407226562\n",
      "[step: 420] loss: 3.134796619415283\n",
      "[step: 421] loss: 3.131516695022583\n",
      "[step: 422] loss: 3.128120183944702\n",
      "[step: 423] loss: 3.124610185623169\n",
      "[step: 424] loss: 3.1212046146392822\n",
      "[step: 425] loss: 3.1178879737854004\n",
      "[step: 426] loss: 3.114485740661621\n",
      "[step: 427] loss: 3.111021041870117\n",
      "[step: 428] loss: 3.107635974884033\n",
      "[step: 429] loss: 3.1043264865875244\n",
      "[step: 430] loss: 3.100978374481201\n",
      "[step: 431] loss: 3.0975775718688965\n",
      "[step: 432] loss: 3.0942180156707764\n",
      "[step: 433] loss: 3.0909271240234375\n",
      "[step: 434] loss: 3.0876498222351074\n",
      "[step: 435] loss: 3.084345579147339\n",
      "[step: 436] loss: 3.08103084564209\n",
      "[step: 437] loss: 3.077749729156494\n",
      "[step: 438] loss: 3.0745110511779785\n",
      "[step: 439] loss: 3.0712921619415283\n",
      "[step: 440] loss: 3.0680699348449707\n",
      "[step: 441] loss: 3.064838409423828\n",
      "[step: 442] loss: 3.061612129211426\n",
      "[step: 443] loss: 3.058401107788086\n",
      "[step: 444] loss: 3.0552103519439697\n",
      "[step: 445] loss: 3.05203914642334\n",
      "[step: 446] loss: 3.048884153366089\n",
      "[step: 447] loss: 3.045743227005005\n",
      "[step: 448] loss: 3.042614221572876\n",
      "[step: 449] loss: 3.039499521255493\n",
      "[step: 450] loss: 3.0363986492156982\n",
      "[step: 451] loss: 3.0333194732666016\n",
      "[step: 452] loss: 3.0302610397338867\n",
      "[step: 453] loss: 3.027235269546509\n",
      "[step: 454] loss: 3.0242371559143066\n",
      "[step: 455] loss: 3.0212817192077637\n",
      "[step: 456] loss: 3.018333673477173\n",
      "[step: 457] loss: 3.0153956413269043\n",
      "[step: 458] loss: 3.012404680252075\n",
      "[step: 459] loss: 3.0093865394592285\n",
      "[step: 460] loss: 3.006319761276245\n",
      "[step: 461] loss: 3.0032289028167725\n",
      "[step: 462] loss: 3.0001184940338135\n",
      "[step: 463] loss: 2.997032403945923\n",
      "[step: 464] loss: 2.993988513946533\n",
      "[step: 465] loss: 2.990988254547119\n",
      "[step: 466] loss: 2.9880099296569824\n",
      "[step: 467] loss: 2.9850516319274902\n",
      "[step: 468] loss: 2.982114791870117\n",
      "[step: 469] loss: 2.9791982173919678\n",
      "[step: 470] loss: 2.976297378540039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 471] loss: 2.9734137058258057\n",
      "[step: 472] loss: 2.970568895339966\n",
      "[step: 473] loss: 2.9677891731262207\n",
      "[step: 474] loss: 2.9651412963867188\n",
      "[step: 475] loss: 2.9626970291137695\n",
      "[step: 476] loss: 2.96063232421875\n",
      "[step: 477] loss: 2.9589943885803223\n",
      "[step: 478] loss: 2.9578988552093506\n",
      "[step: 479] loss: 2.956650972366333\n",
      "[step: 480] loss: 2.9547312259674072\n",
      "[step: 481] loss: 2.9505624771118164\n",
      "[step: 482] loss: 2.9447145462036133\n",
      "[step: 483] loss: 2.939028739929199\n",
      "[step: 484] loss: 2.9355528354644775\n",
      "[step: 485] loss: 2.934044122695923\n",
      "[step: 486] loss: 2.9328458309173584\n",
      "[step: 487] loss: 2.930426597595215\n",
      "[step: 488] loss: 2.926146984100342\n",
      "[step: 489] loss: 2.9215168952941895\n",
      "[step: 490] loss: 2.9180068969726562\n",
      "[step: 491] loss: 2.9157559871673584\n",
      "[step: 492] loss: 2.913832664489746\n",
      "[step: 493] loss: 2.9111294746398926\n",
      "[step: 494] loss: 2.907439708709717\n",
      "[step: 495] loss: 2.903473138809204\n",
      "[step: 496] loss: 2.900141716003418\n",
      "[step: 497] loss: 2.897507667541504\n",
      "[step: 498] loss: 2.8950324058532715\n",
      "[step: 499] loss: 2.89217209815979\n",
      "[step: 500] loss: 2.888716697692871\n",
      "[step: 501] loss: 2.8850901126861572\n",
      "[step: 502] loss: 2.8817408084869385\n",
      "[step: 503] loss: 2.87876558303833\n",
      "[step: 504] loss: 2.8759377002716064\n",
      "[step: 505] loss: 2.872955799102783\n",
      "[step: 506] loss: 2.8696837425231934\n",
      "[step: 507] loss: 2.866199493408203\n",
      "[step: 508] loss: 2.86275577545166\n",
      "[step: 509] loss: 2.8594796657562256\n",
      "[step: 510] loss: 2.8563404083251953\n",
      "[step: 511] loss: 2.8532276153564453\n",
      "[step: 512] loss: 2.850013256072998\n",
      "[step: 513] loss: 2.8466567993164062\n",
      "[step: 514] loss: 2.843196392059326\n",
      "[step: 515] loss: 2.839735507965088\n",
      "[step: 516] loss: 2.8363239765167236\n",
      "[step: 517] loss: 2.8329713344573975\n",
      "[step: 518] loss: 2.829652786254883\n",
      "[step: 519] loss: 2.8263185024261475\n",
      "[step: 520] loss: 2.82293438911438\n",
      "[step: 521] loss: 2.8194878101348877\n",
      "[step: 522] loss: 2.816000461578369\n",
      "[step: 523] loss: 2.812488555908203\n",
      "[step: 524] loss: 2.808973550796509\n",
      "[step: 525] loss: 2.805467367172241\n",
      "[step: 526] loss: 2.801976203918457\n",
      "[step: 527] loss: 2.798491954803467\n",
      "[step: 528] loss: 2.7950074672698975\n",
      "[step: 529] loss: 2.791517496109009\n",
      "[step: 530] loss: 2.788017749786377\n",
      "[step: 531] loss: 2.784510612487793\n",
      "[step: 532] loss: 2.7809906005859375\n",
      "[step: 533] loss: 2.77746844291687\n",
      "[step: 534] loss: 2.773940086364746\n",
      "[step: 535] loss: 2.7704200744628906\n",
      "[step: 536] loss: 2.7669055461883545\n",
      "[step: 537] loss: 2.763417959213257\n",
      "[step: 538] loss: 2.7599592208862305\n",
      "[step: 539] loss: 2.7565736770629883\n",
      "[step: 540] loss: 2.7532801628112793\n",
      "[step: 541] loss: 2.7501888275146484\n",
      "[step: 542] loss: 2.74735426902771\n",
      "[step: 543] loss: 2.745049476623535\n",
      "[step: 544] loss: 2.7432541847229004\n",
      "[step: 545] loss: 2.742368698120117\n",
      "[step: 546] loss: 2.7412235736846924\n",
      "[step: 547] loss: 2.7395031452178955\n",
      "[step: 548] loss: 2.7342889308929443\n",
      "[step: 549] loss: 2.726916551589966\n",
      "[step: 550] loss: 2.7192037105560303\n",
      "[step: 551] loss: 2.7143654823303223\n",
      "[step: 552] loss: 2.712700128555298\n",
      "[step: 553] loss: 2.7120513916015625\n",
      "[step: 554] loss: 2.7101223468780518\n",
      "[step: 555] loss: 2.7054684162139893\n",
      "[step: 556] loss: 2.699653148651123\n",
      "[step: 557] loss: 2.694671869277954\n",
      "[step: 558] loss: 2.6916751861572266\n",
      "[step: 559] loss: 2.689922571182251\n",
      "[step: 560] loss: 2.6878459453582764\n",
      "[step: 561] loss: 2.6846251487731934\n",
      "[step: 562] loss: 2.680229663848877\n",
      "[step: 563] loss: 2.675814151763916\n",
      "[step: 564] loss: 2.6721105575561523\n",
      "[step: 565] loss: 2.669313430786133\n",
      "[step: 566] loss: 2.6669445037841797\n",
      "[step: 567] loss: 2.664353609085083\n",
      "[step: 568] loss: 2.661285638809204\n",
      "[step: 569] loss: 2.6576287746429443\n",
      "[step: 570] loss: 2.653881549835205\n",
      "[step: 571] loss: 2.650294780731201\n",
      "[step: 572] loss: 2.6471359729766846\n",
      "[step: 573] loss: 2.6443417072296143\n",
      "[step: 574] loss: 2.641692638397217\n",
      "[step: 575] loss: 2.63901948928833\n",
      "[step: 576] loss: 2.6360952854156494\n",
      "[step: 577] loss: 2.6330199241638184\n",
      "[step: 578] loss: 2.6297500133514404\n",
      "[step: 579] loss: 2.626476287841797\n",
      "[step: 580] loss: 2.6232476234436035\n",
      "[step: 581] loss: 2.620114803314209\n",
      "[step: 582] loss: 2.6170694828033447\n",
      "[step: 583] loss: 2.614088535308838\n",
      "[step: 584] loss: 2.611170530319214\n",
      "[step: 585] loss: 2.608271598815918\n",
      "[step: 586] loss: 2.605426073074341\n",
      "[step: 587] loss: 2.602590322494507\n",
      "[step: 588] loss: 2.59983229637146\n",
      "[step: 589] loss: 2.5971274375915527\n",
      "[step: 590] loss: 2.594590663909912\n",
      "[step: 591] loss: 2.592247486114502\n",
      "[step: 592] loss: 2.590332508087158\n",
      "[step: 593] loss: 2.588944435119629\n",
      "[step: 594] loss: 2.588524103164673\n",
      "[step: 595] loss: 2.588794469833374\n",
      "[step: 596] loss: 2.5897293090820312\n",
      "[step: 597] loss: 2.5886178016662598\n",
      "[step: 598] loss: 2.5844476222991943\n",
      "[step: 599] loss: 2.5759356021881104\n",
      "[step: 600] loss: 2.5674571990966797\n",
      "[step: 601] loss: 2.5627126693725586\n",
      "[step: 602] loss: 2.5622949600219727\n",
      "[step: 603] loss: 2.563370704650879\n",
      "[step: 604] loss: 2.5623202323913574\n",
      "[step: 605] loss: 2.5581188201904297\n",
      "[step: 606] loss: 2.5523629188537598\n",
      "[step: 607] loss: 2.5480222702026367\n",
      "[step: 608] loss: 2.546954393386841\n",
      "[step: 609] loss: 2.5454676151275635\n",
      "[step: 610] loss: 2.5433454513549805\n",
      "[step: 611] loss: 2.539623975753784\n",
      "[step: 612] loss: 2.536031484603882\n",
      "[step: 613] loss: 2.533168077468872\n",
      "[step: 614] loss: 2.5294950008392334\n",
      "[step: 615] loss: 2.526839256286621\n",
      "[step: 616] loss: 2.5253403186798096\n",
      "[step: 617] loss: 2.523793935775757\n",
      "[step: 618] loss: 2.5211598873138428\n",
      "[step: 619] loss: 2.517228126525879\n",
      "[step: 620] loss: 2.5141408443450928\n",
      "[step: 621] loss: 2.5117907524108887\n",
      "[step: 622] loss: 2.5090296268463135\n",
      "[step: 623] loss: 2.5066349506378174\n",
      "[step: 624] loss: 2.504836082458496\n",
      "[step: 625] loss: 2.502826452255249\n",
      "[step: 626] loss: 2.5002496242523193\n",
      "[step: 627] loss: 2.497483253479004\n",
      "[step: 628] loss: 2.494964122772217\n",
      "[step: 629] loss: 2.4924166202545166\n",
      "[step: 630] loss: 2.4895336627960205\n",
      "[step: 631] loss: 2.4868521690368652\n",
      "[step: 632] loss: 2.484501361846924\n",
      "[step: 633] loss: 2.482147216796875\n",
      "[step: 634] loss: 2.4797027111053467\n",
      "[step: 635] loss: 2.4773266315460205\n",
      "[step: 636] loss: 2.475151538848877\n",
      "[step: 637] loss: 2.473036527633667\n",
      "[step: 638] loss: 2.470867872238159\n",
      "[step: 639] loss: 2.4688470363616943\n",
      "[step: 640] loss: 2.467179536819458\n",
      "[step: 641] loss: 2.466027021408081\n",
      "[step: 642] loss: 2.465637683868408\n",
      "[step: 643] loss: 2.4665751457214355\n",
      "[step: 644] loss: 2.469405174255371\n",
      "[step: 645] loss: 2.474567174911499\n",
      "[step: 646] loss: 2.4789535999298096\n",
      "[step: 647] loss: 2.4791009426116943\n",
      "[step: 648] loss: 2.4690372943878174\n",
      "[step: 649] loss: 2.4541714191436768\n",
      "[step: 650] loss: 2.444047451019287\n",
      "[step: 651] loss: 2.443896770477295\n",
      "[step: 652] loss: 2.4493613243103027\n",
      "[step: 653] loss: 2.4517621994018555\n",
      "[step: 654] loss: 2.4466450214385986\n",
      "[step: 655] loss: 2.437316656112671\n",
      "[step: 656] loss: 2.4309756755828857\n",
      "[step: 657] loss: 2.431056499481201\n",
      "[step: 658] loss: 2.433838367462158\n",
      "[step: 659] loss: 2.43353009223938\n",
      "[step: 660] loss: 2.428682327270508\n",
      "[step: 661] loss: 2.422494411468506\n",
      "[step: 662] loss: 2.4188501834869385\n",
      "[step: 663] loss: 2.4184274673461914\n",
      "[step: 664] loss: 2.418923854827881\n",
      "[step: 665] loss: 2.417825222015381\n",
      "[step: 666] loss: 2.4144482612609863\n",
      "[step: 667] loss: 2.4100534915924072\n",
      "[step: 668] loss: 2.4067747592926025\n",
      "[step: 669] loss: 2.405325174331665\n",
      "[step: 670] loss: 2.40478777885437\n",
      "[step: 671] loss: 2.403820037841797\n",
      "[step: 672] loss: 2.401714563369751\n",
      "[step: 673] loss: 2.3987984657287598\n",
      "[step: 674] loss: 2.395719289779663\n",
      "[step: 675] loss: 2.3930811882019043\n",
      "[step: 676] loss: 2.391155242919922\n",
      "[step: 677] loss: 2.389770746231079\n",
      "[step: 678] loss: 2.3885209560394287\n",
      "[step: 679] loss: 2.3870530128479004\n",
      "[step: 680] loss: 2.385221242904663\n",
      "[step: 681] loss: 2.383077383041382\n",
      "[step: 682] loss: 2.3807716369628906\n",
      "[step: 683] loss: 2.3783962726593018\n",
      "[step: 684] loss: 2.37607741355896\n",
      "[step: 685] loss: 2.373880624771118\n",
      "[step: 686] loss: 2.3718342781066895\n",
      "[step: 687] loss: 2.3699066638946533\n",
      "[step: 688] loss: 2.3680567741394043\n",
      "[step: 689] loss: 2.366267681121826\n",
      "[step: 690] loss: 2.3645434379577637\n",
      "[step: 691] loss: 2.3629138469696045\n",
      "[step: 692] loss: 2.361419200897217\n",
      "[step: 693] loss: 2.360157012939453\n",
      "[step: 694] loss: 2.359304666519165\n",
      "[step: 695] loss: 2.359239339828491\n",
      "[step: 696] loss: 2.3605008125305176\n",
      "[step: 697] loss: 2.364248514175415\n",
      "[step: 698] loss: 2.371284008026123\n",
      "[step: 699] loss: 2.383078098297119\n",
      "[step: 700] loss: 2.394813299179077\n",
      "[step: 701] loss: 2.4002232551574707\n",
      "[step: 702] loss: 2.385446310043335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 703] loss: 2.3587071895599365\n",
      "[step: 704] loss: 2.339970588684082\n",
      "[step: 705] loss: 2.3426826000213623\n",
      "[step: 706] loss: 2.356778383255005\n",
      "[step: 707] loss: 2.362121343612671\n",
      "[step: 708] loss: 2.351215124130249\n",
      "[step: 709] loss: 2.3348138332366943\n",
      "[step: 710] loss: 2.329608678817749\n",
      "[step: 711] loss: 2.3363089561462402\n",
      "[step: 712] loss: 2.3421223163604736\n",
      "[step: 713] loss: 2.3378636837005615\n",
      "[step: 714] loss: 2.3270556926727295\n",
      "[step: 715] loss: 2.320869207382202\n",
      "[step: 716] loss: 2.322903871536255\n",
      "[step: 717] loss: 2.326780319213867\n",
      "[step: 718] loss: 2.3255960941314697\n",
      "[step: 719] loss: 2.3190488815307617\n",
      "[step: 720] loss: 2.3131065368652344\n",
      "[step: 721] loss: 2.3118743896484375\n",
      "[step: 722] loss: 2.3136377334594727\n",
      "[step: 723] loss: 2.314094305038452\n",
      "[step: 724] loss: 2.311000347137451\n",
      "[step: 725] loss: 2.306217670440674\n",
      "[step: 726] loss: 2.302868366241455\n",
      "[step: 727] loss: 2.302079677581787\n",
      "[step: 728] loss: 2.302405595779419\n",
      "[step: 729] loss: 2.3017947673797607\n",
      "[step: 730] loss: 2.2994399070739746\n",
      "[step: 731] loss: 2.2960875034332275\n",
      "[step: 732] loss: 2.29316782951355\n",
      "[step: 733] loss: 2.2913968563079834\n",
      "[step: 734] loss: 2.2905707359313965\n",
      "[step: 735] loss: 2.289881706237793\n",
      "[step: 736] loss: 2.288623094558716\n",
      "[step: 737] loss: 2.286663055419922\n",
      "[step: 738] loss: 2.2842304706573486\n",
      "[step: 739] loss: 2.2817983627319336\n",
      "[step: 740] loss: 2.2796788215637207\n",
      "[step: 741] loss: 2.2779698371887207\n",
      "[step: 742] loss: 2.2765824794769287\n",
      "[step: 743] loss: 2.2753195762634277\n",
      "[step: 744] loss: 2.2740254402160645\n",
      "[step: 745] loss: 2.272587776184082\n",
      "[step: 746] loss: 2.270989179611206\n",
      "[step: 747] loss: 2.2692410945892334\n",
      "[step: 748] loss: 2.2674152851104736\n",
      "[step: 749] loss: 2.2655375003814697\n",
      "[step: 750] loss: 2.263667583465576\n",
      "[step: 751] loss: 2.261808395385742\n",
      "[step: 752] loss: 2.2599947452545166\n",
      "[step: 753] loss: 2.2582244873046875\n",
      "[step: 754] loss: 2.2565200328826904\n",
      "[step: 755] loss: 2.2548892498016357\n",
      "[step: 756] loss: 2.2533833980560303\n",
      "[step: 757] loss: 2.252060890197754\n",
      "[step: 758] loss: 2.251081943511963\n",
      "[step: 759] loss: 2.2506637573242188\n",
      "[step: 760] loss: 2.251328706741333\n",
      "[step: 761] loss: 2.253749132156372\n",
      "[step: 762] loss: 2.259507894515991\n",
      "[step: 763] loss: 2.269822359085083\n",
      "[step: 764] loss: 2.2870688438415527\n",
      "[step: 765] loss: 2.3059966564178467\n",
      "[step: 766] loss: 2.3188226222991943\n",
      "[step: 767] loss: 2.3039937019348145\n",
      "[step: 768] loss: 2.2669389247894287\n",
      "[step: 769] loss: 2.2342464923858643\n",
      "[step: 770] loss: 2.2325479984283447\n",
      "[step: 771] loss: 2.2532739639282227\n",
      "[step: 772] loss: 2.2661373615264893\n",
      "[step: 773] loss: 2.254401445388794\n",
      "[step: 774] loss: 2.230194568634033\n",
      "[step: 775] loss: 2.220449924468994\n",
      "[step: 776] loss: 2.2302486896514893\n",
      "[step: 777] loss: 2.2402145862579346\n",
      "[step: 778] loss: 2.2345664501190186\n",
      "[step: 779] loss: 2.2192888259887695\n",
      "[step: 780] loss: 2.212006092071533\n",
      "[step: 781] loss: 2.217164993286133\n",
      "[step: 782] loss: 2.223053455352783\n",
      "[step: 783] loss: 2.2196407318115234\n",
      "[step: 784] loss: 2.2097742557525635\n",
      "[step: 785] loss: 2.203704833984375\n",
      "[step: 786] loss: 2.205315351486206\n",
      "[step: 787] loss: 2.208705186843872\n",
      "[step: 788] loss: 2.2072854042053223\n",
      "[step: 789] loss: 2.2011184692382812\n",
      "[step: 790] loss: 2.1956892013549805\n",
      "[step: 791] loss: 2.1946911811828613\n",
      "[step: 792] loss: 2.196234703063965\n",
      "[step: 793] loss: 2.196208953857422\n",
      "[step: 794] loss: 2.192991256713867\n",
      "[step: 795] loss: 2.18847393989563\n",
      "[step: 796] loss: 2.185483455657959\n",
      "[step: 797] loss: 2.1848175525665283\n",
      "[step: 798] loss: 2.184918165206909\n",
      "[step: 799] loss: 2.183980703353882\n",
      "[step: 800] loss: 2.1814541816711426\n",
      "[step: 801] loss: 2.1782290935516357\n",
      "[step: 802] loss: 2.175631523132324\n",
      "[step: 803] loss: 2.1741461753845215\n",
      "[step: 804] loss: 2.173375129699707\n",
      "[step: 805] loss: 2.1725053787231445\n",
      "[step: 806] loss: 2.170961380004883\n",
      "[step: 807] loss: 2.1687979698181152\n",
      "[step: 808] loss: 2.1663966178894043\n",
      "[step: 809] loss: 2.164200782775879\n",
      "[step: 810] loss: 2.1624395847320557\n",
      "[step: 811] loss: 2.1610498428344727\n",
      "[step: 812] loss: 2.159834384918213\n",
      "[step: 813] loss: 2.1585607528686523\n",
      "[step: 814] loss: 2.157095432281494\n",
      "[step: 815] loss: 2.155414342880249\n",
      "[step: 816] loss: 2.1535770893096924\n",
      "[step: 817] loss: 2.151675224304199\n",
      "[step: 818] loss: 2.1497981548309326\n",
      "[step: 819] loss: 2.1479904651641846\n",
      "[step: 820] loss: 2.1462783813476562\n",
      "[step: 821] loss: 2.1446516513824463\n",
      "[step: 822] loss: 2.1430892944335938\n",
      "[step: 823] loss: 2.1415772438049316\n",
      "[step: 824] loss: 2.140099287033081\n",
      "[step: 825] loss: 2.1386570930480957\n",
      "[step: 826] loss: 2.137253761291504\n",
      "[step: 827] loss: 2.135908842086792\n",
      "[step: 828] loss: 2.1346569061279297\n",
      "[step: 829] loss: 2.1335623264312744\n",
      "[step: 830] loss: 2.132723093032837\n",
      "[step: 831] loss: 2.132322311401367\n",
      "[step: 832] loss: 2.1326303482055664\n",
      "[step: 833] loss: 2.134186267852783\n",
      "[step: 834] loss: 2.137716054916382\n",
      "[step: 835] loss: 2.144552707672119\n",
      "[step: 836] loss: 2.1557297706604004\n",
      "[step: 837] loss: 2.1723687648773193\n",
      "[step: 838] loss: 2.19053316116333\n",
      "[step: 839] loss: 2.202650547027588\n",
      "[step: 840] loss: 2.193507671356201\n",
      "[step: 841] loss: 2.161966323852539\n",
      "[step: 842] loss: 2.126066207885742\n",
      "[step: 843] loss: 2.111640214920044\n",
      "[step: 844] loss: 2.1232995986938477\n",
      "[step: 845] loss: 2.142411470413208\n",
      "[step: 846] loss: 2.146942377090454\n",
      "[step: 847] loss: 2.1308655738830566\n",
      "[step: 848] loss: 2.1102540493011475\n",
      "[step: 849] loss: 2.1042187213897705\n",
      "[step: 850] loss: 2.1133358478546143\n",
      "[step: 851] loss: 2.1223559379577637\n",
      "[step: 852] loss: 2.118950366973877\n",
      "[step: 853] loss: 2.106311559677124\n",
      "[step: 854] loss: 2.0972843170166016\n",
      "[step: 855] loss: 2.098515033721924\n",
      "[step: 856] loss: 2.104501962661743\n",
      "[step: 857] loss: 2.1059324741363525\n",
      "[step: 858] loss: 2.100048542022705\n",
      "[step: 859] loss: 2.092352867126465\n",
      "[step: 860] loss: 2.089369058609009\n",
      "[step: 861] loss: 2.09143328666687\n",
      "[step: 862] loss: 2.0937981605529785\n",
      "[step: 863] loss: 2.092418909072876\n",
      "[step: 864] loss: 2.087723970413208\n",
      "[step: 865] loss: 2.0833637714385986\n",
      "[step: 866] loss: 2.0819082260131836\n",
      "[step: 867] loss: 2.082736015319824\n",
      "[step: 868] loss: 2.0833303928375244\n",
      "[step: 869] loss: 2.0819036960601807\n",
      "[step: 870] loss: 2.0788309574127197\n",
      "[step: 871] loss: 2.0758326053619385\n",
      "[step: 872] loss: 2.0742084980010986\n",
      "[step: 873] loss: 2.073894500732422\n",
      "[step: 874] loss: 2.0738182067871094\n",
      "[step: 875] loss: 2.072984218597412\n",
      "[step: 876] loss: 2.071181058883667\n",
      "[step: 877] loss: 2.068943500518799\n",
      "[step: 878] loss: 2.0669994354248047\n",
      "[step: 879] loss: 2.065727949142456\n",
      "[step: 880] loss: 2.0649948120117188\n",
      "[step: 881] loss: 2.064366102218628\n",
      "[step: 882] loss: 2.0634567737579346\n",
      "[step: 883] loss: 2.0621321201324463\n",
      "[step: 884] loss: 2.060521125793457\n",
      "[step: 885] loss: 2.058882474899292\n",
      "[step: 886] loss: 2.057432174682617\n",
      "[step: 887] loss: 2.0562446117401123\n",
      "[step: 888] loss: 2.055260181427002\n",
      "[step: 889] loss: 2.0543465614318848\n",
      "[step: 890] loss: 2.0533833503723145\n",
      "[step: 891] loss: 2.052300453186035\n",
      "[step: 892] loss: 2.0510897636413574\n",
      "[step: 893] loss: 2.0497941970825195\n",
      "[step: 894] loss: 2.0484721660614014\n",
      "[step: 895] loss: 2.047175407409668\n",
      "[step: 896] loss: 2.0459342002868652\n",
      "[step: 897] loss: 2.0447590351104736\n",
      "[step: 898] loss: 2.043642044067383\n",
      "[step: 899] loss: 2.0425660610198975\n",
      "[step: 900] loss: 2.041515588760376\n",
      "[step: 901] loss: 2.0404767990112305\n",
      "[step: 902] loss: 2.039440631866455\n",
      "[step: 903] loss: 2.038405418395996\n",
      "[step: 904] loss: 2.03737211227417\n",
      "[step: 905] loss: 2.036343574523926\n",
      "[step: 906] loss: 2.0353291034698486\n",
      "[step: 907] loss: 2.0343360900878906\n",
      "[step: 908] loss: 2.033381462097168\n",
      "[step: 909] loss: 2.032482624053955\n",
      "[step: 910] loss: 2.031670331954956\n",
      "[step: 911] loss: 2.0309884548187256\n",
      "[step: 912] loss: 2.030510187149048\n",
      "[step: 913] loss: 2.030343770980835\n",
      "[step: 914] loss: 2.0306761264801025\n",
      "[step: 915] loss: 2.031778335571289\n",
      "[step: 916] loss: 2.034113645553589\n",
      "[step: 917] loss: 2.038282632827759\n",
      "[step: 918] loss: 2.04518985748291\n",
      "[step: 919] loss: 2.055485248565674\n",
      "[step: 920] loss: 2.0694382190704346\n",
      "[step: 921] loss: 2.0843849182128906\n",
      "[step: 922] loss: 2.0948753356933594\n",
      "[step: 923] loss: 2.0913772583007812\n",
      "[step: 924] loss: 2.070389747619629\n",
      "[step: 925] loss: 2.039806842803955\n",
      "[step: 926] loss: 2.017591714859009\n",
      "[step: 927] loss: 2.015040159225464\n",
      "[step: 928] loss: 2.0278031826019287\n",
      "[step: 929] loss: 2.0413460731506348\n",
      "[step: 930] loss: 2.042670488357544\n",
      "[step: 931] loss: 2.0302958488464355\n",
      "[step: 932] loss: 2.0145864486694336\n",
      "[step: 933] loss: 2.0077197551727295\n",
      "[step: 934] loss: 2.0121443271636963\n",
      "[step: 935] loss: 2.020167350769043\n",
      "[step: 936] loss: 2.0225799083709717\n",
      "[step: 937] loss: 2.0166468620300293\n",
      "[step: 938] loss: 2.007535219192505\n",
      "[step: 939] loss: 2.002293586730957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 940] loss: 2.003368377685547\n",
      "[step: 941] loss: 2.0073540210723877\n",
      "[step: 942] loss: 2.009110450744629\n",
      "[step: 943] loss: 2.0064432621002197\n",
      "[step: 944] loss: 2.0012569427490234\n",
      "[step: 945] loss: 1.9972059726715088\n",
      "[step: 946] loss: 1.9963213205337524\n",
      "[step: 947] loss: 1.9977364540100098\n",
      "[step: 948] loss: 1.9990214109420776\n",
      "[step: 949] loss: 1.9983775615692139\n",
      "[step: 950] loss: 1.995829701423645\n",
      "[step: 951] loss: 1.9927730560302734\n",
      "[step: 952] loss: 1.9906926155090332\n",
      "[step: 953] loss: 1.9900928735733032\n",
      "[step: 954] loss: 1.9903992414474487\n",
      "[step: 955] loss: 1.990588903427124\n",
      "[step: 956] loss: 1.9899489879608154\n",
      "[step: 957] loss: 1.9884365797042847\n",
      "[step: 958] loss: 1.9865331649780273\n",
      "[step: 959] loss: 1.9848442077636719\n",
      "[step: 960] loss: 1.9837262630462646\n",
      "[step: 961] loss: 1.9831565618515015\n",
      "[step: 962] loss: 1.9828497171401978\n",
      "[step: 963] loss: 1.9824659824371338\n",
      "[step: 964] loss: 1.9817872047424316\n",
      "[step: 965] loss: 1.9807754755020142\n",
      "[step: 966] loss: 1.9795509576797485\n",
      "[step: 967] loss: 1.9782893657684326\n",
      "[step: 968] loss: 1.9771370887756348\n",
      "[step: 969] loss: 1.9761682748794556\n",
      "[step: 970] loss: 1.9753782749176025\n",
      "[step: 971] loss: 1.9747087955474854\n",
      "[step: 972] loss: 1.9740837812423706\n",
      "[step: 973] loss: 1.9734385013580322\n",
      "[step: 974] loss: 1.9727355241775513\n",
      "[step: 975] loss: 1.9719606637954712\n",
      "[step: 976] loss: 1.9711220264434814\n",
      "[step: 977] loss: 1.9702397584915161\n",
      "[step: 978] loss: 1.9693324565887451\n",
      "[step: 979] loss: 1.968421459197998\n",
      "[step: 980] loss: 1.9675179719924927\n",
      "[step: 981] loss: 1.9666317701339722\n",
      "[step: 982] loss: 1.9657642841339111\n",
      "[step: 983] loss: 1.9649156332015991\n",
      "[step: 984] loss: 1.964082956314087\n",
      "[step: 985] loss: 1.9632641077041626\n",
      "[step: 986] loss: 1.9624558687210083\n",
      "[step: 987] loss: 1.9616553783416748\n",
      "[step: 988] loss: 1.9608615636825562\n",
      "[step: 989] loss: 1.9600722789764404\n",
      "[step: 990] loss: 1.9592870473861694\n",
      "[step: 991] loss: 1.9585059881210327\n",
      "[step: 992] loss: 1.9577281475067139\n",
      "[step: 993] loss: 1.9569549560546875\n",
      "[step: 994] loss: 1.9561867713928223\n",
      "[step: 995] loss: 1.955427885055542\n",
      "[step: 996] loss: 1.9546804428100586\n",
      "[step: 997] loss: 1.9539546966552734\n",
      "[step: 998] loss: 1.9532636404037476\n",
      "[step: 999] loss: 1.952638030052185\n",
      "RMSE: 35.47024154663086\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXecXFXd/99n2vbNJtnNpldqKAkSAelVaQo2hMeCiuJj\n74/iY3v8iWLHrihIVARRULo0Cc1ACCEF0ns2u9mW7WXaPb8/zj0zd2buzNyZrcme9+u1r9m9M3Pm\nzO7s+ZxvPUJKicFgMBgM6fjGegIGg8FgGJ8YgTAYDAaDK0YgDAaDweCKEQiDwWAwuGIEwmAwGAyu\nGIEwGAwGgytGIAwGg8HgihEIg8FgMLhiBMJgMBgMrgTGegJDoba2Vs6fP3+sp2EwGAyHFC+//HKb\nlLIu3+MOaYGYP38+q1evHutpGAwGwyGFEGKPl8cZF5PBYDAYXDECYTAYDAZXjEAYDAaDwRUjEAaD\nwWBwxQiEwWAwGFwxAmEwGAwGV4xAGAwGg8EVIxAGg2H8074Ddq4Y61lMOIxAGAyG8c9zP4F/fHSs\nZzHhMAJhMBjGP4NdEO0b61lMOIxAGAyG8U+kF2LhsZ7FhMMIhMFgGP9E+iA2CFKO9UwmFEYgDAbD\n+Cfcq27jkbGdxwTDCITBYBj/RGyBiA2O7TwmGEYgDAbD+CchECYOMZoYgTAYDOOfiJ3BZCyIUcUI\nhMFgGN/EY0lhMBbEqGIEwmAwjG+0ewmMBTHKjJhACCFuE0K0CCFedVz7gRBisxBivRDiH0KIGsd9\nNwghtgshtggh3jRS8zIYDIcYKQJhLIjRZCQtiNuBi9OuPQ4cL6U8EdgK3AAghFgMXA0cZz/nV0II\n/wjOzWAwHCpEHBXUxoIYVUZMIKSUzwAH0649JqWM2T++AMy2v78CuEtKGZZS7gK2A6eM1NwMBsMh\nRNhhQUSNQIwmYxmD+CDwiP39LGCf474G+5rBYJjomBjEmDEmAiGE+F8gBtyhL7k8zLWmXghxvRBi\ntRBidWtr60hN0WAwjBcKEQgpYfPDKvPJMGRGXSCEENcClwPvljLRWKUBmON42Gyg0e35UspbpJTL\npJTL6urqRnayBoNh7AkXEKRuXAN3XWPOjhgmRlUghBAXA18C3iKl7HfcdT9wtRCiRAixADgSWDWa\nczMYDOOUQiyIrgb7OT0jN58JRGCkBhZC3AmcC9QKIRqAb6CylkqAx4UQAC9IKf9bSvmaEOJuYCPK\n9fRxKWV8pOZmMBgOIQpJc+05YD/ONPUbDkZMIKSU17hcvjXH428Ebhyp+RgMhkOUQtJctUCYrq/D\ngqmkNhgM45twLwTL1fdeLYi4KagbDkbMgjAYDIZhIdILoUqw4h4siCZ1a1xMw4IRCIPBML6J9EJJ\npbIePFsQRiCGA+NiMhgM45tIn7IggqX5LYheIxDDiREIg8EwvgnbLqZASW4LIjoIAx3qe9PUb1gw\nAmEwGMY32sUUyGNBaOsBjAUxTBiBMBgM45tIL4Qq8lsQPc3J741ADAtGIAwGw/gm4WLKY0HoDCYw\nLqZhwgiEwWAY3+ggdaA0jwVhu5gCZRCPjs7cDnOMQBgMhvGLlI4YREn+GIQvCFX1plBumDACYTAY\nxi/RfkDaMYh8LqYDUDUd/HliFQbPGIEwGAzjF93qO+TBguhpUgIRCBkX0zBhBMJgMIxfdCfXkipv\nMQhtQRgX07BgBMJgMIxftEAk0lzzuJgqp4M/ZHoxDRNGIAwGw/hFt/rOl8UUHYDBToeLyQjEcGAE\nwmAwjF+8xiB0imvVDONiGkaMQBgMhvFLIgZhWxDxCFhW5uN67SrqqnrwB42LaZgwAmEwGMYv6TEI\ncLcOdBV11Qz1OONiGhaMQBgMhvFLegwC3N1MGS4mIxDDgREIg8EwfkmPQYB7oLqnSWUvlU1WQWpT\nKDcsGIEwGAzjl0iPWvgDoTwWRLNKcRVCPd5YEMOCEQiDwTB+0Y36IL8FUTVdfW8EYtgYMYEQQtwm\nhGgRQrzquDZFCPG4EGKbfTvZvi6EED8TQmwXQqwXQrxupOZlMBgOIXSrb1BdWsHdguhtVhlMkP/c\nCINnRtKCuB24OO3al4EnpZRHAk/aPwNcAhxpf10P/HoE52UwGA4VdCdXyG1B9NouJlAWhIyDFR+d\nOR7GjJhASCmfAQ6mXb4CWG5/vxy40nH9j1LxAlAjhJgxUnMzGAyHCPo0Ocgeg4iF1VnUlbYF4Q+p\n2zxupkjMIhp3qakwJBjtGES9lLIJwL6dZl+fBexzPK7BvmYwGCYyKTEILRBpFkRvi7qttJeTXJaG\ng4/d8TJf/cerOR8z0RkvQWrhck26PlCI64UQq4UQq1tbW0d4WgaDYUwJOy0IvfCnWRAJgUi3IHK3\n/G7oGKCxayD7Azb8HTr2FDjhw4vRFohm7Tqyb+2/LA3AHMfjZgONbgNIKW+RUi6TUi6rq6sb0cka\nDIYxJtKnWn1D0oKIpguELpJLF4jcFkQ0nsPFFIvAPR+CNX8sYtKHD6MtEPcD19rfXwvc57j+Pjub\n6TSgS7uiDAbDBCbS45Lmmi4Qdh+myvq0x+UWiJglicVdHRXQ3w7I3O3FJwAjmeZ6J7ASOFoI0SCE\nuA64CbhICLENuMj+GeBhYCewHfgd8LGRmpfBYDiEiPTlD1L3tgACKmyPgj8IwJ6WTp7Y2Jx16Giu\nIHV/m/trTTACIzWwlPKaLHdd4PJYCXx8pOZiMBgOQWIRlYmUL8215wCUT00IA371uPvW7ObPuzu4\ncHG96/BRSxLNZkH0GYGA8ROkNhgMhlQijj5MkNuCqHSIgC0kMjpIJEcaazRuEXNrHQ62i4kJX3Bn\nBMJgMIxP0gXCHwSES5prczLFNfE4IB4lns1CQLmYssYgjAUBGIEwGAzjlbDjLAhQjfgCpfktCH/y\n3IhoNgsB5WLKamEkYhDGgjAYDIbxR9SuUdACAZl9lqRUaa5VTheTSnMV8Qhxy91CkFIqF5OxIHJi\nBMJgMIxPdKsM7TKCTAtisFM9LsWCSLbaiMYlKgcmbWhLIiU5YhDGggAjEAaDYbxi2ZXQPkeyZboF\nkV5FDQkXk89SAuNmRMTsi5FYFoHoM0FqMAJhMBjGK1ZM3fpyWBD6qFFnkFq7mGJKINysBB17iGVx\nQZksJoURCIPBMD6J2wKR4mLKZkFMT16zXUw+aQuES5whalsO2SupTQwCjEAYDIbxiquLKc2CSLTZ\ncKa52i4mu1mfm5WQcDHFrcwYhRWHfvukAmNBGAwGwzhEd2PNaUE0K0EoneR4jG1BWNqCcHExOWIP\nGZlOAx2ABOEzFsRYT8BgMBhccYtBBMsyLYiqelUjofGnCoRbqqvTqsiwMHSKa2W9sSDGegIGg8Hg\nSsKCyJXF1JyawQQOgVACE3URCGeTvoyGfTr+UD3LWBBjPQGDwWBwJWFBpMcgHIf8pFdRg7Im/CEC\ndpDard2G08WU0bBPWxCTZqmzrXWwfAJiBMJgMIxPEkHqHDGIngOpAWqNP4Tffr5bu40UF1NWC2K2\n/YCJa0UYgTAYDOMT1zRXRxZTLAIDB1NTXDX+EH6pBMItBpHiYsqIQdg1ENUz7deZuHEIIxAGg2F8\nkjXN1V6w++wz6d0siEAJAVsg3A4FijpdTOnV1P3tUDIpedSpsSAMBoNhnJE1zdVesNOPGnXiDyZj\nEG4WREoWk4uLqWJq9vMnJhAjdqKcwWAwDAnXGESpCl7HY3kEogS/tLOYnEFoy4KBjlQLwi1IXV7r\n+WzrwxljQRgMhvGJFVe36c36AOJh6G5U31dlCoQMhAjhEoPY8hD85DgVu7DJaLfR3w4VtcaCwAiE\nwWAYr8SjqprZ51imEot2GFo2qdPmqmZmPFX6QoRQFkRKllJXA8QG8Pc1Jy5lHBrU16bOuE6IUWRY\n3s6hiBEIg8EwPrGiqe4lcLh9BqH5Vag/LlVA9FP9IYJaIJwWRLQfAP9Ae+JSioBI6bAgHK81QTEC\nYTAYxifxWGqAGpIWRHQAml+D+uNdnyp9IUJCN+tzCEBULfa+wY7EpRQBGexSwmRiEMAYCYQQ4rNC\niNeEEK8KIe4UQpQKIRYIIV4UQmwTQvxVCBEai7kZDIZxghVNjT9ActFu2wbhbpjuLhCWL+hwMWVa\nEIFwUiBSXEz6HIhyk8UEHgRCKN4jhPi6/fNcIcQpxb6gEGIW8ClgmZTyeMAPXA18D/iJlPJIoAO4\nrtjXMBgMhwHxaHYLYv9qdVt/gutTLWcMwmkh2It90GlBOAVEt9lICVIP0YJ47Z+w9dGhjTFGeLEg\nfgW8AbjG/rkH+OUQXzcAlAkhAkA50AScD/zdvn85cOUQX8NgMBzK5IpBNKwGBNQvdn+qL5jIYkqN\nQag+TqGoUyCyWRDDFIN45oewcqhL5tjgRSBOlVJ+HBgEkFJ2AEW7f6SU+4EfAntRwtAFvAx0Sil1\nV6wGYJbb84UQ1wshVgshVre2thY7DYPBMN6x4i4uJm1BrIEpCyFU4frUeIqLyRmDsAUi3Jm4lOpi\nGgELYuBgwrV1qOFFIKJCCD8gAYQQdUCWk77zI4SYDFwBLABmAhXAJS4PdT0LUEp5i5RymZRyWV1d\nXbHTMBgM4514NLXVNyR39eGurPEHUC6moHDLYtIWRFIgXF1M5cOYxTTQkXjdQw0vAvEz4B/ANCHE\njcBzwHeG8JoXAruklK1SyihwL3A6UGO7nABmA41DeI0JRSxu8eSm5syjEw2GQxlXF1Np8vss8QeA\nmAi6F8rZrcJLIw6BsNJcTMFyCJUPT5A6Oqish0hf8WOMIXkFQkp5B/A/wHdRLqErpZR/G8Jr7gVO\nE0KUCyEEcAGwEXgKeIf9mGuB+4bwGhOKZ7e3cd3y1bzW2D3WUzEYho9caa6Q04KIi9wuptJYUiBS\nWm0424f7Avaxo0NwMQ10pLzuoYaXLKbTgP1Syl9KKX8BNAghTi32BaWUL6KC0WuADfYcbgG+BHxO\nCLEdmArcWuxrTDT6wuof4UDXxE3HMxyGuKa5Oi2I3ALhXiinFuqyaFfyklNAuhuT50AIkdpevBh0\nS49DNAbhpVnfr4HXOX7uc7lWEFLKbwDfSLu8Eyg6fXYioz/gbb0Tt6DHcBiSK821dBJMmp31qTFf\niBIRA2RaHYRtQVh9VAQs+mK+1Pu7G2DOaY7XKxkmC+LQFAgvMQghHc5tKaWF6QI7rtDHJxqBMBxW\nWLHshXL1J6gdfhZidjgzRMy1DgJgelAt2okT5ywLupvUUaOJ1xuiBdFvWxBWLNm+/BDCi0DsFEJ8\nSggRtL8+jdrtG8YJEXsH1NY7cZuKGQ5DXAXCtiByxB8AoijLI0gsLQbRr2ocgBkBFTiOxmwB6WtV\nbq1qp0AMkwUBh2Sg2otA/Dcqy2g/qj7hVOD6kZyUoTB0b/tWY0EYDifcXEz+AFz5azjtYzmfGhPq\neSGimTEIWwBqA/0I4chi6m5Qt9XpFsQwCcQhGKjO6yqSUragWmEYxim60KetxwiE4TDCLc0VYOl/\n5X1qFKeLyRYAKdUiPWk2HFjPFNFD0OdLZjHp8yUmDacFkTx34lCMQ2QVCCHE/0gpvy+E+DkuRWtS\nyk+N6MwMnomaGIThcMQtzdUjUduCCApHDCIWBmTCQphMD0G/SLqguvar2wwLYihZTE4L4jASCGCT\nfbt6NCZiKB6dxdTeZ2IQhsMItzRXj+gYRAnRZJaSXSSnLYTJ9BLw+5Jprt0N4C9JxCgA8IeGZkH0\nOyyIyGEkEFLKB+wWG8dLKb84inMyFIgOUnf2R4nGLYJ+c8yH4TDALQbhkahMupgSldQ6BlBaw6Ao\npYZugn5B1HK4mKpnpmZHBUqTDfyKYaBTiZwVOyQtiJwriZQyDpw8SnMxFEnEcQB7u8lkMhwuuDXr\n80jEtiBKffGkhaAFIlhGt6imWvYQ9PtSXUzptRXDEYPQR6IeggLh5bf/ihDifuBvqCI5AKSU947Y\nrAwF4awEbesNM31SaY5HGwyHCENwMYXtpa0qYGVaEMEyun3VVMtuAn6RGqSe94bUgYYjBjF5PnTt\nPTyzmIApQDvqvAaNRDXZM4wDnAJhUl0PY6y42oWWVBU/RqQPWjdD61aYcwpMXVTcOH3tsONJ2PYY\n1MyDC75W3DjxGGx5GF76HRzcDZ9YBcEy+74huJjspa0yEE8KgF7og+V0UUWN7LazmCz1u+1pTA1Q\nw9DSXKVUMYh5Z9iTOjwtiC9KKdtGfCaGoonELHwCLGlSXQ9LVv4Knv2h2o1KC956Cyx5V+HjbLwf\n/natGgNg8ZVw1fLCx2nbDr89G6K2Q6GyvjiBiMfglnOheYMKBscjakHVaabZ0lw9MGjHIMoD8WSa\nq16gA6V0iSrmWM22i0naRXIxFYNwEigp3oKIDkA8nHw/h2CQOmsMQgjxZiFEK7BeCNEghDh9FOdl\nKIBI3GJalXIrmWrqcYaU6nCbVb8rrtWClPDib6CiDs76vLp2sMhGBuv/ChXT4Ko/wbTFMNiV/zlu\nbH5AicP7H1YFa8VWCDetVeJwwTfg8p+oa3HHBmcIaa4Re+9bLuLJIHQ0aUF0UkVlvMt2MVnJFNeM\nGMQQLAhdA6Gb/x2CFkSuIPWNwFlSypnA21Htvg3jkGjcoqY8SFnQb2ohxhPr7oKfvw5+dx48/AXY\nu7LwMVo3Q+ceOPUjcP5XIVCW3LkXQiwMO1fA0ZfA4rcowSl2Yd+5QgnM/DOUuyvSp4SsUHY9o25P\nek+qW0kzlBiEpZ5XKuLEtYtJL9DBUg7KKsqtPkp8lhIQtypqGJoFoWsgquoBcdgJRExKuRkSLbqH\n4Pg0jCTRuCTo91FbFTICMV6IDsKDn1UL+hmfUdfCPYWPs+URdXvUxeo2VFHcwr53JUR64ag32eNU\nFrdgRQdgz0pYeJ76OVgOyOICsLuegbpj1fkLfn16m+Pz69aLySPaxRTyOSqpHUHqDlkJqFqIWNxK\nVlG7xSCsqIpRFIqugSibov5uh1mQepoQ4nPZfpZS/njkpmUohEjMIugX1FaWmDTX8cLu59QCfNH/\nqbOTn7+5uIV9679gxpKkb7xYgdj6mFqEF5ztGKe38HH2rlRuoIXnJscBNadQufdxYhHY9yKc9F71\ns98+5j5uf34tS8VKinQxhaW2IJyV1PYCHSij3VL73cmil574FOhqUGJQPiV1oIBDuAp5f5C0IMqn\nKAvpEGzWl0sgfkeq1ZD+s2GcEIlbhAI+qkqD7Dt46JmxhyXbHlXWw/wzk77+QhfkvjbYtwrO+VLy\nWrECse1RNRe9oIfKiwua7nhKBY7nn5GcD9jvrYAz4ve/rAR0wVnq50C6QNiupqFaEERd01zbrQoQ\nUEM327UFkV4kB6nHjhYsENqCmKwEwmlBvPZPePZH6lyL8qlw1ufURmCckauS+v9GcyKG4onGLSpL\nAtRWlvDK3o78TzCMLFLC1kdh4TlqYbDUyWYFL+zbHgMkHH1x8loxAtG+A9q3wymOJsyhyuKEZucK\nmHOqQ2js20LdVbueAUQyBTTdxaRjEUVaEIOWH4AS4V4o12pVgh9q6FEuqO79me4lSFoQ8SIsc21B\nlE2GYEVq7Gjb49C2FWYshY33weR541IgTE+Gw4BIzCLk91FXGeJgXyT1kHbD6NO6RQWWj3yj+jlo\n7zwLXZC3PAJVM9QioilGILY9pm71fPQ40T7lyvFKXxscWA+Lzk0dBwqf0+5nYfoJSZdOhotJWxDF\nCoRtQYi0VhvCB/4QbXEVg5hEj0pz7XapgYBUC6JQBjqUFRksy7QgBjuV6/G6R1WgPzY+XcNGIA4D\noraLqbaqBEvCQdO0b2zZ9qi61Quyz69EopBFNBaGHf9WQWWn2yNYUfhufdtjUHsUTFngGMcWrVgB\ngdOdK9StDlDr+UBh7rPogIo/6HgIZLqY4rbVVawFIdXSViJiqYVygTJVL2SpeVfLbmKxqBKISTks\niGJSXfs7kgKYHqQe7FLuJf0a8fGZXJJXIIQQJS7Xprg91jA26CymqRXqT2UymcaYrY/BtOOgZk7y\nWqEC0fiKWnSPuCj1eqHB5VhEBczdxoHC5rRzhVrUZp7kMk4BorVvlRICp0Cku5i0W67YNNe4jzi+\ntBhEPwTLiFoWg5QQ9ZVQZXUzJdYKMj4yFkTZZPV9epB6sBNKa9T3/iH2expBvFgQ9wohEjIuhJgB\nPD5yUzIUispi8lFbqXZhRiDGkIFOlemj00k1hbqGdNqlc9dfzDh9LWoxrj0ybRzlYilIbBpWw9w3\nKIvIOR8obE67nwXhV2NptKUwTEHqmGURJUiImCMGMagEwrYowsHJLOl5jt8P2gWIM5dmDqQtm2IW\n8IGDDoEoz2FBDLGl+AjiRSD+CfxNCOEXQswHHgVuGMqLCiFqhBB/F0JsFkJsEkK8QQgxRQjxuBBi\nm307eSivMZFQWUyC2ipjQYw5O59Su9EMgagsbDHua1W3FdPSxqkobLfe26JuK9PH0XGRQsY6AJPm\npF4LFeFiatumhK+0OnktPRg8xCB1LC6JiqCrBaG7t/aXTmNqtJGXxXHw4X/DLJfG1cNmQZSnugad\nAuEfvy4mL0eO/k4IEUIJxXzgI1LK/wzxdX8K/EtK+Q577HLgK8CTUsqbhBBfBr4MfCnXIAZFNK6C\n1LWVtkD0mBjEmNG8UQVC0xebQnf+vS1qnPS8fGdw2edhf5dLaMD7nGIRteBlCE0RWUy9LVA5PfVa\nwsWkLYihuZgicYu4CBLEWQehLAh9RO9zS7/PvpYO/rAlwFo3cQCHQORYwA/ugo7dsOi81Ov9Bx0x\nCIdAWBYMdqfGIA41C0II8Tn9BZQCc4C1wGlpBXQFIYSoBs4GbgWQUkaklJ3AFYDuHLYcuLLY15ho\nRG0XU3VpgJDfR1vf+PywTQh6mtRinL7zLcY1VF6b6s7R44D3BTlhQaTVKBTqYtJCky4QxWRo9TZn\njpNwMQ1PmmssbhFLCISjWV8g6WKKVs6iq3x+8sQ5NxJB6hwWxPM3wz0fSr0mpUsMwv6bhbsBCWU1\nydc41AQCVRSnvyqBfwDbHdeKZSHQCvxBCPGKEOL3QogKoF5K2QRg307LNYghSSRuEQz4EEJQWxky\nFsRY0tMEVdMzrxdsQbRmLqKQXJC9CkSfLRDpFkSh4/Q2q9vK+tTrPr9K5SzExdTbkjlOuotpiGmu\n0bgkZruYEgJgxyC0iyno9xEMiJR2+Rl4sSB6WzPbqER61Xsosy2IYIXKGLOsZOFkwsUU8lZnsfE+\nuP+T+R83jIxFoVwAeB3wSSnli0KIn6LcSZ4QQlwPXA8wd+7ckZnhIYSUkmhcErKPGa2tKjExiLGk\n5wDUuHwuC45BtKiGem7jgD2Whz1UbyuEqjKrgAt1MfVmERo9ltdYRqQPIj0uFoQOBg9PmmvUdjEF\nZDTpYooOQEVtQhACfl/yPIhseLEg+tuU5WPFkxafs0gOks0IYwMqgwkcLqZSNUY+tj4G6+6Ey3/q\nzb04DHhJc31cCFHj+HmyEOLRIbxmA9BgNwAE+DtKMJrtDCmdKdXi9mQp5S1SymVSymV1dQWU9h+m\naHM5FFB/yqkVIdqNi2ns6G4cWQsiVKBLp68l072k51PoOJBlTgW8t4TLK82CEEJZC/H0NNc0F5tH\nonGLuM92McUdLqZgGZGY/T/jFwT8AkuCla241EuQWp9Z7fwd6EZ9zjoIUCKVsCCcLiYPFsRAh0qA\nGBi9bgleZKjOjhEAIKXsYAjuHynlAWCfEOJo+9IFwEbgfuBa+9q1wH3FvsZEIpowl1UxVXVZkJ7B\n2FhOaeISC6eeQeykkEVUyhwWRIF1B70t2Xf9UMDCbruYss3Jq3WUTSDALhizXUtDdDHFLEncF0q1\nIOxCOR2TCPp9BG3LO5qtotxLoVyfvft3uuuyWRDR/iwuJg+bOt3bSf8tRgEvKQJxIcRcKeVeACHE\nPNSRo0Phk8AddgbTTuADKLG6WwhxHbAXeOcQX2NCEIklP+wAlSUBeo1AjA09B9StqwVRafug4/l3\nxeEetZi57tYLDC73tkDdUZnXCw0u97aqBS3oct55qIDq7kQsw+W9+R31AMOQ5hr3pccg7EI5p4vJ\n3lhF45ISt9UwnwURjyVdRs7fpbNRHyQFIuIiEF4PJdKi09cCLM7/+GHAi0D8L/CcEOJp++ezsWMA\nxSKlXAssc7nrgqGMOxHRH3btYqosDRgLYqzoaVK3VTMy73NmH+U7UzpbaioUvrD3taguruno4LLX\nw4d6m93nAwW6mLIEuyF1J51wMRV5olzcwgoECch+Rx3EIARLEy6moF8QsH35sWxxCH+eQjktBJBW\n59CtbrUIBB1//4H0GITHQjnttuptzf/YYcJLHcS/hBCvA06zL33WnFE9fojEUy2I6tIgkbhFOBan\nJFCc/9ZQJFogqt0EwrGw5xOIbKmpUFiaazzqXrvgHMuz0LS6L+qgFr8+j0tCXysgVIvrdAKhpOWQ\nsCCKrKSOW1i+EIF4l3IfSaksuGB5wsUU8vsI2huraLZUVyFy7/B1/AFS3X7awtMWX4aLSUCJXSjo\npVBOp83CqLqYvIbCTwfOtb9Oy/lIw6iiXUwhh4sJMFbEWNCdy4LQriEPC3K21NSUcTy4mBKWSJZk\njkJ3/m6CVcw4FbXuC7+zJ9EwpLlavhB+K4qUYEX0YUGlaVlMysUUy9XVNledglMYndaY/n1ktEW3\ng9Sl1clMpEAof5Bap81C8vMxCnjJYroJ+DQqkLwR+LQQwpxPPU5Iz2KqKlX/eCYOMQb0NKlFrsyl\nS0whLSlyBXILyWLKNY6eUyExiGEZx6UGQuOsB9BHfA4hzVX6VZorQDRszy9Ynupi0kHqWK5iudLs\nMYhcFkSwPBlvSsQg+lLbbDjHz3WutzNzaTy5mIBLgaVSSgtACLEceIUh9mMyDA/ReGaQGqA3bARi\n1NFFcumnkkFhWUO53DCJGIQHF1O26mfnnLzMJzoA4a5htESyzCcQyuzFNIQ0V8sXwm8LhKV/X8HS\nVBeTDlIXa0E46xecbr9IX/JvDo7CRLsOwikQ/hJAqrhLNkHsd8Q6xqGLqcbx/aSsjzKMOpG0NNeq\nUvUB6x6eKCbUAAAgAElEQVSMjtmcJiw9B5JnR6dTiIupt0WJg5sbJnG2RAGWyFAXdi+WSLTf2+FD\nOS2I4XExWZbEkhALVhKK9QCSWFgLRHlaFpMOUnu0IDb8XR3kpHEu3M7fZbg3i0BoC8KxpHrpGKst\niJJJo+pi8mJBfBd4RQjxFCBQWUxfGdFZGTyTiEEYF9PY090IM050v68QF1NfliI5jdezJXIVt4H3\n4LIXSwQ7COxcFNORMrcF4Q8OSzdXbQ30l9YTivdTxUAyBhEsIxpxZjHpNNcc4uYUrie+qTYBR1+i\nfu5rU63LZdzFgqhM/hxyWhBd6jQ5jbOdR4njOU60QNQdDZ17c739YSWvBSGlvBMVmL7X/nqDfc0w\nDkikufpTBcIEqUcZKZUF4RaghsJcTL1ZiuScY3nJYuptVSKQbdH2WuCWq3YBvKfeDnYqAchmQQRK\nHDGI4tNcdVxuoEzVo8wQ7cT13AJlKW7ZRKFcvnYbsUFlLXTtS12g+9uSBw2lxyCcAuF0MQ10ploQ\nieNWc1kQtqVSd7QS7EKOih0CXoLUT0opm6SU90sp75NSHhBCPDkakzPkx8QgxgnhbuU+yCoQBWYx\n5bIgQpUFjJNHaApxMWWtg/D43vK5qvyObJ4hpLnqmoZBWyBminasiO0iCpYRjWUKRCzXOe46zbX5\nNfVzT5OqqQAVpK6qV0KWnsXkFGafX1kiOkhd5nQxeajWdloQMp5afzGC5Gr3XWofLVpr91+aYn/N\nB7I4Wg2jTUYldcKCMDGIUSVRRZ3PgvCyY2/NvhiDcld4jUHkHMdjkz0vsQzwIBB5LJGUQrniYxA6\nLheuUMvUdHEQmRKkdmYxeXAxaQviwIbkta4GddvXrtqyp/8u0wUCVCaT3kikZDF5EIj+DmUNamul\nd3TiELksiI8ALwPH2Lf66z7glyM/NYMXImlpriUBP6GAjx5jQYwu+ohQtyI5UIufL5B/EQ33qgUk\n787f48Ke0xJxHD6Ui74Wlbqrg6kZ43h0MeWzIFxdTMVYEOp/IlZWh8THDNGO5UxzTXExJVttZCVh\nQbyavNa5R932t6uEAv271KS7mOzXTmwkMrKYyONi6lCN//TvbpQymbIKhJTyp1LKBcAXpJQLpZQL\n7K8lUspfjMrsDHmJphXKAVSbdhujTz4LQghvC3uuIjlNQS6mPAIBKrici97m7Iu6ng/kb9uRq+Ef\nqID0MLT71taAP1hCuLSWmbQjtUsoUJqoeQj6fflbbYDDglgPdceoa517Vdypvw0qptqJA+kxiDQL\nIlSe3Ei4WhA5iuUGDiq3lP576sSBESaXi+n1QojpUsqf2z+/TwhxnxDiZ7bryTAOSMQgAsnce9Ow\nbwxI9GFyadSnCXoICvfmyRgC+3zjPItxPKaCqrmExmtw2UvQ3NM4zcpl5FZICKktJ6yoyg5yqynJ\ng7YGgn7BYPkM5WKKJtNcY5aFT4DfJxxB6jwWRLgHWjbDERcqq6Zzj/pbxiO2BVGemcWUnpEULEt+\nTkrdYhA5WooPdKjDh/TfYRy4mH4LRACEEGcDNwF/BLqAW0Z+agYvROKZFoRq2GdiEKNKT5PKUc+V\n5uklKNyXx9/vdZz+NkDmcVV5bNuRq3YBChAauxo726LvbPcdjxbfydXRzjtcPoOZoj0ZVA6WEolb\niQrqoNcYRO8BJVozT4JJs5UFoVOEy2tt8bfffyyihCMjBlGRXNgLdTH1H1TCWjpJPX6sXUyAX0qp\nQ+XvAm6RUt4jpfwacMTIT83ghUSQOpD8U1aVBE0W02jT05Q9/qDxsrD35qldKHScfMFuyO/2yhvL\n8JrFlKMGAmwXk6Oba7F9mBwupEjFdGakWRDRWPIExkAii8nDsaMA9cdDzTwlEIlDgdIsiPRGfZpg\nGYmTElJcTGmn6bmhz7cWQv0Ox9rFBPiFEDpCdAHwb8d9xbVYNAw7iV5MGRaEEYhRpTvLWdROvMQO\n8jXYA2+Vy/mK5PQ4kHtOiaC5F6HxIFq5LBHtYpLStiCKW2Z0oVzAL4hWzKRchAn0NSuXlT9IzLIS\nloO3ILW9ww+UwtQj1JGynXuTbTYqalNjEOmN+jTOn51prvksCN3JVZ9OV1E3LiyIO4GnhRD3AQPA\nswBCiCNQbibDOCA9zRVUsZwRiFEmV5GcxkthWq+dMZTLveKl5XevF6Hx4GLyEjT37GLKY0HonbQV\nG6IFkXS7xipVqmuoa2dintEUF5OXQjnbgph2rBKtmnnqvehU1/IpqVlMCYFwsyBsCklzDXer2gcd\nu6msH7WGfVklWkp5o10QNwN4TMpEq0Ef6kQ4wzggGrfw+wR+X9KvW1ViYhCjimUpH7UngfAQg8i1\nGOtxwD0Q6hwH8ge7wZvQ5Nr56/5QuQLnVlztuHNaEI6eRFa0qBRXSBa9BXyCeKX6m5R170ychhdx\nuph0u28vFsT0E9Tt5HnqtvEVdVuuLYh8AmH/vn2B5PfO8bMeSqSPL7UtiMo6aFyTfb7DSM6/gJTy\nBZdrW0duOoZCicaT5rKmqlTFIKSUiCKyQAwF0teidrzZGvVpPMUO8vRhAsfpZDnG6m1RJ8alL1Lp\n84Hcc0oUt+WwRCB/f6i+NpBWnhiEdrVEVBZWkS6mRJ1DwIdlF5aV9B9QriFUvEEXyCUPDPJgQdTb\nAmGPQ+NaZeWUVNnFi9rF1KNuM4LUtiiUTkoN1Dvftxv9aceXVtgxCC/H1w4Rr91cDeOUcMxKcS+B\nikFYEvoj8TGa1QRDuxomzc79OC8xiO5GD7EMDwt7d6NqAZFrg+DFxaTrO3Lt/PWccgqNHseDiyke\nsS2I4s+jBgj6fMiKemLS/v9wuJj0/0xQ10HkbLWRZkFogWjZqOIPQijRjg0oazJrDEILRE3q9Xxp\nrtqC0DGIynoltv0j327DCMQhTjRuURJI/TMmOrqaTKbRoWufup00J/fjdAwi28EwA53QtRem5TmQ\n3ktQuPnVAsbJ4WJqeU3tePMKRB7xa9mkbqcemf0xThfTENJck+28BYFggBZ9WoFtCUTjMiEQiVYb\nsRwWxNzT4OhLYeZS9XPldDVXGU+e2RFyuOvyxSBK005M8Oxi0jEI25obhbbfRiAOcZy7IU3y2FET\nhxgVPFsQFWpRyeZK0M3g9E416zh50kojfdC2DaZnaT2u8RJcblqvxsnnqgzlcTE1rlUur9qjsj/G\n6WoZSpDa0Uoj4BM0SXsRT7Eg1PtJtPvOZUHUHwfX3Jlc4H2+5GagPHVsJRC2RZZRKOdwMTnxOywn\nN9IFQseoRiGTyQjEIY5zN6Sptg8NMplMo0TnPghVZf7jp5NvYdfN4PIKRB4XU/NGQOYfJ9/hQ/Go\nEq0ZS3KPo+eUU2jWqvnkiiukuJiKj0HE4s7zHnwOgdAWRHJTJYQg6Be5W224od1MCQvC8TfJ5mLK\nJhBC2GdOZDvWNC0God10o5DJNGYCIYTwCyFeEUI8aP+8QAjxohBimxDir0KILJ3BDE4iMSvRqE9T\nac6EGF26GqBmjrddNmRfkA9sUGmp+dw5+Xb+B9ap22yHF6WPlS2LqW2rys33JBCV2cex4soS0S6a\nbKS7mIrMYnJaEH6foEnavvuEBSFTEjsCPl/uILUbWiAqalPGJtqvakec1zT657K0GATY/Z5yWBCh\nqqTLLdGP6fB2MX0a2OT4+XvAT6SURwIdwHVjMqtDjIiLi8nEIEaZrn353UuQf+d/YL3aZecVmjzN\n8Q5sUIHQfDERPads82lar269CEQuS6R9u5rrDI8CMVQXk05ztdt5JyyIQKYFoR+Xs1DOjawWhO1i\nCpZnZhiFslgQkNrqPJ2Bg1Du6F9VUj1q7TbGRCCEELOBy4Df2z8L4Hzg7/ZDlgNXjsXcDjWicYtQ\nWpqriUGMMl0NHgUih4spFoHWzfndQpBfaJo8Co2eU9Zx1qmFbqqHzjq5hKZxrbrNZ0EEnGmuQ6ik\ndhTKBXw+GhMuJhVDSBeIkN+Xu9WGG5Pnq9uMGERf5nGjmmxBarAtiBxBameDQyHgw/+GMz5b2JyL\nYKwsiJuB/wH0X2Uq0Cml1FveBmDWWEzsUCPikuZaVWJiEKNGpE/t8AqyIFx22m1b1cKYL7AMuV1M\n8ZhKv/Sy64fcweUD61XvIS+59rlamTfpAPXRucfwO3oSDSXNNdFqQwWpDyRcTGqBjqW7mPwid6Gc\nG1ogtLvHmRHmdlgQJOtX0tNcwYNApDXQnn68ajM+woy6QAghLgdapJQvOy+7PNT1LyaEuF4IsVoI\nsbq1dXTKzccz0biJQYwpiQymufkfm2vnrw+j8WJB+HzZC9Patqpgpxeh0XNyG8eylKvKSxxDj5Pt\n8KHGtWpBy2cROF1MQ0pzTVZSB/wiw4JwdnNVj/Mlius8M+tkeNvv4ahL7LEd7U/cDguCPC6mkuwu\nJt3JdQwYCwviDOAtQojdwF0o19LNQI2jOeBsoNHtyVLKW6SUy6SUy+rq8lR3TgAiLllMfp+gPOQ3\nMYjRIFEDMUQX04ENapftxZ0D2Rd2r5lQmmCFe3C5Y5fqAeTZEsnSH8qylCWSL/4ADoEI2zGIoQep\nAz4fbUyit6QepixM3O9sbhkK+Aq3IISAE9+ZzLxy1qa4HRYEyho7/2tw5Bsz7wuEcgepy8fmCJ5R\nFwgp5Q1SytlSyvnA1cC/pZTvBp4C3mE/7FrU0aaGPERdXEygAtXm0KBRwGsNBOR2MR1YD/WLvbdO\nyGZBHFivgrG56g3S55RtPlCYJQKZAtG+XY2fL/4AqSerWbHiz4OIy8SBQAG/wMLH8lPuh9ddm7g/\nNYtJFB6DSCeYVijnJhA+P5z9BSitzrwvUOqe5mpZMNg5oSyIbHwJ+JwQYjsqJnHrGM/nkCDiUkkN\nKlDdEzZB6hGnq0G1kc7XqA+yu5ikVDt/r7t+yJ5W2rROVVB7DfBms0Sa1qsYwLRjvY0TzCJ+TXaA\nuiALIjLkNNdgWjO+qPQlgvbRdBeT30ckVqAFkU56HUS2JorZ8IdSC+UGu6FjtxIHaY2ZQIzpuQ5S\nyhXACvv7ncApYzmfQxG3Zn2gGvaZGMQo0LlPNenzsiBnCy5371duhPrjvb+u285fC83iKwocJ5vQ\nHJPc1XsZBzLfW+NatTvWZznnIsPFVHwMwlkI5/elBqEjsVQXU9A/DBaEP6Q2CgkLokCBCJRAv+N3\n9/cPwPYnHLUTE8TFZBhecrmYcgnElgM9vP7GJ2juznEOriE/XlNcwVG5nLaIJuIGHt054J591LVP\n7Ti9BpbBPbgspV2T4TH+oMeBVLGREvauVMLnRUCdJ6sNJc01bdPk94mUZnwxSyYsC1CxioJjEOkI\nkRTbcE/uo2fdCJSmZjF17Ve/t6XvVoHw+WcMbX5FYgRimGjqGuDxjaNzypOTiEsWE9gxiBxB6o1N\nXbT2hNnekucAG0NuvBbJadxcOmv/ogLU9cexatdBtjX3eBinMnPnv/KXgIB5ZxY2H0h1V61ZrtpJ\nLzy38HGcVs3aO9S5BSe+y9sYKb2Yhpbm6nQhBX2prTSicSvliN6ATxSexeSGPhMjWwwiF+mFcuEe\n5Za77IfwX3clC/NGGSMQw8SPHtvKx+54GZmtU+cI4VYHAXYMIkehXGe/uq+jP8c5uIbcWHHVVttL\nxbIm3YLY9gRsuh/O/jyUVPK5u9fy48c9HLmS7mLavwZe/C28/kPKNVTIfCApEF0N8OhXYcHZcMI7\nsj/PbT6QfG9dDfCvG2DeGWpOXkiJQRQfpI7EJEGfuwUhpczoX6YsiGEQiFC56shrRYuwINJabYR7\n1DkTY4wRiGHAsiRPb20lGpcMRr1/0O5f18g7fv0f4rk6SeYhGpdZLIhgziwmLRD61lAEvc1qMchj\nQezvHOCCH62goaPf3vnbC3t0EB7+gkptPf1TxOIWTV2DtPZkyYd34hSaeAwe/Izq4XTB1wp7D84z\nIaSEBz6jOs6++WfeKrET4zgsESnh/k8qAb3il6puwwv+AAiffaJc8WmuMSvVQgg6KqW1UARTXEwi\n93kQXglWJM8UDxW4uAcczfosS6UYG4E4PNh0oDvxT90X8R4YXrmjjdV7Oljf0Fn0a2cLUleWBOiL\nxLOKT9eAFghjQRRNIsU1twXx6v4udrT2sbmpJ9XF9PzNqt7g0h9CoIQD3YPELUl7n4e/SchRv7Dy\nFyqofMlN+TvKuo0DMNgFz/4Itj8OF3wDpiwobBydxXRgA/ztWtjxb3jjtwofx1/icDEV3801kGZB\n6P+DRI1EIDWLqeBeTG6EytVJflCEi8lRKBftA+S4EIgxzWI6XFixJVnR3R+Og8cEhsZOtWN4emsr\nJ80tPI3NsiQxSxLyZ+bOOxv2TSrLNNW1MHQYC6J4PBbJtfeq33XngO166GuDx74KK38Fx78dFp0H\nwP6OAfvxHiwIneb653eoRf2oi2FxEe3LdIHXn96mWoYcdTGccn0R49gL4spfKLE49wY4+YOFj6PT\nPYdQSZ3ewDLoEIBoohV4ahZTwd1c3QgOQSCchXJhOwblVi8xyhiBGAae3poUiGyB4d88vYOewShf\nfFPSP9zUpRaEFVta+cyFHgubHCTP3nVLc0027HMViAETgxgyHovk9ILf2R9RC8fOp6B5A5z0Xnjj\ntxOPa7AFonsw5trGPQWdZ79vlRrjlOsLcwlpquxztKumw5W/UgJRzDihCjjubaoe5MzP5j/DOhuB\nEEQHADmEI0dTBcLVgkhr9z08MYgKx3nUhdZB2C4mKVUNBBgL4nCgezDKmj0dnDh7EusbuujP4mJ6\nYmMzTV2DqQLROUjAJ1jX0ElHX4TJFYUdgaE/7CHXILX658omWBM2BiGl6lc00KFSCyvqYFIRfSG7\nGmDPSuXSybPT0y6jzv6oshbCPXDB12H2spTH7e8cSHx/sC/C9Eml2Qc94Z2AgCXXDK1pW/1i+OQa\n1XzOaxW3G0LAO/9Q/PM1/pKkC67oNNfMZnz6f8XZhkMTHC4Xk/P8h0IL5QKlgFSxF21BlGT/XP3z\nlf0cMa2S42cV6FIsECMQQ+Q/29uIWZJLT5jB+oaurAty10CUpq6BRJVnz2CUnnCMS46fziOvHuCZ\nba1csbSwhSqi2xo7d5qde2Hzw5yycQVPhdYQ3fYdmJ6ZjdI1WhZEX7vys08/wXvRlZN4TO22D2yA\nls1qQZ48XzVLq/XYtwhUVepzN8O2x6G7wXGHgLfdAide5W2cxlfgvk+qOYE6qzgPCYEYiKiMnixZ\nPdrFBNDWG84tEFXT4fRPeJtzPqYuGp5xhgN/MBlbGcKRo6nN+JIWRGwkXUwhh0AU42ICFaAP57Yg\npJR84W/ruP7shUYgxjtPb22lqiTAmUeok6X6I3HXx3UORLGkshrmTi2nqUvFH9503HQ27thN36o/\nwZTzYO6pnl87xZ8aj8ELv4SnvguxAaorZxETUWY+fwO8/qKM4KWOQWRYEPvXwK6nYd9LKnC59Brl\nJ9e97L1gxeHJ/4ON96mFGdRu6OhL4PUfhjmv9zbOYJfysTesUj8HyuxMD6kCmNc9poQiH+074PbL\nlOl+xPlwzv8ot1BsEJ7/mcrcmbEU6vK4+XY/B3+5Wp0I9sZvwxEXeqoQTrqYcltr+zsHEu6Qg14C\n1YcjgZJkllfR3VwtykPJpU2dGKf+VyJuLqbhzGLSFONiAhV/yWNB9EfixCxJtYvreLiZuAIhZXG+\nVk08iuw5wL5NL3HWohMSfv5cFgTA3oP9zJ1aTmPnAEeKBs55ZTmX828CjVG47buqOOncr3gSCr3r\nqRncD797t6p+PfoyeNO32Rer47M/uZ37xdfhyW/BZT9KPM+ypLsFsfKX8OhX1PdTFqmUw/s+Do99\nTT3/+Lfl/71YcfjnR2H9X+HIN8HJH1BFPtufhM0Pwsb71WEn9YtzjzPYpQKnTWtVls+i82HyAvUP\n1LFLCce918NHnk3duaXTtg1uv1yZ7h96IvN1Z54EvzlLZd586MnsY219FO5+H9TMg/f9U7XX8IgO\nUuvfeTb2dw5wdH0VG5u6ae/zEKg+HPGHkgWARae5SgJpAhC38rmYxtqC0I0KB/NaEN12fZNbbHG4\nmZhprgc2wK0XqXL2QomF4a/vgf9Xi7j5eP4c/Rw3tn6cmha1y+13EYjBaDzhDtrXoT78A/vWcXfo\nW1S3rGLXgmu4Mvwtmk79mjok/rY3we7n804lEreYJw5w7sr3K9fSVX+Eq++AKQupKQ+xQS5kw+xr\n4KVbYe+Lief1hGNYEipCfroGosTjFjz9AyUOi6+AL+6ET62BT7wE1z6oFvgHPg09eSrFrTj882NK\nHM7/Krz7bjjzM0pYrvwlfHyV+tD/7drkub2ub6wvKQ5X/RFO+bByg/h86uD5acfCW3+tOoU+/vXs\n44R7YPmbVV7/+x90F6XqmcrF1LIJ/vVl93GiA0qMao+CDzxSkDhAWgwiC5Yl2d85wImzlaWnRWXC\n4Q85XEzFxyACvtQgdSzNxZTeamPYspg0RQtE2GFBuAuE3mgYgRgpwr3QugVuu1i5H3Lw3Uc28YRu\noRGPwd8/CJsegFM/ypol3+SG6HVUyj6q7rqCHwR+Q3848x/buTDsPdgPBzZw7gsfpJ8SrA/9m5q3\n/pC18gjuKbkCPvWKygR54pvKyslF23b+Gvp/+OODagFcfEXCKqqtLGFRXQU/k1cpd8qDn0n029Hu\npfm1FUgJ4Wduhqe+DSdeDW+/LRn0FAIWnAVvv1XtbB7PU4S18hew/i4476tw9hcz76+qh3fcqhb2\nBz+T/f29vBz2r4Z33AbHXOb+mAVnw2kfh5d+p5qaufHqPdDTBO9cnrsr6REXwKkfgVf+pJrvpbPx\nPtXj6E03FhwQtizJQdsa6BzIvui39YWJxCyOmV5F0C+81UIcjgyTiynkyOwL+pK9liJudRC+Ik6U\nc8MpCsFC6yAcVeT5BMJeT6pLjUCMDPPeANc+ANE+rNsupmfPWteHtfeG+e3TO7nx4U1YsRj887+V\nm+SS78MlN/FP30Xc738jvk++BGd8hncGnuG4XbdnjON0LRxsbYLlb2FQlPKJ0LcI1i6krqqEpXNq\neOTVA+pDcc7/KL/71n9lfw/xGLMffi8B4qw570+uraLPPXoaz+wZIHL2DeoYStuXrwVrfm0FIaKU\nvPAzOOIiuPLX7pkjtUfAGZ9WlsGuZ93nY8Vh1e/Vwn2OizhoFpytXGgb/gYb/p55v5Sw+jaYtSx/\nV9ILvg5Tj4RH/9f9JLPVf4Bpx8G803OPA3Dax+znuHSZf/l2ddjM/LPyj5OGjj0FfCKnBaED1LMn\nlzO1osRbLcThiD+UzGIaQpprpgVhu5himZl/qtJaDr1NjrYgghXeq8c1ATshITZoN/urzJpVZiyI\n0WDmUjredT9t/XF6//AOWtoPZjzkpd0dAOxq62Pb47eoRe2Cr6vdJrBuXycnzJ6Ev6QCLvwm/+J0\nztz3W2h4OWUcvWMP+X0c03Q/DBzkB5O/iaxJVplefuIMXmvsZldbH5z0HhUDePJbauF1Y+sjlPTs\n5X+jHyQy1X13fM5RdURiFi+E3qA+gK/eo+Zjf8AWTK3gjb7V+MMdcNpHc3+oz/q88r8/9Hn3k6+2\nPwlde2HZddnHcI5VfwKs+I6yypzseR7at8EyD0VWwVI498vQulkJt5PGV5SL6uT3e4s1TZ6numa+\nvNzOw7dp3aI6knodJw1tPcybWk7PYCxrvr1OcZ01uYwpFaGJ7WLSMYghpbk6K6UdLibLzcUkUu4r\nGh2DKNS9BKmHJQ125ayB6LZb6BiBGEEGo3E+9HA3n41+ghm08u/f38BAWgbSql0HKQn4qK0IUfrK\n79Vu9MzPARCOxdnY1M2SOfYB5ELw49BH6Q7Wwj3XJc1Ekop/zPRKzu9/BOacxgv9s5hZk0xjvPQE\ndeDMQ+sblWl9/v+qXb/bLhvgpd8TLp/BE9bJWQuqTlkwhdKgjyd39qtjDl/7B8RjKS6mq/wrGCyf\nCQvPy/0LC5bBxTdB2xZYd2fm/S//ASqmZXcJOfH5lJV0cCe8mvb+Vt+mMq6Oe2v+cUA9bsoieOYH\nqS6rl29XWU9e01cBTr1eVRO/eq9jnOVqJ7vkv7yP46DNXugX1amslu4s/bG0BTFrchlTK0O0TVgX\nUwhitkAPIc0148S4XC4mW0yGHIfQbqViBMJ2Mf3hmS1Yg7kb9RkLYoSRUvKle9bz8p4O3v2uazgw\n9828tf8ebvzzQ1iOXcSq3e28bu5kPr+4k3mRHbQfd21iF7mpqYdoXLJ0dk1y3NJJ3Fb/Fejco9JN\nbfQf9M2TdjKPJgaXvJfGrgFmTEqmjs6sKWPZvMk8uL5JXVj8VnU+wNM3ZVoRbdtg5woaj7iGOH7X\nbq4ApUE/b1g4VVV6H/921Uhsz3OJ+RxdepAzfa+yc/aV3kzioy9R6aDP/SR159/VoNxhJ73Hu9/4\nmMuV4D7zg+T7621VWU5LrsmdmeTE54ezPqcyuLY9rq6Fe5SwHv92lZLqlQXnqLTVVb9VYhMdhHV/\ngWMvL7oyWFsCi6YpgchWd7K/c4Cq0gDVpUFqK0sSlseEw+8oFh1CDCKYdmJcepA6lFYnoZ43XBZE\ngSmukHAxPfXaXgZ6Oz0JRGXpyCehTkiBuHv1Pu5b28gX33Q0l54wg+nv+AEiEOScXT/h7tUqSNk9\nGGVjYzenLJjClZGH6Jbl/L4zWfm6dq9yPy2dm1yAyksCrPMtVrvatXeoBYbkH/SNAw/TKStYV3Ue\ng1GLGWmFUJefOIPNB3rY3tKjFuyzv6B22ZvuT30DL90KviD75qsCOLdKas05R9Wxu72fPVPOUB/c\nV+9N+MIXNahjv9fXetj1gxLHs7+g0kxf+0fy+po/qQX15Gu9jQNJK6J9e3LHvvYO1aTt5A94HwfU\neQOT5sDT34OdT8NT31GBzpPfX9g4QqiMqaZ18JerVKbbQEfh4zjQ6aragsgWh9jfMcCsGrVhmNgu\nJkNnOEgAACAASURBVEcx5VCa9aVZEOlprs77tQU+5HYb2nIotIoa6Iio+YSIIQe7c1ZRdw9EqSoN\n4PcNIU3fIxNSIK5YOovvvu0EPnauXUFaPYPgeV/mIv8aNq64GyklL+/pwJJw5vQ4ZdseZPXkS7nj\nlTb67DTWdQ1dTKsqYXp1cpGvLPGrNNfXvU9lvdh+8a6BKLWiiznNT3Jv/CxW7lNBuJk1qcVnl54w\nAyHggXW2FXHM5cp98tzNSfdJpE8dMLP4CvqC6hjCXD17zj16GgArdvWpqt9N99Pd2091iY+yjXfx\nvDyeBlnA7vjoy6DuWNX507KU9bBmucoEmjzf0xBxS/LzJ7fRMONCNdbDn4cfHQtPfAPmnl7YeQag\ndppnfkZlPv3xLfDCr1RA2dHKYmdrL79esSN/IPLEq5WV1LFHubpO/SjMP7uw+Tho742oZLBatbvs\nypLJtL9zgNmT1edhamWI/kg8w+U5Hnl5Twd3v+SS+VUsAYcFUWyaq+ViQSSa9WXWQeiAdjYLYt/B\nfn782Jb8bfmzuJgeWt/EQ9ozkIV/bVYx0BBRRJ5W390D7v3VRoIJKRClQT/XnDIX4Qg6itM+SnfF\nAj7U+xtWbWtk1a6DBHyCpa33gRVl+oWfoHswxi3P7ARUgHrJnJqUMcpDqsU2889WAd01ywElEO8p\nfQ6fFeWO+AWs2qU+DOkWxLTqUk5dMIUH1zeqhcznh9M/qYKtu55RIvHczRDuglM+7FoVms782grm\nTS233Uxvg4EOLtz1Pe7yfRXR1cBD/gsLa7fh8ymXTusmVRD3i1PUISlnftbzEE9uauZHj2/lgfXN\nqkX1jCXJAsG3/977XJyc/AF41x0qO+1Tr8B7/5kSVL7lmZ1871+b2XdwIMcgqN3fR56GT6xSqcOX\n3FR4RoqD9r4wNWVBplaonbEXC6LWfqxbsdxoH0iVj+X/2c1X/rGBjuGKmQyLi0lmxiASzfpcXEx+\n7WJytyC++s9X+dm/t7Nhf1fuF84SpP7x41v45J1reGpzi+vTYnGLe9ephp8lRPFFe3NaEF0D0VFJ\ncYUJKhCuBEKUXvFj5vpaaf3X91i16yCXTu8iuPoWWHQ+i48/ictPnMFvn9nB5gPd7GzrY+mcVP92\nRcivLAyfD173XrWoH9xJxcGNXC/vQS44h+bQPNbY7ql0CwLgshNnsqO1jx2tdi74kmtU8PfZH6na\ngWe+r7pmzjk1UXyXLQahOeeoOlbuaCc2/1wom8JpnQ8R9AFv/DYvVZxdeMO+496mrIX1d6mzcj/+\nAsz3fszl8pW7AdR52AvPVYv6W38N536puMZ5oMT02MtVGu2UhSkZMFLKRMfdtUM4e6MY2nsjTK0s\noaZc/UO7/a67BlRfrlmTky4m/Vwn4Vic19/4JFf9diWbmrpHeObe6OiPELMkj752YHgGdApEEUFq\ny5LErdRCuYDjyFH9P5PiYrL/f9yymFZsaUl8dtbty/PZSVgQSReTZUkaOgawJHziL2tc/26PbWym\noccWLhHDH+3NG4MwFsQYEDrqfDZOuZCL2v/CzIZ/cVP3l9SH9OLvAfCli4/BkvDRP68ByBSIkkCy\nm+vSd6tWFc/8iA833EC/rxLx1t8ye3IZg1GLgE9QW5nZvO6MRaoQa80e+8MYLIXT/lv1R3r5dpVF\n9fZbQYjkbihXW2jg+JmTGIjGaeix4Pqn+O/a2/nmjF/C6Z+kpqK08IZ9/gBcfSe85174r7s9u5YA\ntrf08Pz2dgAO2P2oRpptLb2J3ld5/8nzMBiNc8szOwjHvLl/2vsiTK0IUVUaRIhkirGTRAZTjdqB\nTq20BSLNgmjpDtPWG+al3Qe57GfP8q0HNqYkVYwFOr72oMOF0tQ1wB+e31WcteNs6JglzfUvL+5V\ncToXolZmA0tnmquer3MHrsUiPQYRi1vc+NAm5k8tp7ayJOtn57XGLv7xSoNrkLq1N0w4ZvHx8xZR\nWRrguttfoqUn+bmXUnL787uZWqOeU0qEYKwvZ4fg7iwt/EeCURcIIcQcIcRTQohNQojXhBCftq9P\nEUI8LoTYZt8WfoLOMFBz5feJ4ufnwZ8iQpXwwUcSTdzmTCnnujMXqFoF4ITZqQ3wKkoCyV5M1TNV\naunaP1Nm9fGTuv8H1TOYO0V9iOqrS12DTPOnVlBdGuAV54dx2XWw6AK48jdw4TcSLo+IvUjlClID\nLJqmdjY723ph8ny2hSdTU6YWocnlweIODapfrOIOBdYGLP/PHkIBH8fNrOZA9+gIxIotyrSfO6V8\nyALx9NZWvvPwZh59LU/bEZv23jC1lSX4fYLq0iBdLmLsrIEAEhuHtjQLotn+fd38rqVctWwOtz2/\niwfWNxb9XoYDbRH9Z0cbbXZx3w33buD/HtjIjta+XE91J48F0dUf5Sv/2MC7f/+i6wbDrZVGwJfM\nYursjxDy+ygP+VPuh2QKrObOVXvZ1tLLDZcey9I5NVmtz6/841U+f/c69nVbKsjuyJzbd1DVdCyb\nP4Vbr309Hf1RPvzHlxmMqv/dX63YwardB3n36UcCUOfvReQ5Ta5rIEp12ei00RsLCyIGfF5KeSxw\nGvBxIcRi4MvAk1LKI4En7Z9HnZlzF/G3aZ/kBetYotc+otwVDj527iJqK0MsqqvI8ANWhAIMRq1k\nMOu0j0LJJL5V8gW6JqnA6xxbIJw1EE58PsGSOTWpC1lZDbz3XtVZ1UGim2seC2Jhrdqd7GhR/7Bd\nA1Em2S6PSWUh10VrJOgejHLPmgbefOJMjp1RnVjwRpqnt7ZydH0VFx5bz4b9XUPKd9euv5d2ZRZW\nutHeF0m4jGrKg64WhF5EdAxCWxDpHV1b7GNtj6qv4jtvPYHjZ1XzvUc25wxmD0bjnPODp7h/3cgI\nSWd/hFMXTMGS8MirB3h6a2vihMWNxbjB8sQgdrSp339zd5jrlr+Ucf6KWxDa73AxdfZHqSkPpsQO\ndVsOZ7uNuCW5+YltnLZwCm9cXM/SOZPY2dqXaHOhWbuvk3X7OrEk/HnVXtXI0XEin+69NmdyOcfP\nmsRPr17K+oZOPn/3Oh5Y18gPHt3ClUtncvUblEBMD9iu5YnqYpJSNkkp19jf9wCbgFnAFcBy+2HL\ngSLOTxweLn7P5xn4r/uprp+XcV9VaZA/vP8UfnTV0oz7KkrUriTxoV14LnxpF49GlyR80NqCcNZA\npLN0Tg1bmnvyZrF4CVIDTK4IMaUixM62XqSU6p/E/oAVbUEUwT0vN9AfiXPt6fOYXl1KS084f2bI\nEOkLx3hpVwfnHF3H0rk1hGMWWw64uye8sNPeFa/yIBDRuEVnfzSx4NeUBV1jEK82dlFbWUKt/bjy\nUIDSoC+j3YYW1PrqUnw+wVcvW0xj1yC3PqcSJ9p6w9y1am+KAG5q6mZPez8rd7QX8W5zE7ck3YMx\nTl04lUV1Fdy/dj83PrSRuVPKCfoFGxuLEIhA7jRX/fv/2uWL2dTUzWfuWpviykq2wE+tlNYWREd/\nhMnlqQdzaQsi5mjXsq2lh/a+CO96/RyEECydoxwa6/enWhF//M9uKkJ+zjmqjr++tI/BmadCRW3i\n/r3tuoWK+n9/43HTueGSY3hoQxOfvPMVTp43mZvefiLCft/TfLn7MIVjcQaj1uErEE6EEPOBk4AX\ngXopZRMoEQGmZXnO9UKI1UKI1a2trW4PGTIzJpVx3jGuLw8o11J6/AFI9KDvCycXdil8KYo/Z4r6\noMzIYkEALJldQ9ySvNqYO2si14ly6SysrWBHSx+94RgxSyYEa3JFiIFoPGHyjiR3r25gyexJnDi7\nhvpJpcQtOeI9h1buaCcStzj3qLpEUeO6IQSqtQWxpbknb+aOju1MtV1Gk8pDrhbEun2dLJ0zKWVX\nq/oxZVoQQb9gsv23O23hVN50XD2/WrGDXz61nfN+uIIv37uBhzck4wFrbUs0kfQwjHTb72VyeZDL\nT5zJS7s72Nrcy1cuPYYjp1UVZUFEpKP/kItA7GjtJeATvO8N8/jyJcfw2MbmREwLnHUOTgvC6WKK\nJj77Gh2DiMSSQqMt+CX2Z0a7k52WfVtvmAfXN/GOk2fzsXMX0dkf5f61qZbavo5+6qtLKA0m39eH\nz1rIB86YzzHTq7jlvSer+4QAf4haoVt9ux8E1D0wem02YAwFQghRCdwDfEZK6fmTJKW8RUq5TEq5\nrK6uyHNvRwhtQfQ5zN7ecIy4JRM+f21BzHLJYNLo9h35/OWRmGopIDzEARbVVbKzrTexg9XzyZVd\nM5zsaO1lU1M3b7FPzdP1I01DDFR/5E+r+Z2deuzG01tbKQ/5OXn+ZOZMUX2Oio1DSCnZ2drHMdPV\n7u6l3bmtCL3AT61Ixns609x53YNRdrRmZsTVVoYyOro2dw8yrao05e99wyXHEo1b/ODRLSydU0Nl\nSSDFutHvdWcx8YA8aLGrKQ/y5iWqVcwpC6bwpuOmc9zMajY2dhUcqF7T2J/4PkZms7qdrb3Mm1pO\n0O/j2tPnM7UixO3/2Z18TpYT47SLyc2CCPozLYi1+7qoLg2woFbF7yaVBVlYV8HafclN212r9hKJ\nW7z3DfM5ZcEUjplexe3/2Z3ynvcd7GfO5NSuAEIIvvHm43jk02clNg8ABEqpIfdZEIkg++EsEEKI\nIEoc7pBS6sY3zUKIGfb9MwD3pOFxTEXCgkgKRHrflEV1ldz0thNyHi9aV1XCrJqyxO4vG+ktBXKx\nsK6Ctt6IajcOiRiE/mcZ6aNHH1rfhBBwmd1zSgvEUALVTV0DPPpaM09udg8YSylZsbWF0xdNpSTg\nRwjBktmT8v5es9HeF6FrIMqVJ82iJOBLWYj/vbk5wz+dLhBuLqb19oKzJE0gplSEMrKYWnvC1FWl\nZr7Nr63g1+8+mdvev4w/fvAUls2fnCoQDWr8tt5w3gOLCkWLXU1ZiCOmVfH9t5/Ij965BCEEi2dW\n09YbobXHu4UopeTpHcm94o6DmZ/JHa19LLSr0ksCqp7pyc3NiTiOzmJyupj8PoElVcppR3+UyRWp\ni2tCIOKpFkR6ndPSOTWs3deJlJJo3OLPL+zlrCNrOWJaJUIIrj19Phubulm9pyPxnH0H+xObwnQy\nNnb+ENWWLUATVSCE+q3cCmySUv7Ycdf9gO7VcC1w32jPbahUlGS6mPSCoP+gQgiuPmVuXhNx6Zya\nvK6QaFzmTXHV6FYPa+wPr45BaAtipAXiwfWNvH7elMQ5y/WT1EI3lED1M3Z+erZsmXUNXew7OJDi\nLlwyp4ZtLb1ZT/7Lhd6FHzO9ipPm1vCivRA/u62VD96+OhEL0OgF3uli6h6MpsRd9N/4xNmpAjG1\nMtPF1Nw9SH11Zmr0hYvrOf+YeoQQnLJgCttaemnvDdPZH2FXWx+vs9vB7BxmN5O2IPRm46rXz0kk\nYSyeodI0XyvAzfTCzoPs60r+XTY09afcH4tb7GnvS3yWAd592lx8QvDnF/YA2U+MA1Xn0NkfoSbN\ngtD/C4nDvCJxtjT3ZFh1S+fU0NYbprFrkG8/uJED3YN88MxkR+Yrls6kIuRPuJkiMYum7kFmZxGI\nDAIlVMTHz2lyMDYWxBnAe4HzhRBr7a9LgZuAi4QQ24CL7J8PKRIuJsfi0+0wwwthyZxJ7Ds4kNNH\nH44VZkEAiSK9yQm3h7rt7I/SPRjl0p8+yyk3PsEpNz7BZT97Nmv1ZyFsbe5ha3Mvl9tuCFDVwgGf\ncE1VXLXrIJf//NmU+wajca76zUqe3ZaMO+lsmdaecOIfx4kOIL5lSfIEuCVzapASNjTkqYp1Qfvx\nF9VVcsqCqbzW2EVXf5RvP7gJgBfSAtduFoSU0OOY69p9nSysq8j4h59aqfoxOd0VLT1h6quzx64A\nTl2g2q+8tLuD9fZ7/P/tnXd4nFeZ6H/vzKi3kSxZXbbcWyTbsRU7JtgpQBwcAktJA8ISCHAJEGCX\nFLh3Ye8+D7sPWVi4a8KybAjJhdCSLMHkJoEUJySOW2LLJXGRLVtWsZpHvc+5f3xlvpFmpBn1sc/v\nefRo5tOnmXPmfHPe7+0fWltkjn9yzUxttrly5LW9vMAQENE4qn/xejVxCYH5VdYFj7fmQg8DQ8q+\nlsHwF75vZS6/3ltDV98gL7xtXK/Do5jAaNg06Fe2D8di3pxkFs1NtcthHK5rY8ivbP+DhfX8gScP\n8YtdZ/jsVaVcvTRw85Ec7+Hy+Vm2Blfr60EpwmoQI3DHGyGuwFB8GAERIo9jKpmJKKa/KqVEKVWm\nlFpt/jyjlGpRSl2rlFps/o4sjnAWYTupHT4IX8/4JH55BA7VgSF/RA5qMMJr49zCm2eN1wtEMQVM\nTL/bd46j9e28a3E21y6fS0//EH/7yF7ufGQv5y50h33tN061jAg3dLLjYB0uga2rAgLC5RJy0xNH\nmJiqm7u467F9HK5tDxIGh2vb2FPdyg//csKe+19PNNt31MNt7E4HYprjyxSNo7qrb9AWqMZ7dJLg\ncVHoTbJDO+99opJj5ztYkpvKgRpfkLO/pasPt0vstR/u71FKcaDGF1QR2CI7JYH+Ib+t6fQODOHr\nHmBu2kgNwsllhV7b/HWgxocIbLssH49LxtQgGtt7each8g3d0jqH35GDsYGVZCWHFBBNHX0jIslq\nfT08f7SBjUsCwvxgXfA5pxwC2sknN86nrWeALQ++zPeeO0ZFaRabFgU6/1k5Ec0dAZOYExFhW1k+\ne6pbOd/eG3BQD9MgluenE+92sfN4E9ctz+W+rSP7sFxRmmUHMFhmr+LM8P7GIDwB4djhD73O01nq\nG3Qm9aSSapqYuh3hqeNd0MuKMnAJQU6x4Qyvez8acW4XJVnJI2yY1qbV2tnPY7uquXxeJt//2Gq+\n+zdlPHvPu7l/6zLeONXCbf+5e0RcPsC5C93c8tM3+Nxj+0PmFyil2FFZz4YFc0bYz3PTE4K0hLbu\nAT79yF7AKFvi9BVYj/educDh2jYO1Pjo6BvkExuMUOThm9/juwMORCeZKfEsyE7h9QjCPn+ys4oP\nP/S6/UWvauqiNDsFl0tYU+LF4xKePdJAxfws/u69S+kf9Nt37WDkMWSlxOMyNyhbQJhrUN/WS1NH\n34iNCEaW27Bs+XPH0CDiPS7WlmSyp7qFgzU+FuWkkpkST8mc5DEjme578hAffWhXxOY323wapuz0\nivz0kJFMX/vtAT718z1Bx/5y9Dx+BZuXBwTE2409Qdp4QIMLrnV0RWkW5cVe3CL86NY1/OauDfbN\nGgQERJOpjYfS5reV5aMUPHOonrdqfBR6k0Zcr/EeF+tLM7nMzGcIlehaYWtwrbbJqmROpCYmY807\nVSJtfaFzdWwN4iJOlLtoSQ5hYmobp4kpOd7Dktw03nLcwQK8dKyRLz3+lu0oi9QHAYE7r6Q4tx12\nlxjnJjHOxR8r66hu6eaTGwO5H/EeF5/bvJDHPnMFDe29fO6xfSNKTFgayasnmvmHp48EmUT8fsX/\nfeMMp5q72FZWwHDyMoI1iK//7gA1F7r56SfWsbok2AdzoMZHdmo8SXFuHt1VzcvHGnG7hFsrSvC4\nJGjzGxjy88vdAQficN67Mo/XTzaPGab64juNKBUoI3GqqdP+DJPjPXbo47e2Lbc3hj2nA4KnubPf\nNi+BkZQIAeeudacaKmTayp2wspOt8gxjaRBgbFJH69rZW91qC5+FOamjRjJd6OrnleNNdPQN8tRb\ntfbxN061cOcje0OWFjGKxnmCQkqdrChIp7qlK0jgnGzs5NUTzdS39QZpWzWt3STGuZibGSgx0a/c\nQQXyTjV1MSclfoTGIiL85q4NvHrv1XygvGCE89dtjq/ZFLKZKSM1nkVz01iWl8aOynoz7Dh0H5GH\nP7WeJ75wpe1vHE5ZUQbxpgZ3trWbeLeL3LTRhXpgoMbadpJkh7MOp61ngMQ4Fwme0O1IJxstICaR\nlBB5EL7uAeLcQlJc9Au6aVE2u0+1BkWf/OTlKv54sI6j9e1mmGvkS2hFfwwXVpnJ8Rw/30lOWkKQ\nGchibUkm//rRcvZWX+D+Jw4FCYGDNT4SPC4+e1Upv9p9lgefP8YLb5/nT5X1fOjHr/E//3CE9fMz\n7TBIJ7npiZw3NYiO3gFefKeRz1y1gIrSLFYXe3mnvsPeRA6e87F+fhYfWlvIHw7U8cyhBi4vyWRO\nagIlWclBm9/zR87T0N7LHcO0B4ttZfkM+hXPjlJgrrGjlyOmeWRHZR19g0Ocbe0Ounv9yrWL+c4H\nVlJW5MWbHM+yvDTbcQ1GmQ1ro3d+7tZ6HjjnM9rQ5o+0N8+bY5ZHMed1vr3P/szGwjJ/tfcO2gJi\nQU4K1S1dYXsePHekgUG/IictgUfNUM3+QT8PPHmIF95p5GAITTaUw9fJyoJ0lIJ3HFrEY7uq7cd1\nvkBl3VqfUc3WShhTLg8gQSHJp5q6gvwPThLjwjfOirNMTKawHe6DsNhWls/+Mxc4d6GH8uLQeQgJ\nHveoN2UJHjdrir3sqW7lXGsPhZlJtgY5JubcO1Ry2Iiz6cyiBi0gJhW3S0iMcwX5IIwFjY8oV2E4\n7y/Lp3/Iz1+OGmGc59t72WPG3u883kT/sN67Y2FtbsMvMOtLfltFSdiL/8byAu65bjFPvlXLG6eC\n4+wvK8zg/q3L2boqj+0vVXHnL/bxxV+9SX1bLz+4uZzffm5jkB/AIi89ka7+ITp6B9hn9t+4apGR\nhVpe5GXQrzhS105LZx81rT2sLvZyx8b59A36Od3cxealRh7MgpzUIA3id/trKPSGT3ZcWZBOaXYK\nO0apY/TK8WYAPrSmkCN17ew81oRfBYQsGL027rhyvv28ojSL/WcuMDjkp617gBONnUEZ85bfxzLN\nHDjrY3lBesi7wXlZySTHu20TTWN75BrEmpJM26xi+TcWZqcyMGRUFg3Fjsp65s1J5hvvW8qJxk52\nVbXY2h8Ea0YWvp6RSWdOVliOanMOHb0D/H7/OeabJpfa4QIiM9kutSGuOIqzgkO9qxwaXDS4hwmI\ncELNqeUOd1BHwxWlWRyubePt+nY7qisiPAENQguIi5SUeM+IKKaMcdoL1xR7KfQm2RvZM4fqUcoo\n5vbysSYGBqMzMYXXIOLwuITbrygZ9f8/c9UC4tzCy8eNSJGBIT+HatsoL/bicgnbb1vLn778Lp6+\nexNP372Jl/9+Cx9aUxRWOFohr+fbe+3+G2tKjJIGlop/oMZnm5rKi70szUtjwwLDnLN5iSEgFuak\nUN3SzZBf0TswxK6qFt6zIjdsxy3LKbmrqsW27f9q91nbAQ5Ggb/s1AT+7n1LAfg/L5403yv8BlVR\nmkV3/xBH6tr50Ysn6Owb5E5HGGSGQ0D0DQ5xqLaNNWFMGS6XsDw/3XbynrezqMPfsVskxbttU4el\nnVgFG0P5IZo7+3i9qpltZfncWF5AVko8//7SSX74wgnetSibpbnBmpGFr3v0zSovPZHM5DieO9Jg\n1OHaf46u/iG+cb1Rl6zWIazOWf0wrI5y7jjKiwI1yXzd/bR09Y9LQFg3UdZah4q6AiOnZFVhOi4Z\nWYgzGipK5+BXcKq5K3IHNdhz71BJIaPywMiknq4IJtACYtJJSQgWEL6e/nFLfGsje/VEM77ufnZU\n1rMsL42PrSvizTMXaO3qjziKCQIaxPAojlsrSnjghuVjOkBTEzysm5fFTjO89FhDB32DftuM4XIJ\nKwuMUhplRd4gR2EonNnUe063UlaUQZJZZXNueiIFGYkcrPFxoKbN+NIWGl/ae69fxic3zrNj7Rfm\npNI/6Kf2Qg9vnGqhb9BvaxfheH9ZPn4Fzx6uZ0dlHQ88dYgf/OU4b5xqYcivePVEM5uX5FBo9gq3\nbOGlYUwcABXzDcH16701PLqrmpvXFbM8P2BT97hdpCV68PX08+jrZ+juH+K65blhX89y8vr9isb2\nPnJSEyI2V3x+80K+9p4l9uZoFWwM5Yd49nADfmXcQSfGubllfTGvV7XQ0TvAt7Yt54oFAc3ISVvP\nwKgmJhHhM1ct4PWqFq558GUe2lnF6mIv71mRi0sCGkR3/yCtXf1GvSKrQJ/Lw+piL3VtvTS299oh\nuuFMTKMR0CD6SRvFZwLw9fcs5SvXLhnz2h2NtfO8tgYXcYgraA3iUiA53m10lTMZ60s0FtvKChj0\nK37+WjX7z1xgW1k+m5fkMOhXHDvfEXEUExiqdaE3aUSjohvLC4ISfkZj89Ic3mnooKGt176zDxWm\nGQmWBlHd0k3lOR8VpXOC/l5uJgserPGxJDfNdgyuKcnkH29aZW+W1qZR1dTJzuNNJHhcbFwQ/FrD\nWZqbxqK5qTz8WjVf/+1B1s/PpCAjkX/601HeOnuBtp4BW8hsKwtkf6eGcU6CIdRKs1N4fM9Z4t0u\nvvbeJSPO8SbHcaqpix+9eIItS3N41+LsEK9ksLIgnc6+QWoudNPY0TumAHfy3pV5fH7zQvu5VbAx\nlAaxo7KOBTkpdgmR2zfMI85tJHQuy0sP0oyc+Lr7w96NW3zx6kX84YubKM5K5nx7H3+7aT5xbhd5\n6Ym2BmH5Igq9SYFifS4P602B+9lH99la9Pg0CDOKqaNvTA3s6mVz+cp1i6N+DyfJ8R5WmTcz4zEx\ndaF9EBctqc6mQYytho/FqsJ05s1JZvtLholjW1kBa+dlkmZuVNH4IACe+MKVITeuSLHMOq8cb+LA\nWR9ZKfF2AcJosRyuzx6uZ2BI2UleFuXFXs60dLOvunVUm7C1aVQ1dbLzWBNXLJgTVBwtFJZ2drq5\ni7yMRP7jE+u4d+syDte2882nDuOSgD9kq9krPJK7V0uL+B9XL2JuiOgVb1I8O4830d0/xLfePzKO\n3skKR7JZY3tfRP6H0ViQncKppi583f1895m3ufORvXz6kb3sPt3KtrJA9E+hN4nn7nk3375xZdCc\nnCU8/H5l3vyMfW2XFXl54vNX8vxX320nLRZlJnPOFAyWX6Qwc5iJqdjLv928mrq2Xn7+WjVx38/r\ngQAAECNJREFUbrGrokaD26zW2tzZF9ZBPdlY13JUGoTpf+n3pIQVEO29A9NWZgNgeoJpLyGSEzxB\niztRiW9tZNtfqmJVYTrzzeJhmxZl8+yRhqh8EBC4ax8vy/LSyE1PYOfxJk40dlBelDEuBzwYkSfe\n5Dh2VbUgApfPD+4RZfkhuvqHWF0SXkBkpsSTmRzHzuNNnGru4uMbRpZpD8WtFSWcaOzkq9ctISsl\nnhvLCnj4tWoO1vhYU+K1wyFz0xP5wuaFLMkNX6Pf4mPri+jsD/Y9OLE21NuvKGHR3NFfb0luGm6X\ncLS+nfMdvXYo7XhZmJPKHyvruOZfd+Lr7mdZXjouF1xeksnH1hUFnet0xlua0e7TrXz23UZ/lI7e\nQfwq8vwel0uCPr/CzKSgjGMwNQi3+d0xK7l+cE0h1y6fy49frgIY1TwUDqtaa2t3v31nP9V8+PIi\nzl3oYXFuFBqPmSg36Em18x2cDPkVHb2DWkDEMqkJburNC95a0ImqhDeWF7D9paqgkhGbl+YYAmIc\nX5iJICJsXpLDM4ca6Oof5IbLRoavRkNeeiK+7gFWFqSPcL5dVmgkC/rV2FElC3JSefWEEXk0lv/B\nIjc9ke23rbWfu1zC/9q2gg8/9DrXLA2OgLIcq2Nx+bwsLp8XfiOfm5ZIWqKHe64bW4tLjHOzKMfI\n0PZ1D4SswxQNy/LT+M2+IVYVZPDtD6y0NZRIqJifxbNHGvD7FS6X4OsJn0UdCYXeJBraexkcMnxH\nHjOzHr95PTuaBaUlxnFvhJ9/KCx/gFLhQ1wnmyW5aWy/fe3YJzoxE+WG4tNCahAd01yHCbSAmHSS\nHVFM7ZOUFr8sL53//uImVjq+0JapJ1oT02SwZelcfrvvHDCyHEG05GUk8k5DR8i745QED4vnpnG2\ntZslY9yJLcxJYf+ZCxRnJbEgO3pHpsXl8zJ5+u5NLB7j7n683Ld1GXdfs8jOlB6LFQXpdo2gUCar\naLjtihJWF3tZPaxKaSRUlGbxm301HG/sYFleuqNs/Piu7cLMJIb8ivMdfdT6esjLMFvwivm5hGg3\nOl6shkAwfoE2LZjmNZWQFlKDmO4yG6B9EJNOisNJPd4s6lCsLvYGCYMCbxI3ryvmykWjO2Ongk2L\nsu3IkInEi0Mgkmm4/8Hi1opiPr6hZEzTgmUS2bwkZ9wmL4uyIq8dTTXZ5KQl2D0GImFFfrrdOXDu\nBDWIBI+bNSWZ4/p8ApnihlnIKhcyvHR2pFj9UGov9FBrhbiC0TjHFQfuybt39TgCOSbjuzhlmE5q\nSUinvXdkJrWVXR2utMmUDGna3ukSIcXhpB5vob5I+ZePlE3J645FRlIcl5dk0tTZF/GdcDiKMpNw\nidHUPRSf2hRZdJWlYVy9NHwnwFjEaQaaqAYxEYoykyjISGT36VY+uXG+XS4kI2mcJibT2Vzr66bW\n18PGhY4bHU9CyG5y48XjCA2OJI9kxjAFhDspjbbG2aFBaAExyaQkeBgYUvQNDs3Igk4XD360nJ5J\naFP6iY3z2bBgDtmpE7s73rJkLj//1Hq2ROh/iBVWOPIoJuqDmAgiRhLjAbP21kS1Y0tjqG7u5nx7\nL0XO0Gt3/BSamGbxd9FtCYgM2noGUEoFaXv2fjKNc9AmpkkmxTRNdPcNcabFSO6ZaOTQbKRkTjJL\n8yZup89IigurPUSDyyVcvWzuhM1Ls43MlHgKMhLxuCLLop5KVhd7qfX10NTRZ/sgxnvzkxjnJjs1\nnjfPGiVWCjOHCQj3JAoId6xoEMbY4lOMnvTOqtAQaBakM6ljmGQzP6Gzb5Ddp1spyEgctf+0RjMW\nKwszyE1PjLzo2xRhBSRUnjOiqlITPBMKkij0JrHf7HBY6HXkC3jiL00TU85yyCjBlWGEHA+PZNIm\npouAFEfToD2nW9m0cM5Fd1ermV4euGE5rV2R93aeKlYVpuN2GRVWJ1JCxqIwM8numR2sQSRMsgYR\nIyameRvhq4dIOVQPnKatZyCo6kFbzwAel5A8RQEUodACYpKx2o4eqW2nqaNvRPkIjSZaSrNToop8\nmirsHiU1RpnyiW62Ts0632mGjUsK6q42UYI0iAkGVUwHViLccA3ieEMH+d7Eab3h1AJikrHqBb10\nzKh4OtHsV41mNrG6OIM/VdazcG7qpAmInLSE4NIoN3wP4idPIFoh2XFusX2EsxlLM3PmQrR1D/DK\niSY+5SgvPx1oH8QkY5mYXjnexJyU+BHtETWaWGZ1sZf23kHerm8fURU4WgozDb/DCB9dyQbIu2xC\nr+3EclJ7k8fXl2W6yQihQTx3tIGBIRWyM+NUogXEJGOZmNp7B6kozYqJC1KjiRTLUd074J80DaJw\nHAX4osEKcx1v1vd0Y0UpOQXEjsp6irOSKJtAn4rxMOsEhIhcLyLHROSkiNw30+OJFmcd+XDZwRpN\nrLJ4bprtJJ2wgDAFQ9EUR/lZGsSsjmBykJboQQQ7m/pCVz+vnWzm/ZeN7Lc91cwqASEibmA7sBVY\nAdwqIitmdlTR4ewXoB3UmosNt0vsxk0TNTFlJMXxTx9cxa0Vo3cynCiWk3pWRzA5cLmEtASP7YN4\n9kgDQ35l9yWZ1rFM+zuOTgVwUil1SinVD/wauGmGxxQViXEuXGLUS5mMRDKNZrZhlWGfjIzej2+Y\nZ5ewnyosE1OsaBBgfLaWiWlHZR2l2SlBxTqni9kmIAqBGsfzc+axmEFESIk3umGF64ms0cQylh8i\nVkrI2BrEOAsLzgTpiXH8+eh53vP9neyqamFbWf6M+DNnW5hrqE9ABZ0gchdwF0BJydSqpuPl769f\nOiPSXqOZDrYszeGzV5Vy5cLYMKG6XMIDNyxj85LYKeT4matK+fPR84DReva2K2ZmrxOl1NhnTRMi\nshH4tlLqfebz+wGUUt8Ndf66devUvn37pnGEGo1GE/uIyH6l1LqxzpttJqa9wGIRKRWReOAW4OkZ\nHpNGo9FckswqE5NSalBE7gaeA9zAw0qpIzM8LI1Go7kkmVUCAkAp9QzwzEyPQ6PRaC51ZpuJSaPR\naDSzBC0gNBqNRhMSLSA0Go1GExItIDQajUYTEi0gNBqNRhOSWZUoFy0i0gScGee/ZwPNkzicmUbP\nZ/Zzsc1Jz2d2M9p85imlcsZ6gZgWEBNBRPZFkkkYK+j5zH4utjnp+cxuJmM+2sSk0Wg0mpBoAaHR\naDSakFzKAuKnMz2ASUbPZ/Zzsc1Jz2d2M+H5XLI+CI1Go9GMzqWsQWg0Go1mFC5JASEi14vIMRE5\nKSL3zfR4okVEikXkJRF5W0SOiMhXzONZIvJnETlh/s6c6bFGg4i4ReQtEdlhPi8Vkd3mfH5jloCP\nCUTEKyK/F5F3zHXaGMvrIyJfNa+1wyLyuIgkxtL6iMjDItIoIocdx0Kuhxj8yNwfKkVk7cyNPDRh\n5vM983qrFJGnRMTr+Nv95nyOicj7In2fS05AiIgb2A5sBVYAt4rIipkdVdQMAl9XSi0HNgBfNOdw\nH/CCUmox8IL5PJb4CvC24/m/AD8w53MBuHNGRjU+fgg8q5RaBpRjzCsm10dECoEvA+uUUqswSvHf\nQmytzyPA9cOOhVuPrcBi8+cu4KFpGmM0PMLI+fwZWKWUKgOOA/cDmHvDLcBK839+bO6DY3LJCQig\nAjiplDqllOoHfg3cNMNjigqlVL1S6k3zcQfG5lOIMY9fmKf9AvjgzIwwekSkCHg/8DPzuQDXAL83\nT4mZ+YhIOvBu4L8AlFL9SikfMbw+GK0BkkTEAyQD9cTQ+iilXgFahx0Otx43AY8qgzcAr4jkT89I\nIyPUfJRSzyulBs2nbwBF5uObgF8rpfqUUqeBkxj74JhcigKiEKhxPD9nHotJRGQ+sAbYDeQqperB\nECJA7DThhX8DvgH4zedzAJ/jgo+ldVoANAE/N01mPxORFGJ0fZRStcCDwFkMwdAG7Cd218ci3Hpc\nDHvEp4H/Zz4e93wuRQEhIY7FZCiXiKQCTwD3KKXaZ3o840VEtgGNSqn9zsMhTo2VdfIAa4GHlFJr\ngC5ixJwUCtM2fxNQChQAKRhmmOHEyvqMRSxfe4jINzHM0L+0DoU4LaL5XIoC4hxQ7HheBNTN0FjG\njYjEYQiHXyqlnjQPn7dUYfN340yNL0o2AR8QkWoMk981GBqF1zRpQGyt0zngnFJqt/n89xgCI1bX\n5zrgtFKqSSk1ADwJXEnsro9FuPWI2T1CRO4AtgG3q0AOw7jncykKiL3AYjMCIx7DefP0DI8pKkz7\n/H8Bbyulvu/409PAHebjO4A/TPfYxoNS6n6lVJFSaj7GeryolLodeAn4iHlaLM2nAagRkaXmoWuB\no8To+mCYljaISLJ57Vnzicn1cRBuPZ4GPmlGM20A2ixT1GxGRK4H7gU+oJTqdvzpaeAWEUkQkVIM\n5/ueiF5UKXXJ/QA3YHj5q4BvzvR4xjH+d2GoiJXAAfPnBgy7/QvACfN31kyPdRxz2wLsMB8vMC/k\nk8DvgISZHl8U81gN7DPX6L+BzFheH+A7wDvAYeAxICGW1gd4HMN/MoBxR31nuPXAMMlsN/eHQxjR\nWzM+hwjmcxLD12DtCT9xnP9Ncz7HgK2Rvo/OpNZoNBpNSC5FE5NGo9FoIkALCI1Go9GERAsIjUaj\n0YRECwiNRqPRhEQLCI1Go9GERAsIzUWPiMwRkQPmT4OI1Dqevz4F77dFRNrMMhtvi8g/jOM1ohqX\niDwiIh8Z+0yNJnI8Y5+i0cQ2SqkWjLwEROTbQKdS6sEpfttXlVLbzBpMB0RkhwouJRISEXErpYaU\nUldO8fg0mjHRGoTmkkZEOs3fW0Rkp4j8VkSOi8g/i8jtIrJHRA6JyELzvBwReUJE9po/m0Z7faVU\nF0Zhu4Vi9Lv4nvl/lSLyOcd7vyQiv8JIzHKOS8z/OWyO42bH8X8XkaMi8idipPCfJrbQGoRGE6Ac\nWI5RRvkU8DOlVIUYDZm+BNyD0efhB0qpv4pICfCc+T8hEZE5GD07/jdGtmubUmq9iCQAr4nI8+ap\nFRi1/E8Pe4m/wdB+yoFsYK+IvAJsBJYClwG5GKUvHp7oB6DRONECQqMJsFeZNXdEpAqwNu9DwNXm\n4+uAFUZJIgDSRSRNGX05nFwlIm9hlC//Z6XUERH5DlDm8BVkYNTF6Qf2hBAOYJRVeVwpNYRRXG4n\nsB6j34R1vE5EXpzY1DWakWgBodEE6HM89jue+wl8V1zARqVUzxiv9apSatuwYwJ8SSn1XNBBkS0Y\nJcFDEapUs4Wuk6OZUrQPQqOJjueBu60nIrI6iv99DviCWaodEVliOrFH4xXgZtN/kYOhOewxj99i\nHs8noOFoNJOG1iA0muj4MrBdRCoxvj+vAJ+P8H9/BswH3jTLZjcxdpvOpzD8DQcxNIZvKKUaROQp\njL4ZhzAqE++Mch4azZjoaq4ajUajCYk2MWk0Go0mJFpAaDQajSYkWkBoNBqNJiRaQGg0Go0mJFpA\naDQajSYkWkBoNBqNJiRaQGg0Go0mJFpAaDQajSYk/x9CLi1oZB73+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc71bd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #초기화\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training step\n",
    "    for i in range(iterations):\n",
    "        _, step_loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
    "        print(\"[step: {}] loss: {}\".format(i, step_loss))\n",
    "\n",
    "    # Test step\n",
    "    test_predict = minMaxDeNormalizer(sess.run(Y_pred, feed_dict={X: testX}),originalSales)\n",
    "    rmse_val = sess.run(rmse, feed_dict={targets: denormalizedTestY_feed, predictions: test_predict})\n",
    "    print(\"RMSE: {}\".format(rmse_val))\n",
    "\n",
    "    # Plot predictions\n",
    "    plt.plot(denormalizedTestY_feed)\n",
    "    plt.plot(test_predict)\n",
    "    plt.xlabel(\"Time Period\")\n",
    "    plt.ylabel(\"Stock Price\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "denormalizedTestPredictY=[item for sublist in test_predict for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.470242788206967"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootMeanSquaredError(denormalizedTestY,denormalizedTestPredictY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
